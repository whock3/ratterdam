{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratterdam Beltway Decoding / ML  / Permutation-Shuffling Approaches\n",
    "## Mid August 2020 - Last attempts at finding a decoding method that works and we have confidence in the results\n",
    "### Ideas: \n",
    "### 1) RF at a single alley per cell, so we can go back to 'template' approach that is invalid when using multiple alleys/cells\n",
    "### 2) Cluster-based metrics compared to shuffle (not classification)\n",
    "### 3) sliding window bayesian decoder (started this in another file, should dump what i've done here)\n",
    "### 4) Late Sep 2020 - new shuffling approach to capture envelope fluctuations within field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from scipy.integrate import simps\n",
    "from scipy.ndimage import center_of_mass\n",
    "import math\n",
    "import numpy as np, random, json, pickle, datetime, copy, socket, os, sys, scipy\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from importlib import reload\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_Defaults as Def\n",
    "import ratterdam_DataFiltering as Filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVisitSummaryFeatures(unit, alley, visit, features):\n",
    "    \"\"\"\n",
    "    For a given pass for a given unit summarize the 1d ratemap into a simpler,\n",
    "    explicit vector of attributes. Which attributes to use are given by\n",
    "    the 'features' list. Visit is the visitnum not the data itself\n",
    "    \"\"\"\n",
    "    feats = np.empty((0))\n",
    "    rm = unit.alleys[alley][visit]['ratemap1d']\n",
    "    # i dont know of a better way of doing this other than to just check param name in list and add it if present\n",
    "    if 'rm' in features:\n",
    "        feats = np.append(feats, rm)\n",
    "    if 'time' in features:\n",
    "        feats = np.append(feats, visit)\n",
    "    if 'max95' in features:\n",
    "        maximum = np.nanpercentile(rm, 95)\n",
    "        feats = np.append(feats, maximum)\n",
    "    if 'locmax95' in features:\n",
    "        locmax = np.searchsorted(np.sort(rm), np.percentile(rm, 95))\n",
    "        feats = np.append(feats, locmax)\n",
    "    if 'mean' in features:\n",
    "        mean = np.nanmean(rm)\n",
    "        feats = np.append(feats, mean)\n",
    "    if 'median' in features:\n",
    "        feats = np.append(feats, np.nanmedian(rm))\n",
    "    if 'auc' in features:\n",
    "        auc = simps(rm)\n",
    "        feats = np.append(feats, auc)\n",
    "    if 'avgdrds' in features:\n",
    "        avgdrds = np.mean(np.abs(np.diff(rm))) # avg dr/ds change in rate / change in pos. \n",
    "        feats = np.append(feats, avgdrds)\n",
    "    if 'maxdrds' in features:\n",
    "        maxdrds = np.percentile(np.abs(np.diff(rm)), 95)\n",
    "        feats = np.append(feats, maxdrds)\n",
    "    if 'com' in features:\n",
    "        try:\n",
    "            com = center_of_mass(np.nan_to_num(rm))[0]\n",
    "            feats = np.append(feats, com)\n",
    "        except:\n",
    "            com = int(round(Def.singleAlleyBins[1]-1)/2)\n",
    "            feats = np.append(feats, com)\n",
    "    if 'comval' in features:\n",
    "        try:\n",
    "            comval = rm[int(np.round(com))]\n",
    "            feats  = np.append(feats, comval)\n",
    "        except:\n",
    "            comval = np.nanpercentile(rm, 95)\n",
    "            feats  = np.append(feats, comval)\n",
    "    if 'boundMaxs' in features:\n",
    "        # think there may be something going on at entrace/exit to alley so get the max val \n",
    "        # within each trisector of alley. NB real intersection ends with alleybounds_manuallyshifted2\n",
    "        # gives a 3:6:3 ratio of approach L:alley:approach/exit R but I want to squeeze in the bounds to give\n",
    "        # more space to the flanks (4:4:4 ratio) to capture whats happening at boundary itself as well.\n",
    "        max1,max2,max3 = np.nanmax(rm[:4]), np.nanmax(rm[4:8]), np.nanmax(rm[9:]) # assumes 12bin rm. make generalized later\n",
    "        feats = np.append(feats,(max1,max2,max3))\n",
    "    if 'isi' in features:\n",
    "        begin, end, bsize = 0, 0.075e6, 5000\n",
    "        bins = np.arange(begin,end,bsize)\n",
    "        spikes = unit.alleys[alley][visit]['spikes']\n",
    "        hist = np.histogram(np.diff(spikes[:,0]),bins=bins)[0]\n",
    "        feats = np.append(feats, hist)\n",
    "        \n",
    "    if 'gamma_params':\n",
    "        rm = rm[~np.isnan(rm)]\n",
    "        rm = rm/rm.sum()\n",
    "        a,loc,b = scipy.stats.gamma.fit(rm)\n",
    "        feats = np.append(feats, [a,loc,b])\n",
    "        \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:174: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:174: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:180: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:329: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:502: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:502: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT1\\cl-maze1.1\n",
      "TT1\\cl-maze1.2\n",
      "TT1\\cl-maze1.3\n",
      "TT1\\cl-maze1.4\n",
      "TT1\\cl-maze1.5\n",
      "TT1\\cl-maze1.6\n",
      "TT10\\cl-maze1.10\n",
      "TT10\\cl-maze1.12\n",
      "TT10\\cl-maze1.2\n",
      "TT10\\cl-maze1.3\n",
      "TT10\\cl-maze1.5\n",
      "TT10\\cl-maze1.6\n",
      "TT10\\cl-maze1.7\n",
      "TT10\\cl-maze1.8\n",
      "TT13\\cl-maze1.1\n",
      "TT13\\cl-maze1.2\n",
      "TT13\\cl-maze1.3\n",
      "TT13\\cl-maze1.4\n",
      "TT13\\cl-maze1.5\n",
      "TT13\\cl-maze1.6\n",
      "TT13\\cl-maze1.7\n",
      "TT13\\cl-maze1.8\n",
      "TT6\\cl-maze1.10\n",
      "TT6\\cl-maze1.11\n",
      "TT6\\cl-maze1.12\n",
      "TT6\\cl-maze1.14\n",
      "TT6\\cl-maze1.15\n",
      "TT6\\cl-maze1.16\n",
      "TT6\\cl-maze1.2\n",
      "TT6\\cl-maze1.3\n",
      "TT6\\cl-maze1.5\n",
      "TT6\\cl-maze1.6\n",
      "TT6\\cl-maze1.7\n",
      "TT6\\cl-maze1.8\n",
      "TT6\\cl-maze1.9\n"
     ]
    }
   ],
   "source": [
    "# Load data into population dict. Each cell will be decoded separately. Within each cell each alley will be decoded separately.\n",
    "rat = 'R859'\n",
    "expCode = \"BRD5\"\n",
    "datafile = f\"E:\\\\Ratterdam\\\\{rat}\\\\{rat}{expCode}\\\\\"\n",
    "\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw()\n",
    "            rm = util.makeRM(unit.spikes, unit.position)            \n",
    "            if np.nanpercentile(rm,Def.wholetrack_imshow_pct_cutoff) >= 1.:\n",
    "                print(clustname)\n",
    "                population[unit.name] = unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupAlleyData(unit, alley, repFx, features):\n",
    "    \"\"\"\n",
    "    Create a matrix (n,b) where n is the number of trials at that alley \n",
    "    (usually with rewards removed, but that's done in the unit.loadRawData fx)\n",
    "    and b are the number of spatial bins in the 1d ratemap of each trial at that alley\n",
    "    \"\"\"\n",
    "    X = [] # dont know how size of feature vec ahead of time so array it later\n",
    "    Y = np.empty((0))\n",
    "    \n",
    "    for visitNum,visit in enumerate(unit.alleys[alley]):\n",
    "        reprm = repFx(unit, alley, visitNum, features)\n",
    "        X.append(reprm)\n",
    "        Y = np.append(Y, unit.alleys[alley][visitNum]['metadata']['stimulus'])\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    X[np.where(~np.isfinite(X))] = 0\n",
    "    #X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRandomForest(X, Y, parmdict):\n",
    "    oobs = []\n",
    "#     fimps = []\n",
    "#     paths = []\n",
    "    for i in range(parmdict['nRuns']):\n",
    "        clf = RandomForestClassifier(n_estimators=parmdict['nTrees'], \n",
    "                                     oob_score=True,\n",
    "                                     max_features = parmdict['Max Feats'],\n",
    "                                     max_depth = parmdict['Max Depth']\n",
    "                                    )       \n",
    "        clf.fit(X,Y)\n",
    "        oobs.append(clf.oob_score_)\n",
    "#         fimps.append(clf.feature_importances_)\n",
    "#         paths.append(clf.decision_path(X))\n",
    "        \n",
    "    return oobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parmString(parmdict, features):\n",
    "    string = ''\n",
    "    for k,v in parmdict.items():\n",
    "        string += f\"{k}:{v}\\n\"\n",
    "    for f in features:\n",
    "        string +=f\"{f}\\n\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parmdict = {\n",
    "    'nRuns':3, # reps of decoding for a given dataset. tech replicates. \n",
    "    'nTrees':10000, \n",
    "    'Max Depth':None, \n",
    "    'Max Feats':'auto',\n",
    "    'Cell inclusion in population': '95pctile >=1Hz overall',\n",
    "    'Visit inclusion in data matrix': '12x visits Mean alley activity >=1 Hz, 3 contig bins >=20% max avg field',\n",
    "    'Bootstrap': 'None',\n",
    "    'Shuffle': 200\n",
    "    }\n",
    "\n",
    "features = [\n",
    "    'rm'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\measurements.py:1359: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  for dir in range(input.ndim)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-542e71630b45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparmdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Shuffle'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mYs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mssoobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunRandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparmdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mnulloobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnulloobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssoobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e5bece0269e7>\u001b[0m in \u001b[0;36mrunRandomForest\u001b[1;34m(X, Y, parmdict)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                      \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparmdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Max Depth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                     )       \n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#         fimps.append(clf.feature_importances_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clust = 'TT6cl-maze1.8'\n",
    "unit = population[clust]\n",
    "\n",
    "string = parmString(parmdict, features)\n",
    "stamp = util.genTimestamp()\n",
    "\n",
    "fig, axes = plt.subplots(3,3,figsize=(10,10))\n",
    "plt.suptitle(f\"{clust} RF Decoding by Alley\")\n",
    "plt.text(0.005, 0.2, string, fontsize=6, transform=plt.gcf().transFigure)\n",
    "\n",
    "for i,alley in enumerate(Def.beltwayAlleys):\n",
    "    valid = Filt.checkMinimumPassesActivity(unit, alley)\n",
    "    if valid:\n",
    "        ax = fig.axes[i]\n",
    "        print(alley)\n",
    "        X,Y = setupAlleyData(unit, alley, createVisitSummaryFeatures, features)\n",
    "        realoobs = runRandomForest(X,Y, parmdict)\n",
    "        realmean = np.mean(realoobs)\n",
    "        nulloobs = np.zeros((0,1))\n",
    "        for i in range(parmdict['Shuffle']):\n",
    "            Ys = np.random.permutation(Y)\n",
    "            ssoobs = runRandomForest(X,Ys, parmdict)\n",
    "            nulloobs = np.vstack((nulloobs, np.mean(ssoobs)))\n",
    "        \n",
    "        ax.hist(nulloobs)\n",
    "        ax.vlines(np.percentile(nulloobs, 95),0,150,'k')\n",
    "        ax.vlines(realmean,0,100,'r')\n",
    "        ax.set_title(f\"Alley {alley}, mean {realmean} vs {np.percentile(nulloobs, 95)} 95% null pct\")\n",
    "    else:\n",
    "        fig.axes[i].set_title(f\"Insufficient Activity in Alley {alley} for Decoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cluster Metrics\n",
    "#### Treat trials under a given texture as a cluster with a centroid. Use basic metrics like avg distance to centroid, intercentroid distance,\n",
    "#### and intersample distance (compared to shuffle w corrected pvalue) to test effect of stimulus on neural representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "import ratterdam_Defaults as Def\n",
    "\n",
    "def interCentroidDistance(ncObj):\n",
    "    \"\"\"\n",
    "    Input a NearestCentroid object (sklearn)\n",
    "    and return pairwise Euclidian distances \n",
    "    between them\n",
    "    \"\"\"\n",
    "    return pdist(ncObj.centroids_)\n",
    "\n",
    "def avgDistToCentroid(ncObj,sa,sb,sc):\n",
    "    \"\"\"\n",
    "    Input: ncObj - NearestCentroid object (sklearn)\n",
    "           sa,sb,sc - vectors which produced centroids\n",
    "    \"\"\"\n",
    "    avga = np.mean(np.linalg.norm(ncObj.centroids_[0]-sa,axis=1))\n",
    "    avgb = np.mean(np.linalg.norm(ncObj.centroids_[1]-sb,axis=1))\n",
    "    avgc = np.mean(np.linalg.norm(ncObj.centroids_[2]-sc,axis=1))\n",
    "    return avga, avgb, avgc\n",
    "\n",
    "def interSampleDistance(sa,sb,sc):\n",
    "    \"\"\"\n",
    "    Input sa,sb,sc - samples from a,b,c trials\n",
    "    Return avg Euclidian distance within each set of samples\n",
    "    \"\"\"\n",
    "    avga = np.mean(pdist(sa))\n",
    "    avgb = np.mean(pdist(sb))\n",
    "    avgc = np.mean(pdist(sc))\n",
    "    return avga, avgb, avgc\n",
    "\t\n",
    "\n",
    "def splitSamplesbyLabel(X,y):\n",
    "    \"\"\"\n",
    "    Given input matrix X with samples of different\n",
    "    labels, stored in Y, split them into arrays by label\n",
    "    A=0, B=1, C=2 for texture labels by convention\n",
    "    \"\"\"\n",
    "    a = X[y==0]\n",
    "    b = X[y==1]\n",
    "    c = X[y==2]\n",
    "    return a,b,c\n",
    "\n",
    "def findCentroids(X,Y):\n",
    "    \"\"\"\n",
    "    Given X (n,f) and Y (n,)\n",
    "    create NearestCentroid object \n",
    "    and return it\n",
    "    \"\"\"\n",
    "    nc = NearestCentroid(metric='euclidean')\n",
    "    nc.fit(X,Y)\n",
    "    return nc\n",
    "\n",
    "def outlierRemoval(X,Y):\n",
    "    \"\"\"\n",
    "    Removes outliers from whole data matrix X\n",
    "    using IsolationForest (sklearn). \n",
    "    Returns X,Y with those samples removed\n",
    "    \"\"\"\n",
    "    clf = IsolationForest()\n",
    "    clf.fit(X)\n",
    "    yo = clf.predict(X)\n",
    "    X = X[yo==1]\n",
    "    Y = Y[yo==1]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A 2-dimensional array must be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-73794f709a23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindCentroids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitSamplesbyLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcd\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minterSampleDistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-217-370796b2e802>\u001b[0m in \u001b[0;36minterSampleDistance\u001b[1;34m(sa, sb, sc)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mavg\u001b[0m \u001b[0mEuclidian\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0meach\u001b[0m \u001b[0mset\u001b[0m \u001b[0mof\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mavga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mavgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mavgc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mpdist\u001b[1;34m(X, metric, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1997\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1998\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1999\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A 2-dimensional array must be passed.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A 2-dimensional array must be passed."
     ]
    }
   ],
   "source": [
    "# Intersample distance\t\n",
    "npca=3\n",
    "features = ['rm']\n",
    "X,Y = setupAlleyData(unit, alley, createVisitSummaryFeatures, features)\n",
    "#X,Y = outlierRemoval(X,Y)\n",
    "cent = findCentroids(X,Y)\n",
    "at,bt,ct = splitSamplesbyLabel(X,Y)\n",
    "ad,bd,cd  = interSampleDistance(at,bt,ct)\n",
    "mind = min(ad,bd,cd)\n",
    "\n",
    "nshuff=1000\n",
    "ss = np.empty((0))\n",
    "for s in range(nshuff):\n",
    "    Ys = np.random.permutation(Y)\n",
    "    scent = findCentroids(X,Ys)\n",
    "    sat,sbt,sct = splitSamplesbyLabel(X,Ys)\n",
    "    ssd = np.min(interSampleDistance(sat,sbt,sct))\n",
    "    ss = np.append(ss,ssd)\n",
    "plt.figure()\n",
    "plt.hist(ss)\n",
    "plt.vlines(mind,0,200,'r')\n",
    "plt.vlines(np.percentile(ss,1),0,200,'k')\n",
    "plt.title(f\"{unit.name} ISD pca comp = {npca}\")\n",
    "\n",
    "\n",
    "# Distance to centroids\n",
    "npca=False\n",
    "features = ['rm']\n",
    "X,Y = setupAlleyData(unit, alley, createVisitSummaryFeatures, features)\n",
    "#X,Y = outlierRemoval(X,Y)\n",
    "cent = findCentroids(X,Y)\n",
    "at,bt,ct = splitSamplesbyLabel(X,Y)\n",
    "ad,bd,cd  = avgDistToCentroid(cent,at,bt,ct)\n",
    "mind = min(ad,bd,cd)\n",
    "\n",
    "nshuff=1000\n",
    "ss = np.empty((0))\n",
    "for s in range(nshuff):\n",
    "    Ys = np.random.permutation(Y)\n",
    "    scent = findCentroids(X,Ys)\n",
    "    sat,sbt,sct = splitSamplesbyLabel(X,Ys)\n",
    "    ssdc = np.min(avgDistToCentroid(scent,sat,sbt,sct))\n",
    "    ss = np.append(ss,ssdc)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ss)\n",
    "plt.vlines(mind,0,200,'r')\n",
    "plt.vlines(np.percentile(ss,1),0,200,'k')\n",
    "plt.title(f\"{unit.name} MDC pca comp = {npca}\")\n",
    "\n",
    "# intercentroid distance\n",
    "npca=False\n",
    "features = ['rm']\n",
    "X,Y = setupAlleyData(unit, alley, createVisitSummaryFeatures, features)\n",
    "#X,Y = outlierRemoval(X,Y)\n",
    "cent = findCentroids(X,Y)\n",
    "icd  = interCentroidDistance(cent)\n",
    "\n",
    "nshuff=1000\n",
    "ss = np.empty((0))\n",
    "for s in range(nshuff):\n",
    "    Ys = np.random.permutation(Y)\n",
    "    scent = findCentroids(X,Ys)\n",
    "    sicd = np.max(interCentroidDistance(scent))\n",
    "    ss = np.append(ss,sicd)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ss)\n",
    "plt.vlines(max(icd),0,200,'r')\n",
    "plt.vlines(np.percentile(ss,99),0,200,'k')\n",
    "plt.title(f\"{unit.name} ICD pca comp = {npca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b,c = splitSamplesbyLabel(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'C')"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running isolation forest on trials by txt, one each per loop\n",
    "s = c\n",
    "txt = 'C'\n",
    "\n",
    "clf = IsolationForest()\n",
    "clf.fit(s)\n",
    "yo = clf.predict(s)\n",
    "plt.figure()\n",
    "plt.xlim([-2,6])\n",
    "plt.ylim([-2,6])\n",
    "plt.scatter(s[:,0], s[:,1])\n",
    "plt.scatter(s[yo==-1][:,0], s[yo==-1][:,1],c='r')\n",
    "plt.title(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f713723cf8>"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on all trials. seems like similar results and will do it this way for now\n",
    "clf.fit(X)\n",
    "yo = clf.predict(X)\n",
    "plt.figure()\n",
    "plt.xlim([-2,6])\n",
    "plt.ylim([-2,6])\n",
    "plt.title(\"All trials\")\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.scatter(X[yo==-1][:,0],X[yo==-1][:,1],c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Algs - Spectral Clustering Decoding, KMeans, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stamp = util.genTimestamp()\n",
    "parmdict = {\n",
    "    'name':unit.name,\n",
    "    'alley':5,\n",
    "    'npca':False,\n",
    "    'doSuffle':True,\n",
    "    'nShuffle':500,\n",
    "    'sliding':True,\n",
    "    'ts':stamp,\n",
    "    'alg':KMeans,\n",
    "    'algParms':{'n_clusters':3},\n",
    "    'metric':metrics.adjusted_rand_score,\n",
    "    'nTrees':700,\n",
    "    'nRuns':10,\n",
    "    'Max Feats':None,\n",
    "    'Max Depth':'auto'\n",
    "            }\n",
    "\n",
    "#features = ['com', 'max95', 'auc','locmax95', 'comval','mean']\n",
    "features = ['rm']\n",
    "string = parmString(parmdict, features)\n",
    "\n",
    "\n",
    "X,Y = setupData(unit, parmdict['alley'], features, parmdict['npca'])\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "\n",
    "if parmdict['sliding']:\n",
    "    idx = slidingCArrWindow(X)\n",
    "    allS = []\n",
    "    allR = []\n",
    "    for i in idx:\n",
    "        Xw = X[:,i[0]:i[1]]\n",
    "        model = parmdict['alg'](**parmdict['algParms'])\n",
    "        l=model.fit_predict(Xw,Y)\n",
    "        r = parmdict['metric'](Y,l)\n",
    "        allR.append(r)\n",
    "\n",
    "        if shuffle:\n",
    "            s = []\n",
    "            for i in range(nShuffle):\n",
    "                s.append(parmdict['metric'](np.random.permutation(Y),l))\n",
    "        allS.append(s)\n",
    "        \n",
    "# plt.figure()\n",
    "# plt.text(0.005, 0.2, string, fontsize=6, transform=plt.gcf().transFigure)\n",
    "# plt.hist(s)\n",
    "# plt.vlines(r,0,200,'r')\n",
    "# npct = np.percentile(s,95)\n",
    "# plt.vlines(npct,0,150,'k')\n",
    "# plt.title(f\"{unit.name} A{alley} {parmdict['alg']}, ARI {round(r,2)} vs Shuffle 95% {round(npct,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingCArrWindow(X,stepSize=1,winSize=4):\n",
    "    \"\"\"return col idx of arrays to slice in sliding window fashion\"\"\"\n",
    "    _max = X.shape[1]\n",
    "    idx = []\n",
    "    for i in range(_max):\n",
    "        a,b = 0+(i*stepSize), winSize+(i*stepSize)\n",
    "        if b <= _max:\n",
    "            idx.append([a,b])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f717707748>]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([np.percentile(i,95) for i in allS],'k--')\n",
    "plt.plot([min(i) for i in allS],'k--')\n",
    "plt.plot(allR,'r')\n",
    "plt.plot([np.percentile(i,99.2) for i in allS],'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stamp = util.genTimestamp()\n",
    "parmdict = {\n",
    "    'name':unit.name,\n",
    "    'alley':5,\n",
    "    'npca':False,\n",
    "    'doSuffle':True,\n",
    "    'nShuffle':100,\n",
    "    'sliding':True,\n",
    "    'ts':stamp,\n",
    "    'alg':KMeans,\n",
    "    'algParms':{'n_clusters':3},\n",
    "    'metric':metrics.adjusted_rand_score,\n",
    "    'nTrees':700,\n",
    "    'nRuns':10,\n",
    "    'Max Feats':None,\n",
    "    'Max Depth':6\n",
    "            }\n",
    "\n",
    "#features = ['com', 'max95', 'auc','locmax95', 'comval','mean']\n",
    "features = ['rm']\n",
    "string = parmString(parmdict, features)\n",
    "\n",
    "X,Y = setupData(unit, parmdict['alley'], features, parmdict['npca'])\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "\n",
    "if parmdict['sliding']:\n",
    "    idx = slidingCArrWindow(X)\n",
    "    allS = []\n",
    "    allR = []\n",
    "    for i in idx:\n",
    "        Xw = X[:,i[0]:i[1]]\n",
    "        oob = np.mean(runRandomForest(Xw,Y,parmdict)) \n",
    "        \n",
    "        if shuffle:\n",
    "            s = []\n",
    "            for i in range(parmdict['nShuffle']):\n",
    "                s.append(np.mean(runRandomForest(Xw, np.random.permutation(Y), parmdict)))\n",
    "            allS.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Shuffling Test of Envelope Fluctuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function declarations\n",
    "def computeTestStatistic_Diffs(groupX, groupY):\n",
    "    \"\"\"\n",
    "    Takes two arrays. Each of which is a stack\n",
    "    of single trial {RM or avg? decide}. \n",
    "    \n",
    "    Avgs them to a summary trace and returns their bin-wise diff\n",
    "    \"\"\"    \n",
    "    \n",
    "    maskX= np.ma.masked_invalid(groupX)\n",
    "    avgX = maskX.mean(axis=0) # ignores inf and nan\n",
    "    maskY= np.ma.masked_invalid(groupY)\n",
    "    avgY = maskY.mean(axis=0) # ignores inf and nan\n",
    "    return avgX-avgY\n",
    "\n",
    "def shuffleArray(array):\n",
    "    for row in range(len(array)):\n",
    "        array[row] = np.random.permutation(array[row])\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Select and load data\n",
    "rat = \"R859\"\n",
    "expCode = \"BRD3\"\n",
    "datafile = f\"E:\\\\Ratterdam\\\\{rat}\\\\{rat}{expCode}\\\\\"\n",
    "\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:174: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:174: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:180: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:329: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n"
     ]
    }
   ],
   "source": [
    "unit = Core.UnitData('TT6\\\\cl-maze1.8', datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "unit.loadData_raw()\n",
    "alley = 7\n",
    "labels = np.asarray([visit['metadata']['stimulus'] for visit in unit.alleys[alley]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2 - Create mean field\n",
    "rms = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "for visit in unit.alleys[alley]:\n",
    "    rms = np.vstack((rms, np.nan_to_num(visit['ratemap1d'])))\n",
    "mean = np.nanmean(rms,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Determine spatial extend of field.\n",
    "# Any bin that is at least 20% of the max, for now. This is standard practice but won't \n",
    "# handle certain cases well. Like two fields would be treated as one\n",
    "thresh = 0.15# pct \n",
    "field = mean[np.where(mean>=(thresh*np.nanmax(mean)))] # find bins at least thresh% of max\n",
    "field_idx = np.where(mean>=(thresh*np.nanmax(mean)))[0]\n",
    "rmsin = rms[:,field_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4 Define real test stats\n",
    "a,b,c = np.nanmean(rmsin[np.where(labels=='A')[0]],axis=0), np.nanmean(rmsin[np.where(labels=='B')[0]],axis=0), np.nanmean(rmsin[np.where(labels=='C')[0]],axis=0)\n",
    "ab, bc, ac = a-b, b-c, a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5 - shuffle bins within field for each visit. Create array of null test stats\n",
    "# Note this is for PILOT version of alg. May do more fine-grained test of shuffling spikes\n",
    "# against behavior if deemed necessary/useful\n",
    "rmsshuffle = copy.deepcopy(rms)\n",
    "rmsshuffle = rmsshuffle[:,field_idx]\n",
    "sab_array, sbc_array, sac_array = np.empty((0, field_idx.shape[0])), np.empty((0, field_idx.shape[0])), np.empty((0, field_idx.shape[0]))\n",
    "\n",
    "for i in range(5000):\n",
    "    shuffleArray(rmsshuffle) # shuffle elements of each row in place. \n",
    "    sa,sb,sc = np.nanmean(rmsshuffle[np.where(labels=='A')[0]],axis=0), np.nanmean(rmsshuffle[np.where(labels=='B')[0]],axis=0), np.nanmean(rmsshuffle[np.where(labels=='C')[0]],axis=0)\n",
    "    sab, sbc, sac = sa-sb, sb-sc, sa-sc\n",
    "    sab_array = np.vstack((sab_array, sab))\n",
    "    sbc_array = np.vstack((sbc_array, sbc))\n",
    "    sac_array = np.vstack((sac_array, sac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13665307d30>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6 - Plot results\n",
    "plt.figure()\n",
    "plt.plot(sab_array.T,color='k',alpha=0.2)\n",
    "plt.plot(ab,'r')\n",
    "fwer, lower, upper = Perm.global_FWER_alpha(sab_array,unit)\n",
    "plt.plot(upper,'r--')\n",
    "plt.plot(lower,'r--')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sbc_array.T,color='k',alpha=0.2)\n",
    "plt.plot(bc,'b')\n",
    "fwer, lower, upper = Perm.global_FWER_alpha(sbc_array,unit)\n",
    "plt.plot(upper,'r--')\n",
    "plt.plot(lower,'r--')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sac_array.T,color='k',alpha=0.2)\n",
    "plt.plot(ac,'g')\n",
    "fwer, lower, upper = Perm.global_FWER_alpha(sac_array,unit)\n",
    "plt.plot(upper,'r--')\n",
    "plt.plot(lower,'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sep 21 2020 - this is possibly promising. but this just tests for spatial pattern within a visit but not an overall different between\n",
    "# textures that is spatially uniform across alley. so integrated this into ratterdam_PermutationTests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Timing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:174: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:174: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:180: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:180: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:329: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT1\\cl-maze1.1\n",
      "TT1\\cl-maze1.2\n",
      "TT1\\cl-maze1.3\n",
      "TT1\\cl-maze1.4\n",
      "TT1\\cl-maze1.5\n",
      "TT1\\cl-maze1.6\n",
      "TT10\\cl-maze1.10\n",
      "TT10\\cl-maze1.11\n",
      "TT10\\cl-maze1.12\n",
      "TT10\\cl-maze1.5\n",
      "TT10\\cl-maze1.6\n",
      "TT10\\cl-maze1.7\n",
      "TT13\\cl-maze1.1\n",
      "TT13\\cl-maze1.2\n",
      "TT13\\cl-maze1.3\n",
      "TT13\\cl-maze1.4\n",
      "TT13\\cl-maze1.5\n",
      "TT13\\cl-maze1.6\n",
      "TT13\\cl-maze1.7\n",
      "TT13\\cl-maze1.8\n",
      "TT6\\cl-maze1.10\n",
      "TT6\\cl-maze1.11\n",
      "TT6\\cl-maze1.12\n",
      "TT6\\cl-maze1.14\n",
      "TT6\\cl-maze1.15\n",
      "TT6\\cl-maze1.16\n",
      "TT6\\cl-maze1.2\n",
      "TT6\\cl-maze1.4\n",
      "TT6\\cl-maze1.6\n",
      "TT6\\cl-maze1.7\n",
      "TT6\\cl-maze1.8\n",
      "TT6\\cl-maze1.9\n"
     ]
    }
   ],
   "source": [
    "rat = 'R859'\n",
    "expCode = \"BRD5\"\n",
    "datafile = f\"E:\\\\Ratterdam\\\\{rat}\\\\{rat}{expCode}\\\\\"\n",
    "figpath = f'E:\\\\Ratterdam\\\\{rat}\\\\spike_timing\\\\{expCode}\\\\'\n",
    "    \n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw()\n",
    "            validalleys = []\n",
    "            for a in [16, 17, 3, 1, 5, 7, 8, 10, 11]:\n",
    "                valid = Filt.checkMinimumPassesActivity(unit, a, pass_thresh=12)\n",
    "                validalleys.append(valid)\n",
    "            if sum(validalleys) > 0:         \n",
    "                print(clustname)  \n",
    "                population[clustname] = unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT1\\cl-maze1.1\n",
      "TT1\\cl-maze1.2\n",
      "TT1\\cl-maze1.3\n",
      "TT1\\cl-maze1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT1\\cl-maze1.5\n",
      "TT1\\cl-maze1.6\n",
      "TT10\\cl-maze1.10\n",
      "TT10\\cl-maze1.11\n",
      "TT10\\cl-maze1.12\n",
      "TT10\\cl-maze1.6\n",
      "TT10\\cl-maze1.7\n",
      "TT13\\cl-maze1.1\n",
      "TT13\\cl-maze1.2\n",
      "TT13\\cl-maze1.3\n",
      "TT13\\cl-maze1.4\n",
      "TT13\\cl-maze1.7\n",
      "TT13\\cl-maze1.8\n",
      "TT6\\cl-maze1.10\n",
      "TT6\\cl-maze1.11\n",
      "TT6\\cl-maze1.12\n",
      "TT6\\cl-maze1.14\n",
      "TT6\\cl-maze1.15\n",
      "TT6\\cl-maze1.16\n",
      "TT6\\cl-maze1.2\n",
      "TT6\\cl-maze1.4\n",
      "TT6\\cl-maze1.6\n",
      "TT6\\cl-maze1.7\n",
      "TT6\\cl-maze1.8\n",
      "TT6\\cl-maze1.9\n"
     ]
    }
   ],
   "source": [
    "stamp = util.genTimestamp()\n",
    "cmap = util.makeCustomColormap()\n",
    "plt.rc('xtick',labelsize=8)\n",
    "plt.rc('ytick',labelsize=8)\n",
    "for clust in population.keys():\n",
    "    include, adjAlpha, alleys = checkInclusion(population[clust])\n",
    "    if include:\n",
    "        print(clust)\n",
    "        unit = population[clust]\n",
    "        with PdfPages(figpath+f\"{stamp}_{unit.name}_{Def.velocity_filter_thresh}vfilt_{Def.includeRewards}R_ISI.pdf\") as pdf:\n",
    "            for alley in alleys:          \n",
    "                valid = Filt.checkMinimumPassesActivity(unit, alley, pass_thresh=12)\n",
    "                if valid:        \n",
    "\n",
    "                    begin, end, bsize = 0, 0.150e6, 2000\n",
    "                    spikes = {txt: [visit['spikes'] for visit in unit.alleys[alley] if visit['metadata']['stimulus']==txt] for txt in ['A','B','C']}   \n",
    "                    isis = {txt: [np.diff(trial[:,0]) for trial in spikes[txt]] for txt in ['A','B','C']}\n",
    "                    bins = np.arange(begin,end,bsize)\n",
    "                    hists = {txt: np.asarray([np.histogram(np.clip(trial,bins[0],bins[-1]),bins=bins)[0] for trial in isis[txt]]) for txt in ['A','B','C']}\n",
    "\n",
    "                    # for the heatmaps in col 1\n",
    "                    normed = {txt: hists[txt][:,:-1]/np.sum(hists[txt][:,:-1]) for txt in ['A','B','C']}\n",
    "                    _vmax = np.nanmax(np.vstack(([hists[txt][:,:-1] for txt in ['A','B','C']])))\n",
    "\n",
    "                    s = f\"MW-U test (alpha={round(adjAlpha,5)}\\n\"\n",
    "                    pairs = ['AB','BC','CA']\n",
    "                    ps = []\n",
    "                    for pair in pairs:\n",
    "                        txtX,txtY = pair[0], pair[1]\n",
    "                        x,y = np.sum(hists[txtX][:,:-1],axis=0)/np.sum(hists[txtX][:,:-1]), np.sum(hists[txtY][:,:-1],axis=0)/np.sum(hists[txtY][:,:-1])\n",
    "                        _,p = mannwhitneyu(x,y)\n",
    "                        s += f\"{pair}: {round(p,5)}\\n\"\n",
    "                        ps.append(p)\n",
    "\n",
    "\n",
    "                    fig, ax = plt.subplots(3,2, figsize=(7,8), sharey='col')\n",
    "                    for i, txt in enumerate(['A','B','C']):\n",
    "                        ax[i,0].bar(range(hists[txt].shape[1]-1), np.sum(hists[txt][:,:-1],axis=0)/np.sum(hists[txt][:,:-1]), color='k') #dont include last bin, its the overflow one and has a much higher freq then the rest. \n",
    "                        ax[i,0].set_title(f\"{txt}, {pairs[i]} MW-U p={round(ps[i],6)}\",fontsize=10)\n",
    "                        ax[i,1].imshow(hists[txt][:,:-1],aspect='auto',cmap=cmap,vmin=0,vmax=_vmax)\n",
    "                    ax[0,1].set_title(f\"ISIs by Trial, max:{round(_vmax,4)}\",fontsize=10)\n",
    "                    ax[1,0].set_ylabel('Normalized Frequency', fontsize=10)\n",
    "                    ax[2,0].set_xlabel('Inter-spike Interval', fontsize=10)\n",
    "\n",
    "                    plt.suptitle(f\"{alley} ISIs {begin}-{end/1000}ms, {bsize/1000}ms bins, adj alpha={round(adjAlpha,5)}\")\n",
    "\n",
    "\n",
    "                    validalleys = []\n",
    "                    for a in [16, 17, 3, 1, 5, 7, 8, 10, 11]:\n",
    "                        valid = Filt.checkMinimumPassesActivity(unit, a, pass_thresh=12)\n",
    "                        validalleys.append(valid)\n",
    "                    adjAlpha = 0.05/(3*sum(validalleys))\n",
    "\n",
    "\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "\n",
    "                    velocities = computeInstSpeed(unit,alley)\n",
    "                    fig,ax = plt.subplots(3,1,figsize=(7,8), sharey=True)\n",
    "                    for i,txt in enumerate(['A','B','C']):\n",
    "                        fig.axes[i].hist(velocities[txt],color='k',bins=50,normed=True)\n",
    "                        fig.axes[i].set_title(txt)\n",
    "                    plt.suptitle(f\"{unit.name} Alley {alley} Instantaneous Speeds\")\n",
    "                    plt.xlabel(\"Speed (cm/s)\")\n",
    "                    fig.axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeInstSpeed(unit, alley):\n",
    "    \"\"\"\n",
    "    Give unit and alley\n",
    "    Compute point-to-point speed as inter-sample\n",
    "    time difference in seconds and distance of LED mvmt in cm.\n",
    "    return a dict velocities[A,B,C] = arr(n,) where n is \n",
    "    number of samples-1 for all trials under a given txt\n",
    "    \"\"\"\n",
    "    \n",
    "    occs = {'A':np.empty((0,3)), 'B':np.empty((0,3)), 'C':np.empty((0,3))}\n",
    "    for visit in unit.alleys[alley]:\n",
    "        occs[visit['metadata']['stimulus']] = np.vstack((occs[visit['metadata']['stimulus']], visit['occs']))\n",
    "    \n",
    "    velocities = {txt:np.empty((0)) for txt in ['A','B','C']}\n",
    "    for txt in ['A','B','C']:\n",
    "        for i in range(occs[txt].shape[0]-1):\n",
    "            tsA,tsB = occs[txt][i,0], occs[txt][i+1,0]\n",
    "            dist = distance(occs[txt][i,1:],occs[txt][i+1,1:])\n",
    "            dist = dist/Def.ptsCm_macaulay\n",
    "            v = (dist/(tsB-tsA))*1e6\n",
    "            velocities[txt] = np.hstack((velocities[txt], v))\n",
    "    return velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(p0, p1):\n",
    "    return math.sqrt((p0[0] - p1[0])**2 + (p0[1] - p1[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "def findField(unit,alley,sthresh=3,rthresh=0.5,pctThresh=None):\n",
    "    \"\"\"\n",
    "    Identify a field as a set of sthresh or more contiguous bins\n",
    "    greater than some thresh\n",
    "    rthresh - an absolute thresh in Hz\n",
    "    pct thresh - a pct of max \n",
    "    One of these must be None, cant have both\n",
    "    \"\"\"\n",
    "    rms = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "    for visit in unit.alleys[alley]:\n",
    "        rm = visit['ratemap1d']\n",
    "        rms = np.vstack((rms, rm))\n",
    "        \n",
    "    if rthresh is not None and pctThresh is not None:\n",
    "        print(\"Error - conflicting thresh definitions\")\n",
    "    mean = np.nanmean(rms, axis=0)\n",
    "    if rthresh is not None:\n",
    "        thresh = rthresh        \n",
    "        fi = np.where(mean>=rthresh)[0]\n",
    "    elif pctThresh is not None:\n",
    "        thresh = pctThresh\n",
    "        fi = np.where(mean>=(pctthresh*np.nanmax(mean)))[0]        \n",
    "    \n",
    "    field = True\n",
    "    try:\n",
    "        field_idx = np.concatenate(([i for i in consecutive(fi) if len(i)>=sthresh]))\n",
    "    except:\n",
    "        field = False\n",
    "        field_idx = None\n",
    "    return field, field_idx\n",
    "\n",
    "def checkInclusion(unit):\n",
    "    \"\"\"\n",
    "    Apply inclusion criteria to a unit, deciding which(if any)\n",
    "    alleys will be included in analysis. If 0, cell is not used.\n",
    "    If >0, return: inclusion bool, adj alpha, alley(s) to be included\n",
    "    adj alpha just takes #alleys into account\n",
    "    \"\"\"\n",
    "    validalleys = []\n",
    "    for alley in Def.beltwayAlleys:\n",
    "        passesCheck = Filt.checkMinimumPassesActivity(unit, alley, pass_thresh=12)\n",
    "        fieldCheck, _ = findField(unit, alley)\n",
    "        if passesCheck is True and fieldCheck is True:\n",
    "            validalleys.append(alley)\n",
    "    if len(validalleys)>0:\n",
    "        alphaCorr = 0.05/(len(validalleys))\n",
    "        include = True\n",
    "    else:\n",
    "        alphaCorr = None\n",
    "        include = False\n",
    "    return include, alphaCorr, validalleys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 10-1-20 Log transform and other tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit = population['TT6\\\\cl-maze1.2']\n",
    "alley=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin, end, bsize = 0, 0.100e6, 1000\n",
    "spikes = {txt: [visit['spikes'] for visit in unit.alleys[alley] if visit['metadata']['stimulus']==txt] for txt in ['A','B','C']}   \n",
    "isis = {txt: [np.diff(trial[:,0]) for trial in spikes[txt]] for txt in ['A','B','C']}\n",
    "bins = np.arange(begin,end,bsize)\n",
    "hists = {txt: np.asarray([np.histogram(np.clip(trial,bins[0],bins[-1]),bins=bins)[0] for trial in isis[txt]]) for txt in ['A','B','C']}\n",
    "\n",
    "# for the heatmaps in col 1\n",
    "normed = {txt: np.sum(hists[txt][:,:-1],axis=0)/np.sum(hists[txt][:,:-1]) for txt in ['A','B','C']}\n",
    "summed = {txt: np.sum(hists[txt][:,:-1],axis=0) for txt in ['A','B','C']}\n",
    "_vmax = np.nanmax(np.vstack(([hists[txt][:,:-1] for txt in ['A','B','C']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trialRM(spikes, position, alley, bins):\n",
    "    longDimBins, shortDimBins = bins\n",
    "    alleyBins = {i:{'rows':None,'cols':None} for i in range(17)}\n",
    "    dim=1\n",
    "    for i,v in enumerate(unit.alleyBounds.values()):\n",
    "        x,y = v\n",
    "        if i in [i-1 for i in [1,5,7,2,13,9,16,14,11]]:\n",
    "            bins = [shortDimBins, longDimBins] #again, np.2dhist takes [x,y] which means [c, r]\n",
    "        elif i in [i-1 for i in [3,4,6,8,17,15,12,10]]:\n",
    "            bins = [longDimBins, shortDimBins]\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        alleyBins[i]['rows'] = np.linspace(unit.alleyBounds[i][1][0], unit.alleyBounds[i][1][1],num=bins[0])\n",
    "        alleyBins[i]['cols'] = np.linspace(unit.alleyBounds[i][0][0], unit.alleyBounds[i][0][1],num=bins[1])\n",
    "\n",
    "\n",
    "    rbins,cbins = alleyBins[alley-1]['rows'], alleyBins[alley-1]['cols']\n",
    "    hs = np.histogram2d(spikes[:,2],spikes[:,1],bins=[rbins, cbins])[0]\n",
    "    ho = np.histogram2d(position[:,2],position[:,1],bins=[rbins, cbins])[0]\n",
    "    if dim == 2:\n",
    "        n = (hs*np.reciprocal(ho))*30\n",
    "        n[np.where(ho==0)] = np.nan\n",
    "        n = util.weird_smooth(n,Def.smoothing_2d_sigma)\n",
    "        n[np.where(ho==0)] = np.nan\n",
    "    elif dim == 1:\n",
    "        ls,lo  = np.sum(hs,axis=util.getAxType(ho)), np.sum(ho,axis=util.getAxType(ho))\n",
    "        n = (ls* np.reciprocal(lo)) * 30\n",
    "        if np.count_nonzero(~np.isnan(n))>1:\n",
    "            n = util.stepsmooth(n,Def.smoothing_1d_sigma)\n",
    "        n[np.where(lo==0)] = np.nan\n",
    "    return n,rbins,cbins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 10-8-20 Fitting empirical dist to trial and using trial-by-trial fitted params to identify txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit = population['TT6\\\\cl-maze1.2']\n",
    "alley=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas, locations, betas, txts = [], [], [], []\n",
    "for visit in unit.alleys[alley]:\n",
    "    rm = visit['ratemap1d'][~np.isnan(visit['ratemap1d'])] # flip if field is at far end of alley\n",
    "    a,loc,b = scipy.stats.gamma.fit(rm)\n",
    "    alphas.append(a)\n",
    "    locations.append(loc)\n",
    "    betas.append(b)\n",
    "    txts.append(visit['metadata']['stimulus'])\n",
    "    \n",
    "alphas = np.asarray(alphas)\n",
    "locations = np.asarray(locations)\n",
    "betas = np.asarray(betas)\n",
    "txts  = np.asarray(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2873eaf4630>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(betas, alphas,c=c)\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
