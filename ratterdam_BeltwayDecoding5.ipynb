{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratterdam Beltway Decoding / ML approaches\n",
    "## Mid August 2020 - Last attempts at finding a decoding method that works and we have confidence in the results\n",
    "### Ideas: \n",
    "### 1) RF at a single alley per cell, so we can go back to 'template' approach that is invalid when using multiple alleys/cells\n",
    "### 2) Cluster-based metrics compared to shuffle (not classification)\n",
    "### 3) sliding window bayesian decoder (started this in another file, should dump what i've done here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from scipy.integrate import simps\n",
    "from scipy.ndimage import center_of_mass\n",
    "import numpy as np, random, json, pickle, datetime, copy, socket, os, sys, scipy\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from importlib import reload\n",
    "\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_Defaults as Def\n",
    "import ratterdam_DataFiltering as Filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVisitSummaryFeatures(unit, alley, visit, features):\n",
    "    \"\"\"\n",
    "    For a given pass for a given unit summarize the 1d ratemap into a simpler,\n",
    "    explicit vector of attributes. Which attributes to use are given by\n",
    "    the 'features' list. Visit is the visitnum not the data itself\n",
    "    \"\"\"\n",
    "    feats = np.empty((0))\n",
    "    rm = unit.alleys[alley][visit]['ratemap1d']\n",
    "    # i dont know of a better way of doing this other than to just check param name in list and add it if present\n",
    "    if 'rm' in features:\n",
    "        feats = np.append(feats, rm)\n",
    "    if 'time' in features:\n",
    "        feats = np.append(feats, visit)\n",
    "    if 'max95' in features:\n",
    "        maximum = np.nanpercentile(rm, 95)\n",
    "        feats = np.append(feats, maximum)\n",
    "    if 'locmax95' in features:\n",
    "        locmax = np.searchsorted(np.sort(rm), np.percentile(rm, 95))\n",
    "        feats = np.append(feats, locmax)\n",
    "    if 'mean' in features:\n",
    "        mean = np.nanmean(rm)\n",
    "        feats = np.append(feats, mean)\n",
    "    if 'auc' in features:\n",
    "        auc = simps(rm)\n",
    "        feats = np.append(feats, auc)\n",
    "    if 'avgdrds' in features:\n",
    "        avgdrds = np.mean(np.abs(np.diff(rm))) # avg dr/ds change in rate / change in pos. \n",
    "        feats = np.append(feats, avgdrds)\n",
    "    if 'maxdrds' in features:\n",
    "        maxdrds = np.percentile(np.abs(np.diff(rm)), 95)\n",
    "        feats = np.append(feats, maxdrds)\n",
    "    if 'com' in features:\n",
    "        try:\n",
    "            com = center_of_mass(rm)[0]\n",
    "            feats = np.append(feats, com)\n",
    "        except:\n",
    "            com = int(round(Def.singleAlleyBins[1]-1)/2)\n",
    "            feats = np.append(feats, com)\n",
    "    if 'comval' in features:\n",
    "        try:\n",
    "            comval = rm[int(np.round(com))]\n",
    "            feats  = np.append(feats, comval)\n",
    "        except:\n",
    "            comval = np.nanpercentile(rm, 95)\n",
    "            feats  = np.append(feats, comval)\n",
    "    if 'boundMaxs' in features:\n",
    "        # think there may be something going on at entrace/exit to alley so get the max val \n",
    "        # within each trisector of alley. NB real intersection ends with alleybounds_manuallyshifted2\n",
    "        # gives a 3:6:3 ratio of approach L:alley:approach/exit R but I want to squeeze in the bounds to give\n",
    "        # more space to the flanks (4:4:4 ratio) to capture whats happening at boundary itself as well.\n",
    "        max1,max2,max3 = np.nanmax(rm[:4]), np.nanmax(rm[4:8]), np.nanmax(rm[9:]) # assumes 12bin rm. make generalized later\n",
    "        feats = np.append(feats,(max1,max2,max3))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:166: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:166: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:172: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\ratterdam_CoreDataStructures.py:172: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:329: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:502: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:502: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT1\\cl-maze1.2\n",
      "TT12\\cl-maze1.1\n",
      "TT12\\cl-maze1.3\n",
      "TT15\\cl-maze1.2\n",
      "TT5\\cl-maze1.5\n",
      "TT6\\cl-maze1.1\n",
      "TT6\\cl-maze1.2\n",
      "TT6\\cl-maze1.3\n"
     ]
    }
   ],
   "source": [
    "# Load data into population dict. Each cell will be decoded separately. Within each cell each alley will be decoded separately.\n",
    "rat = 'R808'\n",
    "expCode = \"BRD6\"\n",
    "datafile = f\"E:\\\\Ratterdam\\\\{rat}\\\\{rat}{expCode}\\\\\"\n",
    "\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw()\n",
    "            rm = util.makeRM(unit.spikes, unit.position)            \n",
    "            if np.nanpercentile(rm,Def.wholetrack_imshow_pct_cutoff) >= 1.:\n",
    "                print(clustname)\n",
    "                population[unit.name] = unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupAlleyData(unit, alley, repFx, features):\n",
    "    \"\"\"\n",
    "    Create a matrix (n,b) where n is the number of trials at that alley \n",
    "    (usually with rewards removed, but that's done in the unit.loadRawData fx)\n",
    "    and b are the number of spatial bins in the 1d ratemap of each trial at that alley\n",
    "    \"\"\"\n",
    "    if features == 'rm':\n",
    "        X = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "    else:\n",
    "        X = np.empty((0, len(features)))\n",
    "    Y = np.empty((0))\n",
    "    \n",
    "    for visitNum,visit in enumerate(unit.alleys[alley]):\n",
    "        reprm = repFx(unit, alley, visitNum, features)\n",
    "        X = np.vstack((X, reprm))\n",
    "        Y = np.append(Y, unit.alleys[alley][visitNum]['metadata']['stimulus'])\n",
    "    \n",
    "    X[np.where(~np.isfinite(X))] = 0\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRandomForest(X, Y, parmdict):\n",
    "    oobs = []\n",
    "#     fimps = []\n",
    "#     paths = []\n",
    "    for i in range(parmdict['nRuns']):\n",
    "        clf = RandomForestClassifier(n_estimators=parmdict['nTrees'], \n",
    "                                     oob_score=True,\n",
    "                                     max_features = parmdict['Max Feats'],\n",
    "                                     max_depth = parmdict['Max Depth']\n",
    "                                    )       \n",
    "        clf.fit(X,Y)\n",
    "        oobs.append(clf.oob_score_)\n",
    "#         fimps.append(clf.feature_importances_)\n",
    "#         paths.append(clf.decision_path(X))\n",
    "        \n",
    "    return oobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parmString(parmdict, features):\n",
    "    string = ''\n",
    "    for k,v in parmdict.items():\n",
    "        string += f\"{k}:{v}\\n\"\n",
    "    for f in features:\n",
    "        string +=f\"{f}\\n\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parmdict = {\n",
    "    'nRuns':25, # reps of decoding for a given dataset. tech replicates. \n",
    "    'nTrees':700, \n",
    "    'Max Depth':None, \n",
    "    'Max Feats':'auto',\n",
    "    'Cell inclusion in population': '95pctile >=1Hz overall',\n",
    "    'Visit inclusion in data matrix': '9x visits Mean alley activity >=1 Hz',\n",
    "    'Bootstrap': 'None',\n",
    "    'Shuffle': 1000\n",
    "    }\n",
    "\n",
    "features = [\n",
    "    'time',\n",
    "    'auc',\n",
    "    'com',\n",
    "    'comval',\n",
    "    'max95',\n",
    "    'locmax95',\n",
    "    'mean',\n",
    "    'avgdrds',\n",
    "    'maxdrds'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\measurements.py:1359: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  for dir in range(input.ndim)]\n"
     ]
    }
   ],
   "source": [
    "clust = 'TT15cl-maze1.2'\n",
    "unit = population[clust]\n",
    "\n",
    "string = parmString()\n",
    "stamp = util.genTimestamp()\n",
    "\n",
    "fig, axes = plt.subplots(3,3,figsize=(10,10))\n",
    "plt.suptitle(f\"{clust} RF Decoding by Alley\")\n",
    "plt.text(0.005, 0.2, string, fontsize=6, transform=plt.gcf().transFigure)\n",
    "\n",
    "for i,alley in enumerate(Def.beltwayAlleys):\n",
    "    valid = Filt.checkMinimumPassesActivity(unit, alley)\n",
    "    if valid:\n",
    "        ax = fig.axes[i]\n",
    "        print(alley)\n",
    "        X,Y = setupAlleyData(unit, alley, createVisitSummaryFeatures, features)\n",
    "        realoobs = runRandomForest(X,Y, parmdict)\n",
    "        realmean = np.mean(realoobs)\n",
    "        nulloobs = np.zeros((0,1))\n",
    "        for i in range(parmdict['Shuffle']):\n",
    "            Ys = np.random.permutation(Y)\n",
    "            ssoobs = runRandomForest(X,Ys, parmdict)\n",
    "            nulloobs = np.vstack((nulloobs, np.mean(ssoobs)))\n",
    "        \n",
    "        ax.hist(nulloobs)\n",
    "        ax.vlines(np.percentile(nulloobs, 95),0,150,'k')\n",
    "        ax.vlines(realmean,0,100,'r')\n",
    "        ax.set_title(f\"Alley {alley}, mean {realmean} vs {np.percentile(nulloobs, 95)} 95% null pct\")\n",
    "    else:\n",
    "        fig.axes[i].set_title(f\"Insufficient Activity in Alley {alley} for Decoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cluster Metrics\n",
    "#### Treat trials under a given texture as a cluster with a centroid. Use basic metrics like avg distance to centroid, intercentroid distance,\n",
    "#### and intersample distance (compared to shuffle w corrected pvalue) to test effect of stimulus on neural representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "import ratterdam_Defaults as Def\n",
    "\n",
    "def interCentroidDistance(ncObj):\n",
    "    \"\"\"\n",
    "    Input a NearestCentroid object (sklearn)\n",
    "    and return pairwise Euclidian distances \n",
    "    between them\n",
    "    \"\"\"\n",
    "    return pdist(ncObj.centroids_)\n",
    "\n",
    "def avgDistToCentroid(ncObj,sa,sb,sc):\n",
    "    \"\"\"\n",
    "    Input: ncObj - NearestCentroid object (sklearn)\n",
    "           sa,sb,sc - vectors which produced centroids\n",
    "    \"\"\"\n",
    "    avga = np.mean(np.linalg.norm(ncObj.centroids_[0]-sa,axis=1))\n",
    "    avgb = np.mean(np.linalg.norm(ncObj.centroids_[1]-sb,axis=1))\n",
    "    avgc = np.mean(np.linalg.norm(ncObj.centroids_[2]-sc,axis=1))\n",
    "    return avga, avgb, avgc\n",
    "\n",
    "def interSampleDistance(sa,sb,sc):\n",
    "    \"\"\"\n",
    "    Input sa,sb,sc - samples from a,b,c trials\n",
    "    Return avg Euclidian distance within each set of samples\n",
    "    \"\"\"\n",
    "    avga = np.mean(pdist(sa))\n",
    "    avgb = np.mean(pdist(sb))\n",
    "    avgc = np.mean(pdist(sc))\n",
    "    return avga, avgb, avgc\n",
    "\t\n",
    "def setupData(unit, alley, features, dimred):\n",
    "    \"\"\"\n",
    "    Input   - unit: Unit class object\n",
    "            - alley: alley in whole track terms\n",
    "            - list of features (e.g. COM, Max, etc) to represent a single RM\n",
    "                or pass 'rm' to use original rm \n",
    "            - dimred: if False, no dimensionality reduction\n",
    "                if a number then thats # pca comps\n",
    "\n",
    "    Returns: data matrix X (n,f) n samples f features\n",
    "             label vector Y (n,)\n",
    "    \"\"\"\n",
    "    if 'rm' in features:\n",
    "        atrials,btrials,ctrials = np.empty((0,Def.singleAlleyBins[0]-1)), np.empty((0,Def.singleAlleyBins[0]-1)), np.empty((0,Def.singleAlleyBins[0]-1))\n",
    "    else:\n",
    "        atrials,btrials,ctrials = np.empty((0,len(features))), np.empty((0,len(features))), np.empty((0,len(features)))\n",
    "    for i,visit in enumerate(unit.alleys[alley]):\n",
    "        stim = visit['metadata']['stimulus']\n",
    "        feats = createVisitSummaryFeatures(unit,alley,i,features)\n",
    "        if stim == 'A':\n",
    "            atrials = np.vstack((atrials, feats))\n",
    "        elif stim == 'B':\n",
    "            btrials = np.vstack((btrials, feats))\n",
    "        elif stim == 'C':\n",
    "            ctrials = np.vstack((ctrials, feats))\n",
    "            \n",
    "    X = np.vstack((atrials, btrials, ctrials))\n",
    "    X[np.where(~np.isfinite(X))] = 0\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    Y = np.asarray([0]*atrials.shape[0] + [1]*btrials.shape[0] + [2]*ctrials.shape[0])\n",
    "    if dimred:\n",
    "        if dimred > len(features) and 'rm' not in features:\n",
    "            print(\"Error - PCA ncomp > original vector size\")\n",
    "        else:\n",
    "            pca = decomposition.PCA(n_components=dimred)\n",
    "            pca.fit(X)\n",
    "            X = pca.transform(X)\n",
    "    return X, Y\n",
    "\n",
    "def splitSamplesbyLabel(X,y):\n",
    "    \"\"\"\n",
    "    Given input matrix X with samples of different\n",
    "    labels, stored in Y, split them into arrays by label\n",
    "    A=0, B=1, C=2 for texture labels by convention\n",
    "    \"\"\"\n",
    "    a = X[y==0]\n",
    "    b = X[y==1]\n",
    "    c = X[y==2]\n",
    "    return a,b,c\n",
    "\n",
    "def findCentroids(X,Y):\n",
    "    \"\"\"\n",
    "    Given X (n,f) and Y (n,)\n",
    "    create NearestCentroid object \n",
    "    and return it\n",
    "    \"\"\"\n",
    "    nc = NearestCentroid(metric='euclidean')\n",
    "    nc.fit(X,Y)\n",
    "    return nc\n",
    "\n",
    "def outlierRemoval(X,Y):\n",
    "    \"\"\"\n",
    "    Removes outliers from whole data matrix X\n",
    "    using IsolationForest (sklearn). \n",
    "    Returns X,Y with those samples removed\n",
    "    \"\"\"\n",
    "    clf = IsolationForest()\n",
    "    clf.fit(X)\n",
    "    yo = clf.predict(X)\n",
    "    X = X[yo==1]\n",
    "    Y = Y[yo==1]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'TT1cl-maze1.2 ICD pca comp = False')"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersample distance\t\n",
    "npca=3\n",
    "features = ['rm']\n",
    "X,Y = setupData(unit, alley, features, npca)\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "cent = findCentroids(X,Y)\n",
    "at,bt,ct = splitSamplesbyLabel(X,Y)\n",
    "ad,bd,cd  = interSampleDistance(at,bt,ct)\n",
    "mind = min(ad,bd,cd)\n",
    "\n",
    "nshuff=1000\n",
    "ss = np.empty((0))\n",
    "for s in range(nshuff):\n",
    "    Ys = np.random.permutation(Y)\n",
    "    scent = findCentroids(X,Ys)\n",
    "    sat,sbt,sct = splitSamplesbyLabel(X,Ys)\n",
    "    ssd = np.min(interSampleDistance(sat,sbt,sct))\n",
    "    ss = np.append(ss,ssd)\n",
    "plt.figure()\n",
    "plt.hist(ss)\n",
    "plt.vlines(mind,0,200,'r')\n",
    "plt.vlines(np.percentile(ss,1),0,200,'k')\n",
    "plt.title(f\"{unit.name} ISD pca comp = {npca}\")\n",
    "\n",
    "\n",
    "# Distance to centroids\n",
    "npca=False\n",
    "features = ['rm']\n",
    "X,Y = setupData(unit, alley, features, npca)\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "cent = findCentroids(X,Y)\n",
    "at,bt,ct = splitSamplesbyLabel(X,Y)\n",
    "ad,bd,cd  = avgDistToCentroid(cent,at,bt,ct)\n",
    "mind = min(ad,bd,cd)\n",
    "\n",
    "nshuff=1000\n",
    "ss = np.empty((0))\n",
    "for s in range(nshuff):\n",
    "    Ys = np.random.permutation(Y)\n",
    "    scent = findCentroids(X,Ys)\n",
    "    sat,sbt,sct = splitSamplesbyLabel(X,Ys)\n",
    "    ssdc = np.min(avgDistToCentroid(scent,sat,sbt,sct))\n",
    "    ss = np.append(ss,ssdc)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ss)\n",
    "plt.vlines(mind,0,200,'r')\n",
    "plt.vlines(np.percentile(ss,1),0,200,'k')\n",
    "plt.title(f\"{unit.name} MDC pca comp = {npca}\")\n",
    "\n",
    "# intercentroid distance\n",
    "npca=False\n",
    "features = ['rm']\n",
    "X,Y = setupData(unit, alley, features, npca)\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "cent = findCentroids(X,Y)\n",
    "icd  = interCentroidDistance(cent)\n",
    "\n",
    "nshuff=1000\n",
    "ss = np.empty((0))\n",
    "for s in range(nshuff):\n",
    "    Ys = np.random.permutation(Y)\n",
    "    scent = findCentroids(X,Ys)\n",
    "    sicd = np.max(interCentroidDistance(scent))\n",
    "    ss = np.append(ss,sicd)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ss)\n",
    "plt.vlines(max(icd),0,200,'r')\n",
    "plt.vlines(np.percentile(ss,99),0,200,'k')\n",
    "plt.title(f\"{unit.name} ICD pca comp = {npca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b,c = splitSamplesbyLabel(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'C')"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running isolation forest on trials by txt, one each per loop\n",
    "s = c\n",
    "txt = 'C'\n",
    "\n",
    "clf = IsolationForest()\n",
    "clf.fit(s)\n",
    "yo = clf.predict(s)\n",
    "plt.figure()\n",
    "plt.xlim([-2,6])\n",
    "plt.ylim([-2,6])\n",
    "plt.scatter(s[:,0], s[:,1])\n",
    "plt.scatter(s[yo==-1][:,0], s[yo==-1][:,1],c='r')\n",
    "plt.title(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f713723cf8>"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on all trials. seems like similar results and will do it this way for now\n",
    "clf.fit(X)\n",
    "yo = clf.predict(X)\n",
    "plt.figure()\n",
    "plt.xlim([-2,6])\n",
    "plt.ylim([-2,6])\n",
    "plt.title(\"All trials\")\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.scatter(X[yo==-1][:,0],X[yo==-1][:,1],c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Algs - Spectral Clustering Decoding, KMeans, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = util.genTimestamp()\n",
    "parmdict = {\n",
    "    'name':unit.name,\n",
    "    'alley':5,\n",
    "    'npca':False,\n",
    "    'doSuffle':True,\n",
    "    'nShuffle':500,\n",
    "    'sliding':True,\n",
    "    'ts':stamp,\n",
    "    'alg':KMeans,\n",
    "    'algParms':{'n_clusters':3},\n",
    "    'metric':metrics.adjusted_rand_score,\n",
    "    'nTrees':700,\n",
    "    'nRuns':10,\n",
    "    'Max Feats':None,\n",
    "    'Max Depth':'auto'\n",
    "            }\n",
    "\n",
    "#features = ['com', 'max95', 'auc','locmax95', 'comval','mean']\n",
    "features = ['rm']\n",
    "string = parmString(parmdict, features)\n",
    "\n",
    "\n",
    "X,Y = setupData(unit, parmdict['alley'], features, parmdict['npca'])\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "\n",
    "if parmdict['sliding']:\n",
    "    idx = slidingCArrWindow(X)\n",
    "    allS = []\n",
    "    allR = []\n",
    "    for i in idx:\n",
    "        Xw = X[:,i[0]:i[1]]\n",
    "        model = parmdict['alg'](**parmdict['algParms'])\n",
    "        l=model.fit_predict(Xw,Y)\n",
    "        r = parmdict['metric'](Y,l)\n",
    "        allR.append(r)\n",
    "\n",
    "        if shuffle:\n",
    "            s = []\n",
    "            for i in range(nShuffle):\n",
    "                s.append(parmdict['metric'](np.random.permutation(Y),l))\n",
    "        allS.append(s)\n",
    "        \n",
    "# plt.figure()\n",
    "# plt.text(0.005, 0.2, string, fontsize=6, transform=plt.gcf().transFigure)\n",
    "# plt.hist(s)\n",
    "# plt.vlines(r,0,200,'r')\n",
    "# npct = np.percentile(s,95)\n",
    "# plt.vlines(npct,0,150,'k')\n",
    "# plt.title(f\"{unit.name} A{alley} {parmdict['alg']}, ARI {round(r,2)} vs Shuffle 95% {round(npct,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingCArrWindow(X,stepSize=1,winSize=4):\n",
    "    \"\"\"return col idx of arrays to slice in sliding window fashion\"\"\"\n",
    "    _max = X.shape[1]\n",
    "    idx = []\n",
    "    for i in range(_max):\n",
    "        a,b = 0+(i*stepSize), winSize+(i*stepSize)\n",
    "        if b <= _max:\n",
    "            idx.append([a,b])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f717707748>]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([np.percentile(i,95) for i in allS],'k--')\n",
    "plt.plot([min(i) for i in allS],'k--')\n",
    "plt.plot(allR,'r')\n",
    "plt.plot([np.percentile(i,99.2) for i in allS],'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = util.genTimestamp()\n",
    "parmdict = {\n",
    "    'name':unit.name,\n",
    "    'alley':5,\n",
    "    'npca':False,\n",
    "    'doSuffle':True,\n",
    "    'nShuffle':100,\n",
    "    'sliding':True,\n",
    "    'ts':stamp,\n",
    "    'alg':KMeans,\n",
    "    'algParms':{'n_clusters':3},\n",
    "    'metric':metrics.adjusted_rand_score,\n",
    "    'nTrees':700,\n",
    "    'nRuns':10,\n",
    "    'Max Feats':None,\n",
    "    'Max Depth':6\n",
    "            }\n",
    "\n",
    "#features = ['com', 'max95', 'auc','locmax95', 'comval','mean']\n",
    "features = ['rm']\n",
    "string = parmString(parmdict, features)\n",
    "\n",
    "X,Y = setupData(unit, parmdict['alley'], features, parmdict['npca'])\n",
    "X,Y = outlierRemoval(X,Y)\n",
    "\n",
    "if parmdict['sliding']:\n",
    "    idx = slidingCArrWindow(X)\n",
    "    allS = []\n",
    "    allR = []\n",
    "    for i in idx:\n",
    "        Xw = X[:,i[0]:i[1]]\n",
    "        oob = np.mean(runRandomForest(Xw,Y,parmdict)) \n",
    "        \n",
    "        if shuffle:\n",
    "            s = []\n",
    "            for i in range(parmdict['nShuffle']):\n",
    "                s.append(np.mean(runRandomForest(Xw, np.random.permutation(Y), parmdict)))\n",
    "            allS.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
