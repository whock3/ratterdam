{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratterdam Beltway Decoding / ML approaches\n",
    "## Mid August 2020 - Last attempts at finding a decoding method that works and we have confidence in the results\n",
    "### Ideas: \n",
    "### 1) RF at a single alley per cell, so we can go back to 'template' approach that is invalid when using multiple alleys/cells\n",
    "### 2) Cluster-based metrics compared to shuffle (not classification)\n",
    "### 3) sliding window bayesian decoder (started this in another file, should dump what i've done here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from scipy.integrate import simps\n",
    "from scipy.ndimage import center_of_mass\n",
    "import numpy as np, random, json, pickle, datetime, copy, socket, os, sys, scipy\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from importlib import reload\n",
    "\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_PermutationTests as Perm\n",
    "import ratterdam_Defaults as Def\n",
    "import ratterdam_DataFiltering as Filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVisitSummaryFeatures(unit, alley, visit, features):\n",
    "    \"\"\"\n",
    "    For a given pass for a given unit summarize the 1d ratemap into a simpler,\n",
    "    explicit vector of attributes. Which attributes to use are given by\n",
    "    the 'features' list.\n",
    "    \"\"\"\n",
    "    feats = np.empty((0))\n",
    "    rm = unit.alleys[alley][visit]['ratemap1d']\n",
    "    # i dont know of a better way of doing this other than to just check param name in list and add it if present\n",
    "    if 'rm' in features:\n",
    "        feats = np.append(feats, rm)\n",
    "    if 'time' in features:\n",
    "        feats = np.append(feats, visit)\n",
    "    if 'max95' in features:\n",
    "        maximum = np.nanpercentile(rm, 95)\n",
    "        feats = np.append(feats, maximum)\n",
    "    if 'locmax95' in features:\n",
    "        locmax = np.searchsorted(np.sort(rm), np.percentile(rm, 95))\n",
    "        feats = np.append(feats, locmax)\n",
    "    if 'mean' in features:\n",
    "        mean = np.nanmean(rm)\n",
    "        feats = np.append(feats, mean)\n",
    "    if 'auc' in features:\n",
    "        auc = simps(rm)\n",
    "        feats = np.append(feats, auc)\n",
    "    if 'avgdrds' in features:\n",
    "        avgdrds = np.mean(np.abs(np.diff(rm))) # avg dr/ds change in rate / change in pos. \n",
    "        feats = np.append(feats, avgdrds)\n",
    "    if 'maxdrds' in features:\n",
    "        maxdrds = np.percentile(np.abs(np.diff(rm)), 95)\n",
    "        feats = np.append(feats, maxdrds)\n",
    "    if 'com' in features:\n",
    "        try:\n",
    "            com = center_of_mass(rm)[0]\n",
    "            feats = np.append(feats, com)\n",
    "        except:\n",
    "            com = int(round(Def.singleAlleyBins[1]-1)/2)\n",
    "            feats = np.append(feats, com)\n",
    "    if 'comval' in features:\n",
    "        try:\n",
    "            comval = rm[int(np.round(com))]\n",
    "            feats  = np.append(feats, comval)\n",
    "        except:\n",
    "            comval = np.nanpercentile(rm, 95)\n",
    "            feats  = np.append(feats, comval)\n",
    "    if 'boundMaxs' in features:\n",
    "        # think there may be something going on at entrace/exit to alley so get the max val \n",
    "        # within each trisector of alley. NB real intersection ends with alleybounds_manuallyshifted2\n",
    "        # gives a 3:6:3 ratio of approach L:alley:approach/exit R but I want to squeeze in the bounds to give\n",
    "        # more space to the flanks (4:4:4 ratio) to capture whats happening at boundary itself as well.\n",
    "        max1,max2,max3 = np.nanmax(rm[:4]), np.nanmax(rm[4:8]), np.nanmax(rm[9:]) # assumes 12bin rm. make generalized later\n",
    "        feats = np.append(feats,(max1,max2,max3))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data into population dict. Each cell will be decoded separately. Within each cell each alley will be decoded separately.\n",
    "rat = 'R808'\n",
    "expCode = \"BRD6\"\n",
    "datafile = f\"E:\\\\Ratterdam\\\\{rat}\\\\{rat}{expCode}\\\\\"\n",
    "\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw()\n",
    "            rm = util.makeRM(unit.spikes, unit.position)            \n",
    "            if np.nanpercentile(rm,Def.wholetrack_imshow_pct_cutoff) >= 1.:\n",
    "                print(clustname)\n",
    "                population[unit.name] = unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupAlleyData(unit, alley, repFx, features):\n",
    "    \"\"\"\n",
    "    Create a matrix (n,b) where n is the number of trials at that alley \n",
    "    (usually with rewards removed, but that's done in the unit.loadRawData fx)\n",
    "    and b are the number of spatial bins in the 1d ratemap of each trial at that alley\n",
    "    \"\"\"\n",
    "    X = np.empty((0, Def.singleAlleyBins-1))\n",
    "    Y = np.empty((0, 1))\n",
    "    \n",
    "    for visitNum,visit in enumerate(unit.alleys[alley]):\n",
    "        reprm = repFx(unit, alley, visit, features)\n",
    "        X = np.vstack((X, reprm))\n",
    "        Y = np.vstack((Y, unit.alleys[alley]['metadata']['stimulus']))\n",
    "    \n",
    "    X[np.where(~np.isfinite(X))] = 0\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRandomForest(X, Y, runs=300, trees=700):\n",
    "    oobs = []\n",
    "    fimps = []\n",
    "    paths = []\n",
    "    for i in range(runs):\n",
    "        print(i)\n",
    "        clf = RandomForestClassifier(n_estimators=trees, \n",
    "                                     oob_score=True,\n",
    "                                     max_features = None,\n",
    "                                     max_depth = 4\n",
    "                                    )       \n",
    "        clf.fit(X,Y)\n",
    "        oobs.append(clf.oob_score_)\n",
    "        fimps.append(clf.feature_importances_)\n",
    "        paths.append(clf.decision_path(X))\n",
    "        \n",
    "    return oobs, fimps, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
