{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## math, plotting\n",
    "\n",
    "user = 'will' # this is hacky i know\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "## machine learning\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from os import listdir\n",
    "if user != 'will':\n",
    "    sys.path.append('../../Beltway_Project/')\n",
    "    sys.path.append('../../RatterdamOpen_Project/')\n",
    "    sys.path.append('../DATA/')\n",
    "    sys.path.append('../../../ratterdam/')\n",
    "    from statannot import add_stat_annotation\n",
    "\n",
    "\n",
    "\n",
    "import RateMapClass_William_20190308 as RateMapClass\n",
    "import ratterdam_RepetitionCoreFx as CoreFx\n",
    "import confounds as direction\n",
    "import newAlleyBounds as bounds2\n",
    "\n",
    "import repetition_manuscript_defaults as MDef\n",
    "\n",
    "#%qtconsole --style paraiso-dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changes in representation with time\n",
    "## Population vector correlation heatmaps\n",
    "## x and y axis - time windows\n",
    "\n",
    "rep_nonrep = 'both' ## 'nonrep' ## 'both'\n",
    "def correlation_finder(rep_nonrep):\n",
    "    ## Reading in file with all data\n",
    "    if user != 'will':\n",
    "        file = open('../DATA/20220405-124315_superPopulationRepetition.pickle','rb')\n",
    "        alldat = pickle.load(file)\n",
    "        store_dir = '../DATA/FILES/'\n",
    "    elif user == 'will':\n",
    "        with open(\"E:\\\\Ratterdam\\\\R_data_repetition\\\\20220405-124315_superPopulationRepetition.pickle\",\"rb\") as f:\n",
    "            alldat = pickle.load(f)  \n",
    "        store_dir = 'E:\\\\Ratterdam\\\\repetition_manuscript\\\\Figure6_TemporalDynamics\\\\MN_analyses\\\\FILES\\\\'\n",
    "\n",
    "    interneuron_thresh = 0.03 ##0.08\n",
    "    interneuron_num_alleys = 17\n",
    "    all_delta_corr = [[],[],[],[],[],[],[]]\n",
    "    ##fig, axs = plt.subplots(5,2, figsize = (12,30))\n",
    "    num_cells = []\n",
    "    all_rats = list(alldat.keys())\n",
    "    figy = 0\n",
    "    for rat in all_rats:\n",
    "        all_days = list(alldat[rat].keys())\n",
    "        figx = 0\n",
    "        for day in all_days:\n",
    "            day_neur = rat + '_' + day\n",
    "            print(day_neur)\n",
    "            anorm = np.load(store_dir + rat + '_' + day + '_time_alley_neur_normalized_.npy')\n",
    "            anorm[anorm == np.inf] = np.NaN\n",
    "\n",
    "            repeating_cells = []\n",
    "            all_cells = alldat[rat][day]['units'].keys()\n",
    "            for each_cell in all_cells:\n",
    "                data = alldat[rat][day]['units'][each_cell]\n",
    "                if data.repeating == True:\n",
    "                    repeating_cells.append(True)\n",
    "                else:\n",
    "                    repeating_cells.append(False)\n",
    "\n",
    "            if rep_nonrep == 'rep':\n",
    "                anorm = anorm[:,:, repeating_cells]\n",
    "            elif rep_nonrep == 'nonrep':\n",
    "                anorm = anorm[:,:, ~np.array(repeating_cells)]\n",
    "\n",
    "\n",
    "            ## excluding interneurons\n",
    "            exclude_only = np.nanmean(anorm, axis = (0,1))> interneuron_thresh\n",
    "            exclude_only= exclude_only*(np.sum(np.nanmean(anorm, axis = 0)>interneuron_thresh, axis = 0)>interneuron_num_alleys)\n",
    "            include_only = ~exclude_only\n",
    "            anorm = anorm[:,:, include_only]\n",
    "\n",
    "            if np.shape(anorm)[2]!=0:\n",
    "                corr_plot = np.zeros((len(anorm), len(anorm)))\n",
    "                for i in range(0, len(anorm)):\n",
    "                    for j in range(0, len(anorm)):\n",
    "                        if True not in np.isnan(anorm[i]) and True not in np.isnan(anorm[j]) and i!=j:\n",
    "                            corr_plot[i,j] = scipy.stats.pearsonr(anorm[i].flatten(),anorm[j].flatten())[0]\n",
    "                            if i>=j:\n",
    "                                all_delta_corr[abs(i-j)].append(corr_plot[i,j])\n",
    "                        else:\n",
    "                            no_na_i = ~np.isnan(anorm[i].flatten())\n",
    "                            no_na_j = ~np.isnan(anorm[j].flatten())\n",
    "                            no_na = no_na_i*no_na_j\n",
    "                            corr_plot[i,j] = scipy.stats.pearsonr(anorm[i].flatten()[no_na],anorm[j].flatten()[no_na])[0]\n",
    "                            if i>=j:\n",
    "                                all_delta_corr[abs(i-j)].append(corr_plot[i,j])\n",
    "                '''sb.heatmap(corr_plot, ax = axs[figy, figx])\n",
    "                axs[figy, figx].set_title(rat + '_' + day)'''\n",
    "                ##plt.show()\n",
    "                figx = figx + 1\n",
    "        figy = figy + 1\n",
    "    return all_delta_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R765_RFD5\n",
      "R765_DFD4\n",
      "R781_D3\n",
      "R781_D4\n",
      "R808_D6\n",
      "R808_D7\n",
      "R859_D1\n",
      "R859_D2\n",
      "R886_D1\n",
      "R886_D2\n",
      "R-squared: 0.20258138388958621\n",
      "pvalue: 9.80310893968718e-08\n",
      "slope: -0.0675924111115843\n",
      "R765_RFD5\n",
      "R765_DFD4\n",
      "R781_D3\n",
      "R781_D4\n",
      "R808_D6\n",
      "R808_D7\n",
      "R859_D1\n",
      "R859_D2\n",
      "R886_D1\n",
      "R886_D2\n",
      "R-squared: 0.1640643433690796\n",
      "pvalue: 4.01407858532984e-12\n",
      "slope: -0.05357315255212921\n"
     ]
    }
   ],
   "source": [
    "## plots a single figure showing drop in population-vector correlation with increasing time difference\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "all_rep_nonrep = ['rep', 'nonrep']\n",
    "rep_face_colors = ['darkorange', 'darkgrey']\n",
    "rep_edge_colors = ['darkgoldenrod', 'black']\n",
    "df_corr_created = False\n",
    "for curr_rep_nonrep in range(len(all_rep_nonrep)):\n",
    "    rep_nonrep = all_rep_nonrep[curr_rep_nonrep]\n",
    "    all_delta_corr = correlation_finder(rep_nonrep)\n",
    "    if df_corr_created == False:\n",
    "        df_corr = pd.DataFrame(np.array([np.ones(len(all_delta_corr[1])),np.array(all_delta_corr[1]).astype('float'), [curr_rep_nonrep]*len(all_delta_corr[1])]).T, columns = ['time', 'correlation', 'repetition'])\n",
    "        df_corr_created = True\n",
    "    else:\n",
    "        df_new = pd.DataFrame(np.array([np.ones(len(all_delta_corr[1])),np.array(all_delta_corr[1]).astype('float'), [curr_rep_nonrep]*len(all_delta_corr[1])]).T, columns = ['time', 'correlation', 'repetition'])\n",
    "        df_corr = df_corr.append(df_new, ignore_index = True)\n",
    "    for j in range(2, len(all_delta_corr)):\n",
    "        df_new = pd.DataFrame(np.array([j*np.ones(len(all_delta_corr[j])),np.array(all_delta_corr[j]).astype('float'), [curr_rep_nonrep]*len(all_delta_corr[j])]).T, columns = ['time', 'correlation', 'repetition'])\n",
    "        df_corr = df_corr.append(df_new, ignore_index = True)\n",
    "\n",
    "\n",
    "    ##res = scipy.stats.linregress(df_corr)\n",
    "    res = scipy.stats.linregress(df_corr['time'].astype('float'), df_corr['correlation'].astype('float'))\n",
    "    print(f\"R-squared: {res.rvalue**2}\")\n",
    "    print(f\"pvalue: {res.pvalue}\")\n",
    "    print(f\"slope: {res.slope}\")\n",
    "\n",
    "    b1 = ax.boxplot(all_delta_corr[1:],patch_artist=True)\n",
    "\n",
    "    [patch.set(alpha=0.6) for patch in b1['boxes']]\n",
    "    plt.setp(b1[\"fliers\"], markeredgecolor=rep_edge_colors[curr_rep_nonrep] )\n",
    "    plt.setp(b1[\"boxes\"], facecolor=rep_face_colors[curr_rep_nonrep] )\n",
    "    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(b1[item], color=rep_edge_colors[curr_rep_nonrep],linewidth=2)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(axis='both', labelsize=MDef.ticksize)\n",
    "    ax.set_ylabel(\"Population Vector Correlation\", fontsize=MDef.ylabelsize)\n",
    "    ax.set_xlabel(\"Time Window Delta\",fontsize=MDef.ylabelsize)\n",
    "    ax.plot(np.arange(1, 7, 1), res.intercept + res.slope*np.arange(1, 7, 1), '-o', label=rep_nonrep, color = rep_edge_colors[curr_rep_nonrep] )\n",
    "    ax.set_label(rep_nonrep)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    ##plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whockei1\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='time', ylabel='correlation'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.swarmplot(df_corr['time'],df_corr['correlation'], hue = df_corr['repetition'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.14404361656013384 False\n",
      "2.0 0.056088220670682254 False\n",
      "3.0 0.03810804441974767 False\n",
      "4.0 0.04446081951174478 False\n",
      "5.0 0.17194935735074687 False\n",
      "6.0 0.4244956816280012 False\n"
     ]
    }
   ],
   "source": [
    "## statistics\n",
    "num_tests = len(np.unique(np.array(df_corr['time'])))\n",
    "alpha = 0.05/num_tests\n",
    "all_time_curr = np.arange(1.0, 7.0, 1)\n",
    "pval_all = []\n",
    "for time_curr in all_time_curr:\n",
    "    rep_df = df_corr.loc[(df_corr['time'] == time_curr) & (df_corr['repetition'] == 0)]\n",
    "    nonrep_df = df_corr.loc[(df_corr['time'] == time_curr) & (df_corr['repetition'] == 1)]\n",
    "    pval_all.append(scipy.stats.ttest_ind(np.array(rep_df['correlation']), np.array(nonrep_df['correlation'])).pvalue)\n",
    "    \n",
    "    if pval_all[-1]<alpha:\n",
    "        significance  = True\n",
    "    else:\n",
    "        significance  = False\n",
    "        \n",
    "    print(time_curr, pval_all[-1], significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(time)</th>\n",
       "      <td>1.404025</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.382295</td>\n",
       "      <td>6.103610e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(repetition)</th>\n",
       "      <td>0.423466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.165004</td>\n",
       "      <td>4.643739e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(time):C(repetition)</th>\n",
       "      <td>0.087348</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.708126</td>\n",
       "      <td>6.178052e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>6.389615</td>\n",
       "      <td>259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sum_sq     df          F        PR(>F)\n",
       "C(time)                1.404025    5.0  11.382295  6.103610e-10\n",
       "C(repetition)          0.423466    1.0  17.165004  4.643739e-05\n",
       "C(time):C(repetition)  0.087348    5.0   0.708126  6.178052e-01\n",
       "Residual               6.389615  259.0        NaN           NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('correlation ~ C(time) + C(repetition) + C(time):C(repetition)', data=df_corr).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=-7.880558137725835, pvalue=2.4956444521450746e-05)\n",
      "-0.0593\n",
      "0.02257454318474684\n"
     ]
    }
   ],
   "source": [
    "slopes = [-0.046,\n",
    "-0.044,\n",
    "-0.091,\n",
    "-0.053,\n",
    "-0.1,\n",
    "-0.029,\n",
    "-0.053,\n",
    "-0.056,\n",
    "-0.083,\n",
    "-0.038\n",
    "]\n",
    "print(ttest_1samp(slopes,0,alternative='two-sided'))\n",
    "print(np.mean(slopes))\n",
    "print(np.std(slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.765625000000005e-14"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_test(10,10,0.05,'greater')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "810497aa9f218318f89d4d2cff33f7d283ecef935a2d4dd2910844a97859f315"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
