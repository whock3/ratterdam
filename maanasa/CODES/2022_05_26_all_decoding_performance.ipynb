{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## math, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "## machine learning\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from os import listdir\n",
    "user = 'will'\n",
    "if user != 'will':\n",
    "\n",
    "    sys.path.append('../../Beltway_Project/')\n",
    "    sys.path.append('../../RatterdamOpen_Project/')\n",
    "    sys.path.append('../DATA/')\n",
    "    sys.path.append('../../../ratterdam/')\n",
    "\n",
    "\n",
    "import RateMapClass_William_20190308 as RateMapClass\n",
    "import ratterdam_RepetitionCoreFx as CoreFx\n",
    "import confounds as direction\n",
    "import newAlleyBounds as bounds2\n",
    "\n",
    "import repetition_manuscript_defaults as MDef \n",
    "\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_scorer(x,y, inst_fr):\n",
    "    target1 = (x-np.mean(x))/np.std(x)\n",
    "    target2 = (y-np.mean(y))/np.std(y)\n",
    "\n",
    "    train_size = 8000\n",
    "    test_size = 1000\n",
    "    buffer = int((dt-train_size-test_size)/2)\n",
    "    for i in range(0, int(len(inst_fr)/dt)):\n",
    "        if i == 0:\n",
    "            X_train = inst_fr[i*dt : i*dt + train_size,:]\n",
    "            y_train1 = target1[i*dt : i*dt + train_size]\n",
    "            y_train2 = target2[i*dt : i*dt + train_size]\n",
    "            X_test = inst_fr[(i)*dt + train_size + buffer: (i)*dt + train_size + buffer+test_size,:]\n",
    "            y_test1 = target1[(i)*dt + train_size + buffer: (i)*dt + train_size + buffer+test_size]\n",
    "            y_test2 = target2[(i)*dt + train_size + buffer: (i)*dt + train_size + buffer+test_size]\n",
    "        else:\n",
    "            X_train  = np.vstack((X_train, inst_fr[i*dt + buffer: i*dt + train_size+ buffer]))\n",
    "            ##print('training', i*dt + buffer,i*dt + train_size+ buffer)\n",
    "            X_test = np.vstack((X_test, inst_fr[(i)*dt + train_size + 2*buffer: (i)*dt + train_size + 2*buffer+test_size,:]))\n",
    "            ##print('testing',(i)*dt + train_size + 2*buffer,((i)*dt + train_size + 2*buffer+test_size))\n",
    "            y_train1 = np.append(y_train1, target1[i*dt+ buffer: i*dt + train_size+ buffer])\n",
    "            y_test1 = np.append(y_test1, target1[(i)*dt + train_size + 2*buffer: (i)*dt + train_size + 2*buffer+test_size])\n",
    "\n",
    "            y_train2 = np.append(y_train2, target2[i*dt+ buffer: i*dt + train_size+ buffer])\n",
    "            y_test2 = np.append(y_test2, target2[(i)*dt + train_size + 2*buffer: (i)*dt + train_size + 2*buffer+test_size])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)        \n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train1)\n",
    "\n",
    "    model2 = LinearRegression()\n",
    "    model2.fit(X_train, y_train2)\n",
    "    \n",
    "    \n",
    "    train_score = (model.score(X_train, y_train1) + model2.score(X_train, y_train2))/2\n",
    "    test_score = (model.score(X_test, y_test1) + model2.score(X_test, y_test2))/2\n",
    "    ##print('model score', model.score(X_train, y_train1))\n",
    "    ##ypred = model.predict(X_train)\n",
    "    ##print('r2 function', r2_score(y_train1, ypred))\n",
    "    return(np.array([train_score, test_score]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R765 RFD5\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R765 DFD4\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R781 D3\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R781 D4\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R808 D6\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R808 D7\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R859 D1\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R859 D2\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R886 D1\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "R886 D2\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "## Reading in file with all data\n",
    "if user != 'will':\n",
    "    file = open('../DATA/20220405-124315_superPopulationRepetition.pickle','rb')\n",
    "    alldat = pickle.load(file)\n",
    "    store_dir = '../DATA/FILES/'\n",
    "elif user == 'will':\n",
    "    with open(\"E:\\\\Ratterdam\\\\R_data_repetition\\\\20220405-124315_superPopulationRepetition.pickle\",\"rb\") as f:\n",
    "        alldat = pickle.load(f)  \n",
    "    store_dir = 'E:\\\\Ratterdam\\\\repetition_manuscript\\\\Figure6_TemporalDynamics\\\\MN_analyses\\\\FILES\\\\'\n",
    "\n",
    "## performance of all cells with shuffle performance\n",
    "dt = 10000\n",
    "all_num_repeat= []\n",
    "all_num = []\n",
    "all_rats = list(alldat.keys())\n",
    "all_rat_day = []\n",
    "all_scores = []\n",
    "\n",
    "## for permutation test\n",
    "num_shuff = 1000\n",
    "alpha = 0.05\n",
    "each_side = int((alpha/2)*num_shuff)\n",
    "train_test_95 = []\n",
    "\n",
    "for rat in all_rats:  \n",
    "    all_days = list(alldat[rat].keys())\n",
    "    for day in all_days:\n",
    "        print(rat, day)\n",
    "        day_scores = np.zeros((10,2))\n",
    "        inst_fr = np.load(store_dir + rat + '_' + day + '_inst_fr.npy')\n",
    "        x_order = np.load(store_dir + rat + '_' + day + '_x_within.npy')\n",
    "        y_order = np.load(store_dir + rat + '_' + day + '_y_within.npy')\n",
    "        ## actual data\n",
    "        for rep in range(0,10):\n",
    "            all_rat_day.append(rat+ '_' + day)\n",
    "            \n",
    "            shuff_start = np.random.choice(len(inst_fr),1)[0]\n",
    "            shuff_inst_fr = np.vstack((inst_fr[shuff_start:,:], inst_fr[0:shuff_start,:]))\n",
    "            \n",
    "            x = np.concatenate((x_order[shuff_start:], x_order[0:shuff_start]))\n",
    "            y = np.concatenate((y_order[shuff_start:], y_order[0:shuff_start]))\n",
    "            day_scores[rep, :] = train_test_scorer(x,y, shuff_inst_fr)\n",
    "        all_scores.append(day_scores)\n",
    "        ## permutation test\n",
    "        all_perm_scores = np.zeros((num_shuff,2))\n",
    "        for perm in range(0,num_shuff):\n",
    "            if perm%100== 0:\n",
    "                print(perm)\n",
    "            shuff_start = np.random.choice(len(inst_fr),1)[0]\n",
    "            shuff_inst_fr = np.vstack((inst_fr[shuff_start:,:], inst_fr[0:shuff_start,:]))\n",
    "            all_perm_scores[perm] = train_test_scorer(x_order,y_order, shuff_inst_fr)\n",
    "        train_test_95.append(np.array([np.sort(all_perm_scores[:,0])[-each_side], np.sort(all_perm_scores[:,1])[-each_side]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots figure\n",
    "\n",
    "all_scores = np.array(all_scores)\n",
    "score_df = pd.DataFrame(all_scores[:,:,0].flatten(), columns = ['score'])\n",
    "score_df['rat-day'] = np.array(all_rat_day)\n",
    "score_df['train-test'] = ['train']*len(all_rat_day)\n",
    "\n",
    "score_df2= pd.DataFrame(all_scores[:,:,1].flatten(), columns = ['score'])\n",
    "score_df2['rat-day'] = np.array(all_rat_day)\n",
    "score_df2['train-test'] = ['test']*len(all_rat_day)\n",
    "\n",
    "score_df_all = pd.concat([score_df, score_df2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13,7))\n",
    "sb.set_style('darkgrid',{'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "sb.boxplot(x = score_df_all['rat-day'], y = score_df_all['score'], hue = score_df_all['train-test'], whis=[5, 95])\n",
    "## box inter-quartile range\n",
    "## whiskers whis=[2.5, 97.5]\n",
    "## whiskers whis=[5, 95]\n",
    "ax.set_xticklabels(np.unique(all_rat_day),rotation = 45, fontsize=MDef.xlabelsize)\n",
    "ax.set_ylabel('Position decoding ($r^2$)', fontsize=MDef.ylabelsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "## axis limited, because some outliers very extreme, smushes everything else\n",
    "#ax.set_ylim(-0.45, 1)\n",
    "##ax.plot(np.linspace(-0.2, 8.8, 10),np.array(train_test_95)[:,0],'o')\n",
    "\n",
    "\n",
    "ax.plot(np.linspace(0.2, 9.2, 10),np.array(train_test_95)[:,1],'+', color = 'orange', markersize=10)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2.7545826171875007e-06\n"
     ]
    }
   ],
   "source": [
    "## Statistics\n",
    "## Binomial test\n",
    "num_not_cross = 0\n",
    "num_rat_days = len(train_test_95)\n",
    "all_test_lim = np.array(train_test_95)[:,1]\n",
    "for i in range(num_rat_days):\n",
    "    if np.percentile(all_scores[i,:,1], 5)> all_test_lim[i]:\n",
    "        num_not_cross = num_not_cross + 1\n",
    "print(num_not_cross)\n",
    "print(scipy.stats.binom_test(num_not_cross,num_rat_days, p = 0.05, alternative = \"greater\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.380931071345294\n"
     ]
    }
   ],
   "source": [
    "print(np.median(all_scores[:,:,1]))\n",
    "print(np.std(all_scores[:,:,1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "810497aa9f218318f89d4d2cff33f7d283ecef935a2d4dd2910844a97859f315"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
