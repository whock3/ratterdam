{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy\n",
    "\n",
    "import numpy as np, random, json, pickle, datetime, copy, socket, os, sys\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from importlib import reload\n",
    "\n",
    "if socket.gethostname() == 'Tolman':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whockei1\\\\Google Drive'\n",
    "elif socket.gethostname() == 'DESKTOP-BECTOJ9':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whock\\\\Google Drive'\n",
    "    \n",
    "sys.path.insert(0, codeDirBase + '\\\\KnierimLab\\\\Ratterdam\\\\Code')\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_PermutationTests as Perm\n",
    "import ratterdam_Defaults as Def\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT11\\cl-maze1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:157: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:157: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:163: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:163: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:321: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT11\\cl-maze1.2\n",
      "TT3\\cl-maze1.1\n",
      "TT3\\cl-maze1.2\n",
      "TT3\\cl-maze1.3\n",
      "TT3\\cl-maze1.4\n",
      "TT3\\cl-maze1.5\n",
      "TT3\\cl-maze1.6\n",
      "TT3\\cl-maze1.7\n",
      "TT5\\cl-maze1.1\n",
      "TT5\\cl-maze1.2\n",
      "TT5\\cl-maze1.3\n",
      "TT5\\cl-maze1.4\n",
      "TT6\\cl-maze1.1\n",
      "TT6\\cl-maze1.2\n",
      "TT6\\cl-maze1.3\n",
      "TT6\\cl-maze1.4\n",
      "TT6\\cl-maze1.5\n",
      "TT6\\cl-maze1.6\n",
      "TT6\\cl-maze1.7\n",
      "TT6\\cl-maze1.8\n",
      "TT6\\cl-maze1.9\n",
      "TT9\\cl-maze1.1\n",
      "TT9\\cl-maze1.2\n",
      "TT9\\cl-maze1.3\n",
      "TT9\\cl-maze1.4\n",
      "TT9\\cl-maze1.5\n",
      "TT9\\cl-maze1.6\n",
      "TT9\\cl-maze1.7\n"
     ]
    }
   ],
   "source": [
    "# figpath = f\"C:\\\\Users\\\\whockei1\\\\Google Drive\\\\KnierimLab\\\\Ratterdam\\\\Figures\\\\R765{exp}\\\\\"\n",
    "# datafile = f'E:\\\\Ratterdam\\\\R765\\\\R765{exp}\\\\'\n",
    "# behav = core.BehavioralData(datafile, exp, velocity_filter_thresh)\n",
    "# ts, position, alleyTracking, alleyVisits,  txtVisits = behav.loadData()\n",
    "\n",
    "datafile = \"E:\\\\Ratterdam\\\\R781\\\\Beltway_D3_190307\\\\\"\n",
    "expCode = \"BRD3\"\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            print(clustname)\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw(includeRewards=False)\n",
    "            population[unit.name] = unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to temporal confound, recompute average texture-response linear ratemap ONLY WITH trials meeting a firing criteria of >1hz in >3 bins (10% have some activity). \n",
    "#### The rationale is then a cell will not \"vote\" that it does not \"like\" a texture simply because it did not have a field when that texture was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT10cl-maze1.1\n",
      "TT10cl-maze1.2\n",
      "TT10cl-maze1.3\n",
      "TT10cl-maze1.4\n",
      "TT10cl-maze1.5\n",
      "TT10cl-maze1.6\n",
      "TT10cl-maze1.7\n",
      "TT13cl-maze1.1\n",
      "TT13cl-maze1.2\n",
      "TT13cl-maze1.3\n",
      "TT15cl-maze1.1\n",
      "TT15cl-maze1.2\n",
      "TT15cl-maze1.3\n",
      "TT15cl-maze1.4\n",
      "TT15cl-maze1.5\n",
      "TT4cl-maze1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:309: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:305: RuntimeWarning: invalid value encountered in multiply\n",
      "  W=0*U.copy()+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT4cl-maze1.10\n",
      "TT4cl-maze1.11\n",
      "TT4cl-maze1.12\n",
      "TT4cl-maze1.2\n",
      "TT4cl-maze1.3\n",
      "TT4cl-maze1.4\n",
      "TT4cl-maze1.5\n",
      "TT4cl-maze1.6\n",
      "TT4cl-maze1.7\n",
      "TT4cl-maze1.8\n",
      "TT4cl-maze1.9\n",
      "TT6cl-maze1.1\n",
      "TT6cl-maze1.2\n",
      "TT7cl-maze1.1\n",
      "TT7cl-maze1.2\n",
      "TT7cl-maze1.3\n"
     ]
    }
   ],
   "source": [
    "firing_thresh = 1# what is minimum firing rate in Hz required\n",
    "spike_thresh = 5\n",
    "bin_num_thresh = 3 # in how many bins, at minimum, is the above rate required? Not nec. contiguous. \n",
    "\n",
    "for unitName in unitList:\n",
    "    unit = population[unitName]\n",
    "    \n",
    "    print(unitName)\n",
    "\n",
    "    for alley in range(1,18):\n",
    "        \n",
    "        for texture in ['A', 'B', 'C']:\n",
    "            \n",
    "            visit_spikes = np.empty((0,3))\n",
    "            visit_occs = np.empty((0,3))\n",
    "            added_ratemap = False # toggle if any rms have passed and added their spikes. IDK how many spikes that is so i cant just check shape\n",
    "            c = 0\n",
    "            for visit in unit.alleys[alley]:\n",
    "                if visit['metadata']['stimulus'][0] == texture:\n",
    "                    ratemap = visit['ratemap1d']\n",
    "                    if ratemap[ratemap>firing_thresh].shape[0] >= bin_num_thresh:   #key line - this is the exclusion\n",
    "                    #if visit['spikes'].shape[0] > spike_thresh:\n",
    "                        visit_spikes = np.vstack((visit_spikes, visit['spikes']))\n",
    "                        visit_occs = np.vstack((visit_occs, visit['occs']))\n",
    "                        added_ratemap = True\n",
    "                        c+=1\n",
    "\n",
    "            if added_ratemap:\n",
    "                unit.linRMS[alley][texture] = unit.computeSingleRM(visit_spikes, visit_occs, alley, dim=1)\n",
    "            else:\n",
    "                unit.linRMS[alley][texture] = None\n",
    "                \n",
    "        # if any are none, delete the whole alley's data \n",
    "        if unit.linRMS[alley]['A'] is None or unit.linRMS[alley]['B'] is None or unit.linRMS[alley]['C'] is None:\n",
    "            for txt in ['A','B','C']:\n",
    "                unit.linRMS[alley][txt] = None\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture x Alley Conjunctive Decoding (using separate random forests at each alley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 1\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 2\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 3\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 4\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 5\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 6\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 7\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 8\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 9\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 10\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 11\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 12\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 13\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n",
      "iter 14\n",
      "alley 1\n",
      "alley 3\n",
      "alley 5\n",
      "alley 7\n",
      "alley 8\n",
      "alley 10\n",
      "alley 11\n",
      "alley 16\n",
      "alley 17\n"
     ]
    }
   ],
   "source": [
    "all_oobs, all_cvs = [], []\n",
    "\n",
    "ratemaps = {txt: np.empty((0, Def.singleAlleyBins[0]-1)) for txt in ['A', 'B', 'C']}\n",
    "\n",
    "for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "    for clustName, unit in population.items():\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            if type(rm) == np.ndarray:\n",
    "                ratemaps[stim] = np.vstack((ratemaps[stim], rm))\n",
    "for stim in ['A','B','C']:\n",
    "    ratemaps[stim][np.where(np.isnan(ratemaps[stim]))] = 0\n",
    "\n",
    "pop = np.vstack((ratemaps['A'], ratemaps['B'], ratemaps['C']))\n",
    "labels = ['A']*ratemaps['A'].shape[0] + ['B']*ratemaps['B'].shape[0] + ['C']*ratemaps['C'].shape[0]\n",
    "Y = np.asarray(labels)\n",
    "for r in range(15):\n",
    "    print(f\"iter {r}\")\n",
    "    oobs, cvs = [], []\n",
    "    \n",
    "    for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "        print(f\"alley {alley}\")\n",
    "        \n",
    "        ratemaps = {txt: np.empty((0, Def.singleAlleyBins[0]-1)) for txt in ['A', 'B', 'C']}\n",
    "        for clustName, unit in population.items():\n",
    "            for stim in ['A', 'B', 'C']:\n",
    "                rm = unit.linRMS[alley][stim]\n",
    "                if type(rm) == np.ndarray:\n",
    "                    ratemaps[stim] = np.vstack((ratemaps[stim], rm))\n",
    "        for stim in ['A','B','C']:\n",
    "            ratemaps[stim][np.where(np.isnan(ratemaps[stim]))] = 0\n",
    "            \n",
    "        pop = np.vstack((ratemaps['A'], ratemaps['B'], ratemaps['C']))\n",
    "        labels = ['A']*ratemaps['A'].shape[0] + ['B']*ratemaps['B'].shape[0] + ['C']*ratemaps['C'].shape[0]\n",
    "        if pop.shape[0] > 0:\n",
    "            X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "            Y = np.asarray(labels)\n",
    "\n",
    "            clf = RandomForestClassifier(n_estimators=700, oob_score=True)\n",
    "            clf2 = RandomForestClassifier(n_estimators=700, oob_score=False)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,random_state=0)\n",
    "            clf2.fit(Xtrain,ytrain)\n",
    "            ypred = clf2.predict(Xtest)\n",
    "            cv = np.where(ypred==ytest)[0].shape[0]/len(ypred)\n",
    "            clf.fit(X,Y)\n",
    "            \n",
    "            cvs.append(np.mean(cv))\n",
    "            clf.fit(X,Y)\n",
    "            oobs.append(clf.oob_score_)\n",
    "    all_oobs.append(np.mean(oobs))\n",
    "    all_cvs.append(np.mean(cvs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),\n",
       " <a list of 6 Text yticklabel objects>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.bar(1, np.mean(all_cvs), width=0.2, color='cornflowerblue', yerr=np.std(all_cvs), alpha=0.6, align='edge')\n",
    "plt.scatter([1]*len(all_cvs), all_cvs, c='k', alpha=0.3)\n",
    "plt.bar(1.5, np.mean(all_oobs), width=0.2, color='firebrick', yerr=np.std(all_oobs), alpha=0.6)\n",
    "plt.scatter([1.5]*len(all_oobs), all_oobs, c='k', alpha=0.3)\n",
    "plt.xticks([1, 1.5], [\"Cross validation\", \"OOB\"], fontsize=22)\n",
    "plt.ylabel(\"Performance\", fontsize=32)\n",
    "plt.yticks(fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1, b2 = 1,1.5\n",
    "\n",
    "titles = [\"Alley Alone\", \"Texture Alone\", \"Texture within Alley\", \"All Alley / Texture Combos\"]\n",
    "fig, ax = plt.subplots(2,2)\n",
    "for i,c,o,n,t in zip([0,1,2,3],[cvsAlley, cvsTxt, all_cvs, cvsCombo], [oobsAlley, oobsTxt, all_oobs, oobsCombo],[1/9, 1/3, 1/3, 1/27], titles):\n",
    "    fig.axes[i].bar(b1, np.mean(c), width=0.2, color='cornflowerblue', yerr=np.std(c), alpha=0.6, align='edge')\n",
    "    fig.axes[i].bar(b2, np.mean(o), width=0.2, color='firebrick', yerr=np.std(o), alpha=0.6, align='edge')\n",
    "    \n",
    "    fig.axes[i].scatter([b1]*len(c), c, c='k', alpha=0.3)\n",
    "    fig.axes[i].scatter([b2]*len(o), o, c='k', alpha=0.3)\n",
    "    \n",
    "    fig.axes[i].set_xticks([b1,b2])\n",
    "    fig.axes[i].set_xticklabels([\"Cross-Validation\", \"OOB\"], fontsize=22)\n",
    "    fig.axes[i].tick_params(labelsize=22)\n",
    "    fig.axes[i].set_ylabel(\"Performance\", fontsize=32)\n",
    "    \n",
    "    fig.axes[i].set_title(t, fontsize=22)\n",
    "    \n",
    "    xlims = fig.axes[i].get_xlim()\n",
    "    fig.axes[i].plot([xlims[0], xlims[1]], [n, n], 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style paraiso-dark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Alone Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# txt alone\n",
    "ratemaps = {txt: np.empty((0, Def.singleAlleyBins[0]-1)) for txt in ['A', 'B', 'C']}\n",
    "\n",
    "for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "    for clustName, unit in population.items():\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            if type(rm) == np.ndarray:\n",
    "                ratemaps[stim] = np.vstack((ratemaps[stim], rm))\n",
    "    for stim in ['A','B','C']:\n",
    "        ratemaps[stim][np.where(np.isnan(ratemaps[stim]))] = 0\n",
    "\n",
    "pop = np.vstack((ratemaps['A'], ratemaps['B'], ratemaps['C']))\n",
    "labels = ['A']*ratemaps['A'].shape[0] + ['B']*ratemaps['B'].shape[0] + ['C']*ratemaps['C'].shape[0]\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)\n",
    "    \n",
    "oobsTxt,cvsTxt = [], []   \n",
    "\n",
    "for i in range(15):\n",
    "    clf = RandomForestClassifier(n_estimators=700, oob_score=True)\n",
    "    clf2 = RandomForestClassifier(n_estimators=700, oob_score=False)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,random_state=0)\n",
    "    clf2.fit(Xtrain,ytrain)\n",
    "    ypred = clf2.predict(Xtest)\n",
    "    cvs = np.where(ypred==ytest)[0].shape[0]/len(ypred)\n",
    "    clf.fit(X,Y)\n",
    "    oobsTxt.append(clf.oob_score_)\n",
    "    cvsTxt.append(np.mean(cvs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(1, np.mean(cvsTxt), color='cornflowerblue', yerr=np.std(cvsTxt), alpha=0.6)\n",
    "plt.scatter([1]*len(cvsTxt), cvsTxt, c='k', alpha=0.3)\n",
    "plt.bar(2, np.mean(oobsTxt), color='firebrick', yerr=np.std(oobsTxt), alpha=0.6)\n",
    "plt.scatter([2]*len(oobsTxt), oobsTxt, c='k', alpha=0.3)\n",
    "plt.xticks([1,2,3], [\"Accuracy\", \"OOB\"], fontsize=22)\n",
    "plt.ylabel(\"Score\", fontsize=32)\n",
    "plt.title(\"Texture Alone Classification\", fontsize=28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alley Alone Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alley alone\n",
    "ratemaps = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [1,3,5,7,8,10,11,16,17]}\n",
    "\n",
    "for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "    for clustName, unit in population.items():\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            if type(rm) == np.ndarray:\n",
    "                ratemaps[alley] = np.vstack((ratemaps[alley], rm))\n",
    "    for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "        ratemaps[alley][np.where(np.isnan(ratemaps[alley]))] = 0\n",
    "\n",
    "pop = np.vstack(([ratemaps[i] for i in [1,3,5,7,8,10,11,16,17]]))\n",
    "labels = [[i]*ratemaps[i].shape[0] for i in [1,3,5,7,8,10,11,16,17]]\n",
    "labels = np.asarray([item for sublist in labels for item in sublist])\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)\n",
    "cvsAlley, oobsAlley = [], []  \n",
    "#cvs = cross_val_score(clf, X, Y, cv=5)\n",
    "for i in range(10):\n",
    "    clf = RandomForestClassifier(n_estimators=700, oob_score=True)\n",
    "    clf2 = RandomForestClassifier(n_estimators=700, oob_score=False)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,random_state=0)\n",
    "    clf2.fit(Xtrain,ytrain)\n",
    "    ypred = clf2.predict(Xtest)\n",
    "    cvs = np.where(ypred==ytest)[0].shape[0]/len(ypred)\n",
    "    clf.fit(X,Y)\n",
    "    cvsAlley.append(np.mean(cvs))\n",
    "    oobsAlley.append(clf.oob_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(1, np.mean(cvsAlley), color='cornflowerblue', yerr=np.std(cvsAlley), alpha=0.6)\n",
    "plt.scatter([1]*len(cvsAlley), cvsAlley, c='k', alpha=0.3)\n",
    "plt.bar(2, np.mean(oobsAlley), color='firebrick', yerr=np.std(oobsAlley), alpha=0.6)\n",
    "plt.scatter([2]*len(oobsAlley), oobsAlley, c='k', alpha=0.3)\n",
    "plt.xticks([1,2], [\"Cross Validation\", \"OOB\"], fontsize=22)\n",
    "plt.ylabel(\"Score\", fontsize=32)\n",
    "plt.title(\"Alley Alone Classification\", fontsize=24)\n",
    "plt.yticks(fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## All condition decoding (all texture x alley combinations - 51 label decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratemaps = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "labels = []\n",
    "popidx = []\n",
    "idx = 0\n",
    "# accs, shuffs, oobs = [], [], []\n",
    "cvsCombo, oobsCombo = [], []\n",
    "for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "    for clustName, unit in population.items():\n",
    "        popidx.append(idx)\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            if type(rm) == np.ndarray:\n",
    "                ratemaps[alley] = np.vstack((ratemaps[alley], rm))\n",
    "                labels.append(f\"{alley}{stim}\")\n",
    "                idx += 1\n",
    "    for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "        ratemaps[alley][np.where(np.isnan(ratemaps[alley]))] = 0\n",
    "        \n",
    "pop = np.vstack(([ratemaps[i] for i in [16,17,3,1,5,7,8,10,11]]))\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)\n",
    "accsCombo = []\n",
    "oobsCombo = []\n",
    "shuffsCombo = []\n",
    "clf = RandomForestClassifier(n_estimators=700, oob_score=True)\n",
    "for i in range(10):\n",
    "    clf = RandomForestClassifier(n_estimators=700, oob_score=True)\n",
    "    clf2 = RandomForestClassifier(n_estimators=1000, oob_score=False)\n",
    "\n",
    "    #cvs = cross_val_score(clf, X, Y, cv=kf)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,random_state=0)\n",
    "    clf2.fit(Xtrain,ytrain)\n",
    "    ypred = clf2.predict(Xtest)\n",
    "    cvs = np.where(ypred==ytest)[0].shape[0]/len(ypred)\n",
    "    clf.fit(X,Y)\n",
    "    cvsCombo.append(np.mean(cvs))\n",
    "    oobsCombo.append(clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(1, np.mean(cvsCombo), color='cornflowerblue', yerr=np.std(cvsCombo), alpha=0.6)\n",
    "plt.scatter([1]*len(cvsCombo), cvsCombo, c='k', alpha=0.3)\n",
    "plt.bar(2, np.mean(oobsCombo), color='firebrick', yerr=np.std(oobsCombo), alpha=0.6)\n",
    "plt.scatter([2]*len(oobsCombo), oobsCombo, c='k', alpha=0.3)\n",
    "plt.xticks([1,2,3], [\"Accuracy\", \"OOB\"], fontsize=22)\n",
    "plt.ylabel(\"Score\", fontsize=32)\n",
    "plt.title(\"Classification of All Alley/Texure Combinations\", fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dropout Analysis\n",
    "### Want to know how performance of stimulus decoding and position decoding are affected by dropping out different Units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping out xxx\n",
      "Attempting texture decoding\n",
      "Attempting alley decoding\n"
     ]
    }
   ],
   "source": [
    "# txt alone\n",
    "\n",
    "# alley_scores = []\n",
    "# txt_scores = []\n",
    "for clust in ['xxx']:\n",
    "    print(f\"Dropping out {clust}\")\n",
    "    \n",
    "    ratemaps = {txt: np.empty((0, 30)) for txt in ['A', 'B', 'C']}\n",
    "    \n",
    "    print(\"Attempting texture decoding\")\n",
    "    \n",
    "    for alley in range(1,18):\n",
    "        for clustName, unit in population.items():\n",
    "            if clustName != clust:\n",
    "                for stim in ['A', 'B', 'C']:\n",
    "                    rm = unit.linRMS[alley][stim]\n",
    "                    if type(rm) == np.ndarray:\n",
    "                        ratemaps[stim] = np.vstack((ratemaps[stim], rm))\n",
    "        for stim in ['A','B','C']:\n",
    "            ratemaps[stim][np.where(np.isnan(ratemaps[stim]))] = 0\n",
    "\n",
    "        pop = np.vstack((ratemaps['A'], ratemaps['B'], ratemaps['C']))\n",
    "        labels = ['A']*ratemaps['A'].shape[0] + ['B']*ratemaps['B'].shape[0] + ['C']*ratemaps['C'].shape[0]\n",
    "        X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "        Y = np.asarray(labels)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=700, oob_score=True)\n",
    "    cvs_alley = cross_val_score(clf, X, Y, cv=10)\n",
    "    #txt_scores.append(cvs)\n",
    "\n",
    "\n",
    "    # alley alone\n",
    "    ratemaps = {alley: np.empty((0, 30)) for alley in range(1,18)}\n",
    "    \n",
    "    print(\"Attempting alley decoding\")\n",
    "\n",
    "    for alley in range(1,18):\n",
    "        for clustName, unit in population.items():\n",
    "            if clustName != clust:\n",
    "                for stim in ['A', 'B', 'C']:\n",
    "                    rm = unit.linRMS[alley][stim]\n",
    "                    if type(rm) == np.ndarray:\n",
    "                        ratemaps[alley] = np.vstack((ratemaps[alley], rm))\n",
    "        for alley in range(1,18):\n",
    "            ratemaps[alley][np.where(np.isnan(ratemaps[alley]))] = 0\n",
    "\n",
    "        pop = np.vstack(([ratemaps[i] for i in range(1,18)]))\n",
    "        labels = [[i]*ratemaps[i].shape[0] for i in range(1,18)]\n",
    "        labels = np.asarray([item for sublist in labels for item in sublist])\n",
    "        X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "        Y = np.asarray(labels)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=200, oob_score=True)\n",
    "    clf.fit(X,Y)\n",
    "    cvs_txt = cross_val_score(clf, X, Y, cv=10)\n",
    "    #alley_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alley_means  = np.asarray([np.mean(i) for i in alley_scores])\n",
    "alley_errs = np.asarray([sem(i) for i in alley_scores])\n",
    "\n",
    "txt_means  = np.asarray([np.mean(i) for i in txt_scores])\n",
    "txt_errs = np.asarray([sem(i) for i in txt_scores])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d03d61f048>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(alley_means, \"g-^\")\n",
    "#plt.fill_between(range(len(alley_means)), alley_means-alley_errs, alley_means+alley_errs, color=\"g\", alpha=0.5)\n",
    "\n",
    "plt.plot(txt_means, \"b-^\")\n",
    "#plt.fill_between(range(len(txt_means)), txt_means-txt_errs, txt_means+txt_errs, color=\"b\", alpha=0.5)\n",
    "\n",
    "plt.plot([np.mean(alley_means)]*len(alley_means),'g')\n",
    "plt.plot([np.mean(txt_means)]*len(txt_means),'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Txt and Alley Pop Matrices for Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratemaps_txt = {txt: np.empty((0, 30)) for txt in ['A', 'B', 'C']}\n",
    "for alley in range(1,18):\n",
    "    for clustName, unit in population.items():\n",
    "        if clustName != clust:\n",
    "            for stim in ['A', 'B', 'C']:\n",
    "                rm = unit.linRMS[alley][stim]\n",
    "                if type(rm) == np.ndarray:\n",
    "                    ratemaps_txt[stim] = np.vstack((ratemaps_txt[stim], rm))\n",
    "    for stim in ['A','B','C']:\n",
    "        ratemaps_txt[stim][np.where(np.isnan(ratemaps_txt[stim]))] = 0\n",
    "\n",
    "    pop_txts = np.vstack((ratemaps_txt['A'], ratemaps_txt['B'], ratemaps_txt['C']))\n",
    "    labels_txts = ['A']*ratemaps_txt['A'].shape[0] + ['B']*ratemaps_txt['B'].shape[0] + ['C']*ratemaps_txt['C'].shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "ratemaps_alleys = {alley: np.empty((0, 30)) for alley in range(1,18)}\n",
    "for alley in range(1,18):\n",
    "    for clustName, unit in population.items():\n",
    "        if clustName != clust:\n",
    "            for stim in ['A', 'B', 'C']:\n",
    "                rm = unit.linRMS[alley][stim]\n",
    "                if type(rm) == np.ndarray:\n",
    "                    ratemaps_alleys[alley] = np.vstack((ratemaps_alleys[alley], rm))\n",
    "    for alley in range(1,18):\n",
    "        ratemaps_alleys[alley][np.where(np.isnan(ratemaps_alleys[alley]))] = 0\n",
    "\n",
    "    pop_alleys = np.vstack(([ratemaps_alleys[i] for i in range(1,18)]))\n",
    "    labels = [[i]*ratemaps_alleys[i].shape[0] for i in range(1,18)]\n",
    "    labels_alleys = np.asarray([item for sublist in labels for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frs = []\n",
    "for entry in pop_alleys:\n",
    "    entry = np.ndarray.flatten(entry)\n",
    "    frs.extend(entry)\n",
    "frs = np.asarray(frs)\n",
    "frs = frs[np.isfinite(frs)]\n",
    "h,b = np.histogram(frs, bins=100)\n",
    "frcum = np.cumsum(h)\n",
    "propExp = np.asarray([i/h.sum() for i in frcum])\n",
    "try:\n",
    "    thresh = np.where(propExp < cutoff)[0][-1]\n",
    "except:\n",
    "    thresh = np.where(b == np.median(b))\n",
    "_max = b[thresh]*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "for i,txt in zip([0,1,2],['A','B','C']):\n",
    "    sortedArray = np.sort(ratemaps_txt[txt],axis=0)\n",
    "    ax[i].imshow(np.sort(sortedArray), aspect='auto', interpolation='None',vmax=_max, origin='lower')\n",
    "    ax[i].set_title(txt)\n",
    "    ax[i].set_ylim([sortedArray.shape[0], sortedArray.shape[0]-25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Distributed Texture Info: Binned test stats across pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT10\\cl-maze1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:139: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:139: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:309: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT10\\cl-maze1.2\n",
      "TT10\\cl-maze1.3\n",
      "TT10\\cl-maze1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:305: RuntimeWarning: invalid value encountered in multiply\n",
      "  W=0*U.copy()+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT10\\cl-maze1.5\n",
      "TT10\\cl-maze1.6\n",
      "TT10\\cl-maze1.7\n",
      "TT13\\cl-maze1.1\n",
      "TT13\\cl-maze1.2\n",
      "TT13\\cl-maze1.3\n",
      "TT15\\cl-maze1.1\n",
      "TT15\\cl-maze1.2\n",
      "TT15\\cl-maze1.3\n",
      "TT15\\cl-maze1.4\n",
      "TT15\\cl-maze1.5\n",
      "TT4\\cl-maze1.1\n",
      "TT4\\cl-maze1.10\n",
      "TT4\\cl-maze1.11\n",
      "TT4\\cl-maze1.12\n",
      "TT4\\cl-maze1.2\n",
      "TT4\\cl-maze1.3\n",
      "TT4\\cl-maze1.4\n",
      "TT4\\cl-maze1.5\n",
      "TT4\\cl-maze1.6\n",
      "TT4\\cl-maze1.7\n",
      "TT4\\cl-maze1.8\n",
      "TT4\\cl-maze1.9\n",
      "TT6\\cl-maze1.1\n",
      "TT6\\cl-maze1.2\n",
      "TT7\\cl-maze1.1\n",
      "TT7\\cl-maze1.2\n",
      "TT7\\cl-maze1.3\n"
     ]
    }
   ],
   "source": [
    "exp = \"RFD5\"\n",
    "population = {}\n",
    "dayCode = f\"R765{exp}\\\\\"\n",
    "figpath = f\"C:\\\\Users\\\\whockei1\\\\Google Drive\\\\KnierimLab\\\\Ratterdam\\\\Figures\\\\R765{exp}\\\\\"\n",
    "datafile = f'E:\\\\Ratterdam\\\\R765\\\\R765{exp}\\\\'\n",
    "behav = core.BehavioralData(datafile, exp, velocity_filter_thresh)\n",
    "ts, position, alleyTracking, alleyVisits,  txtVisits = behav.loadData()\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            print(clustname)\n",
    "            unit = core.UnitData(clustname, datafile, exp, alleyBounds, alleyVisits, txtVisits, position, ts)\n",
    "            unit.loadData_raw()\n",
    "            population[unit.name] = unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2026b606240>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitList = list(population.keys())\n",
    "unit = population[unitList[9]]\n",
    "plt.scatter(unit.spikes[:,1], unit.spikes[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcOverallTestStat(linX, linY):\n",
    "    \"\"\"\n",
    "    Given two test stats from all visits of a txt\n",
    "    Take their binwise difference and return it\n",
    "    \"\"\"\n",
    "    if type(linX) is np.ndarray and type(linY) is np.ndarray:\n",
    "        d = linX - linY\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "banned = ['null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allTestStatDiffs = np.empty((0))\n",
    "allNullDiffs = np.empty((0))\n",
    "minTestStatDiffs = np.empty((0))\n",
    "for unit in population.values():\n",
    "    for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "        pairs = [\"AB\", \"BC\", \"CA\"]\n",
    "        for pair in pairs:\n",
    "            x,y = unit.linRMS[alley][pair[0]], unit.linRMS[alley][pair[1]]\n",
    "            diffTrace = calcOverallTestStat(x, y)\n",
    "             \n",
    "            labels = Perm.getLabels(unit, alley)\n",
    "            null = Perm.genSingleNullStat(unit, alley, pair[0], pair[1], labels)\n",
    "                \n",
    "            if diffTrace is not None:\n",
    "                allTestStatDiffs = np.concatenate((allTestStatDiffs, np.abs(diffTrace)))\n",
    "                allNullDiffs     = np.concatenate((allNullDiffs, np.abs(null)))\n",
    "                \n",
    "            if unit.name not in banned and diffTrace is not None:\n",
    "                minTestStatDiffs = np.concatenate((minTestStatDiffs, np.abs(diffTrace)))\n",
    "                \n",
    "\n",
    "allTestStatDiffs = allTestStatDiffs[np.isfinite(allTestStatDiffs)]\n",
    "allNullDiffs = allNullDiffs[np.isfinite(allNullDiffs)]\n",
    "minTestStatDiffs = minTestStatDiffs[np.isfinite(minTestStatDiffs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(allTestStatDiffs, bins=500,color='g',alpha=0.4)\n",
    "_ = plt.hist(allNullDiffs, bins=500,color='k',alpha=0.4)\n",
    "_ = plt.hist(minTestStatDiffs, bins=500,color='r',alpha=0.4)\n",
    "\n",
    "for d,c in zip([allTestStatDiffs, allNullDiffs, minTestStatDiffs],['g','k','r']):\n",
    "    plt.vlines(np.percentile(d,95), 0, 10000, f\"{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of abs. test statistic values across population bins')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.xlabel(\"Test Statistic Size\", fontsize=14)\n",
    "plt.ylabel(\"Number of Bins\", fontsize=14)\n",
    "plt.title(\"Distribution of abs. test statistic values across population bins\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Support Vector Machines - Beltway Data - Decoding different types of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frThresh=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alley and Texture - 27 label decoding\n",
    "\n",
    "ratemaps = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "labels = []\n",
    "popidx = []\n",
    "idx = 0\n",
    "\n",
    "target = 'Alley/Texture'\n",
    "# accs, shuffs, oobs = [], [], []\n",
    "for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "    for clustName, unit in population.items():\n",
    "        popidx.append(idx)\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            \n",
    "            if type(rm) == np.ndarray and np.nanmax(rm)>frThresh:\n",
    "                ratemaps[alley] = np.vstack((ratemaps[alley], rm))\n",
    "                labels.append(f\"{alley}{stim}\")\n",
    "                idx += 1\n",
    "    for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "        ratemaps[alley][np.where(np.isnan(ratemaps[alley]))] = 0\n",
    "        \n",
    "pop = np.vstack(([ratemaps[i] for i in [16,17,3,1,5,7,8,10,11]]))\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)\n",
    "targetclasses = list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alley alone\n",
    "target = 'Alley'\n",
    "targetclasses = [16,17,3,1,5,7,8,10,11]\n",
    "ratemaps = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [1,3,5,7,8,10,11,16,17]}\n",
    "\n",
    "for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "    for clustName, unit in population.items():\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                ratemaps[alley] = np.vstack((ratemaps[alley], rm))\n",
    "    for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "        ratemaps[alley][np.where(np.isnan(ratemaps[alley]))] = 0\n",
    "\n",
    "pop = np.vstack(([ratemaps[i] for i in [1,3,5,7,8,10,11,16,17]]))\n",
    "labels = [[i]*ratemaps[i].shape[0] for i in [1,3,5,7,8,10,11,16,17]]\n",
    "labels = np.asarray([item for sublist in labels for item in sublist])\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# texture alone\n",
    "target = 'Texture'\n",
    "targetclasses = ['A','B','C']\n",
    "ratemaps = {txt: np.empty((0, Def.singleAlleyBins[0]-1)) for txt in ['A', 'B', 'C']}\n",
    "\n",
    "for alley in [1,3,5,7,8,10,11,16,17]:\n",
    "    for clustName, unit in population.items():\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            if type(rm) == np.ndarray and np.nanmax(rm)>frThresh:\n",
    "                ratemaps[stim] = np.vstack((ratemaps[stim], rm))\n",
    "    for stim in ['A','B','C']:\n",
    "        ratemaps[stim][np.where(np.isnan(ratemaps[stim]))] = 0\n",
    "\n",
    "pop = np.vstack((ratemaps['A'], ratemaps['B'], ratemaps['C']))\n",
    "labels = ['A']*ratemaps['A'].shape[0] + ['B']*ratemaps['B'].shape[0] + ['C']*ratemaps['C'].shape[0]\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_epoch(val,size):\n",
    "    \"\"\"hardcode that session is divided\n",
    "    into thirds. find in which third the trial is in\"\"\"\n",
    "    propthrusess = val/size\n",
    "    if propthrusess < 0.5:\n",
    "        epoch = 0\n",
    "    elif propthrusess >= 0.5:\n",
    "        epoch = 1\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alley/txt/epoch\n",
    "target = \"AlleyXTextureXEpoch\"\n",
    "ratemaps = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "labels = []\n",
    "for clustname, unit in population.items():\n",
    "    for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "        for i,visit in enumerate(unit.alleys[alley]):\n",
    "            rm = visit['ratemap1d']\n",
    "            if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                ratemaps = np.vstack((ratemaps, rm))\n",
    "                epoch = compute_epoch(i,len(unit.alleys[alley]))\n",
    "                labels.append(f\"{alley}{visit['metadata']['stimulus']}{epoch}\")\n",
    "\n",
    "ratemaps = np.nan_to_num(ratemaps)\n",
    "        \n",
    "#X = preprocessing.StandardScaler().fit_transform(ratemaps)\n",
    "X = preprocessing.Imputer().fit_transform(ratemaps)\n",
    "Y = np.asarray(labels)\n",
    "targetclasses = list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alley/epoch\n",
    "target = \"AlleyXEpoch\"\n",
    "ratemaps = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "labels = []\n",
    "for clustname, unit in population.items():\n",
    "    for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "        for i,visit in enumerate(unit.alleys[alley]):\n",
    "            rm = visit['ratemap1d']\n",
    "            if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                ratemaps = np.vstack((ratemaps, rm))\n",
    "                epoch = compute_epoch(i,len(unit.alleys[alley]))\n",
    "                labels.append(f\"{alley}{epoch}\")\n",
    "\n",
    "ratemaps = np.nan_to_num(ratemaps)\n",
    "        \n",
    "#X = preprocessing.StandardScaler().fit_transform(ratemaps)\n",
    "X = preprocessing.Imputer().fit_transform(ratemaps)\n",
    "Y = np.asarray(labels)\n",
    "targetclasses = list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#txt/epoch\n",
    "target = \"TextureXEpoch\"\n",
    "ratemaps = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "labels = []\n",
    "for clustname, unit in population.items():\n",
    "    for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "        for i,visit in enumerate(unit.alleys[alley]):\n",
    "            rm = visit['ratemap1d']\n",
    "            if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                ratemaps = np.vstack((ratemaps, rm))\n",
    "                epoch = compute_epoch(i,len(unit.alleys[alley]))\n",
    "                labels.append(f\"{visit['metadata']['stimulus']}{epoch}\")\n",
    "\n",
    "ratemaps = np.nan_to_num(ratemaps)\n",
    "        \n",
    "#X = preprocessing.StandardScaler().fit_transform(ratemaps)\n",
    "X = preprocessing.Imputer().fit_transform(ratemaps)\n",
    "Y = np.asarray(labels)\n",
    "targetclasses = list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# splitting cells into train/test\n",
    "precisions, recalls, f1s, accuracies = [], [], [], []\n",
    "precisions_shuff, recalls_shuff, f1s_shuff, accuracies_shuff = [], [], [], []\n",
    "\n",
    "avgType = 'macro'\n",
    "\n",
    "target = 'AlleyXTexture'\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "    ratemaps_train = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "    ratemaps_test = np.empty((0, Def.singleAlleyBins[0]-1))\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "\n",
    "    unitnames = list(population.keys())\n",
    "\n",
    "    np.random.shuffle(unitnames) # KEY: HERE IS WHERE YOU SHUFFLE \n",
    "\n",
    "    poptrain = {name: population[name] for name in unitnames[:22]}\n",
    "    poptest = {name: population[name] for name in unitnames[22:]}\n",
    "\n",
    "    #create training set\n",
    "    for clustname, unit in poptrain.items():\n",
    "        for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "            for stim in ['A','B','C']:\n",
    "                rm = unit.linRMS[alley][stim]\n",
    "                if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                    ratemaps_train = np.vstack((ratemaps_train, rm))\n",
    "                    if target == 'Alley':\n",
    "                        labels_train.append(f\"{alley}\")\n",
    "                    elif target == 'Texture':\n",
    "                        labels_train.append(f\"{stim}\")\n",
    "                    elif target == 'AlleyXTexture':\n",
    "                        labels_train.append(f\"{alley}{stim}\")\n",
    "                        \n",
    "    \n",
    "    ratemaps_train[np.where(np.isnan(ratemaps_train))] = 0\n",
    "    ratemaps_train = np.nan_to_num(ratemaps_train)\n",
    "    Xtrain = preprocessing.StandardScaler().fit_transform(ratemaps_train)\n",
    "    ytrain = np.asarray(labels_train)\n",
    "\n",
    "    #create test set\n",
    "    for clustname, unit in poptest.items():\n",
    "        for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "            for stim in ['A','B','C']:\n",
    "                rm = unit.linRMS[alley][stim]\n",
    "                if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                    ratemaps_test = np.vstack((ratemaps_test, rm))\n",
    "                    if target == 'Alley':\n",
    "                        labels_test.append(f\"{alley}\")\n",
    "                    elif target == 'Texture':\n",
    "                        labels_test.append(f\"{stim}\")\n",
    "                    elif target == 'AlleyXTexture':\n",
    "                        labels_test.append(f\"{alley}{stim}\")\n",
    "                        \n",
    "\n",
    "    ratemaps_test[np.where(np.isnan(ratemaps_test))] = 0\n",
    "    ratemaps_test = np.nan_to_num(ratemaps_test)\n",
    "    Xtest = preprocessing.StandardScaler().fit_transform(ratemaps_test)\n",
    "    ytest = np.asarray(labels_test)\n",
    "\n",
    "    targetclasses = list(set(labels_train) | set(labels_test))\n",
    "\n",
    "    _ = np.random.shuffle(labels_train)\n",
    "    \n",
    "    svc = SVC(C=1e7, gamma=0.01,kernel='rbf')\n",
    "    svc.fit(Xtrain,ytrain)\n",
    "    yfit = svc.predict(Xtest)\n",
    "    \n",
    "    svc_shuffle = SVC(C=1e7, gamma=0.01, kernel='rbf')\n",
    "    svc_shuffle.fit(Xtrain,labels_train) # it has been shuffled in place\n",
    "    yfit_shuff = svc_shuffle.predict(Xtest)\n",
    "\n",
    "    \n",
    "    \n",
    "    p = precision_score(ytest, yfit, average=avgType)\n",
    "    r = recall_score(ytest, yfit, average=avgType)\n",
    "    f1 = f1_score(ytest, yfit, average=avgType)\n",
    "    acc = accuracy_score(ytest,yfit)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f1)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    pshuff = precision_score(ytest, yfit_shuff, average=avgType)\n",
    "    rshuff = recall_score(ytest, yfit_shuff, average=avgType)\n",
    "    f1shuff = f1_score(ytest, yfit_shuff, average=avgType)\n",
    "    accshuff = accuracy_score(ytest,yfit_shuff)\n",
    "    precisions_shuff.append(pshuff)\n",
    "    recalls_shuff.append(rshuff)\n",
    "    f1s_shuff.append(f1shuff)\n",
    "    accuracies_shuff.append(accshuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def condense_epochs(ratemaps, labels):\n",
    "    \"\"\"ratemaps is dict w keys being alleys and values\n",
    "    being a stack of linear ratemaps. labels is array stack\n",
    "    with target label for each ratemap if the dict values\n",
    "    were stacked in one big array in order of beltway alleys\n",
    "    ie. [16,17,1,5,7,8,10,11]\"\"\"\n",
    "    arrstack = np.vstack(([ratemaps[i] for i in [16,17,3,1,5,7,8,10,11]]))\n",
    "    condensed_ratemaps = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "    arrlb = [(arr, lab) for arr,lab in zip(arrstack,labels)]\n",
    "    arrlb = sorted(arrlb, key=lambda x: x[1])\n",
    "    for groupID, rows in groupby(arrlb, key = itemgetter(1)):\n",
    "        condensed_ratemaps[group] = np.ma.masked_invalid(rows).mean(axis=0)\n",
    "    \n",
    "    return condensed_ratemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 6 should be equal to 7, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1cf376ac5d90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0myfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0msvc_shuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \"\"\"\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    457\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    458\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 6 should be equal to 7, the number of features at training time"
     ]
    }
   ],
   "source": [
    "# splitting cells into train/test FOR EPOCH STUFF WHICH IS TRIAL BASED \n",
    "precisions, recalls, f1s, accuracies = [], [], [], []\n",
    "precisions_shuff, recalls_shuff, f1s_shuff, accuracies_shuff = [], [], [], []\n",
    "\n",
    "avgType = 'macro'\n",
    "\n",
    "target = 'AlleyXEpoch'\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "    ratemaps_train = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "    ratemaps_test = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "\n",
    "    unitnames = list(population.keys())\n",
    "\n",
    "    np.random.shuffle(unitnames) # KEY: HERE IS WHERE YOU SHUFFLE \n",
    "\n",
    "    poptrain = {name: population[name] for name in unitnames[:22]}\n",
    "    poptest = {name: population[name] for name in unitnames[22:]}\n",
    "\n",
    "    #train\n",
    "    for clustname, unit in poptrain.items():\n",
    "        for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "            ratemaps_temp = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "            labels_temp = []\n",
    "            for i,visit in enumerate(unit.alleys[alley]):\n",
    "                rm = visit['ratemap1d']\n",
    "                if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                    ratemaps_temp[alley] = np.vstack((ratemaps_temp[alley], rm))\n",
    "                    epoch = compute_epoch(i,len(unit.alleys[alley]))\n",
    "                    if target == 'AlleyXEpoch':\n",
    "                        labels_temp.append(f\"{alley}{epoch}\")\n",
    "                    elif target == 'TextureXEpoch':\n",
    "                        labels_temp.append(f\"{visit['metadata']['stimulus']}{epoch}\")\n",
    "                    elif target == 'AlleyXTextureXEpoch':\n",
    "                        labels_temp.append(f\"{alley}{visit['metadata']['stimulus']}{epoch}\")\n",
    "    \n",
    "            ratemaps_train[alley] = np.vstack((ratemaps_train[alley],npcondense_epochs(ratemaps_temp, labels_temp)))\n",
    "            labels_train.extend(labels_temp)\n",
    "                        \n",
    "        for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "            ratemaps_train[alley][np.where(np.isnan(ratemaps_train[alley]))] = 0\n",
    "\n",
    "    poptrain = np.vstack(([ratemaps_train[i] for i in [16,17,3,1,5,7,8,10,11]]))\n",
    "    Xtrain = preprocessing.Imputer().fit_transform(poptrain)\n",
    "    ytrain = np.asarray(labels_train)\n",
    "\n",
    "    #test\n",
    "    for clustname, unit in poptest.items():\n",
    "        for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "            for i,visit in enumerate(unit.alleys[alley]):\n",
    "                rm = visit['ratemap1d']\n",
    "                if type(rm) == np.ndarray and np.nanmax(rm) > frThresh:\n",
    "                    ratemaps_test[alley] = np.vstack((ratemaps_test[alley], rm))\n",
    "                    epoch = compute_epoch(i,len(unit.alleys[alley]))\n",
    "                    if target == 'AlleyXEpoch':\n",
    "                        labels_test.append(f\"{alley}{epoch}\")\n",
    "                    elif target == 'TextureXEpoch':\n",
    "                        labels_test.append(f\"{visit['metadata']['stimulus']}{epoch}\")\n",
    "                    elif target == 'AlleyXTextureXEpoch':\n",
    "                        labels_test.append(f\"{alley}{visit['metadata']['stimulus']}{epoch}\")\n",
    "                        \n",
    "        for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "            ratemaps_test[alley][np.where(np.isnan(ratemaps_test[alley]))] = 0\n",
    "\n",
    "    poptest = np.vstack(([ratemaps_test[i] for i in [16,17,3,1,5,7,8,10,11]]))\n",
    "    Xtest = preprocessing.Imputer().fit_transform(poptest)\n",
    "    ytest = np.asarray(labels_test)\n",
    "\n",
    "    targetclasses = list(set(labels_train) | set(labels_test))\n",
    "\n",
    "    _ = np.random.shuffle(labels_train)\n",
    "    \n",
    "    svc = SVC(C=1e7, gamma=0.01,kernel='rbf')\n",
    "    svc.fit(Xtrain,ytrain)\n",
    "    yfit = svc.predict(Xtest)\n",
    "    \n",
    "    svc_shuffle = SVC(C=1e7, gamma=0.01, kernel='rbf')\n",
    "    svc_shuffle.fit(Xtrain,labels_train) # it has been shuffled in place\n",
    "    yfit_shuff = svc_shuffle.predict(Xtest)\n",
    "\n",
    "    \n",
    "    \n",
    "    p = precision_score(ytest, yfit, average=avgType)\n",
    "    r = recall_score(ytest, yfit, average=avgType)\n",
    "    f1 = f1_score(ytest, yfit, average=avgType)\n",
    "    acc = accuracy_score(ytest,yfit)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f1)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    pshuff = precision_score(ytest, yfit_shuff, average=avgType)\n",
    "    rshuff = recall_score(ytest, yfit_shuff, average=avgType)\n",
    "    f1shuff = f1_score(ytest, yfit_shuff, average=avgType)\n",
    "    accshuff = accuracy_score(ytest,yfit_shuff)\n",
    "    precisions_shuff.append(pshuff)\n",
    "    recalls_shuff.append(rshuff)\n",
    "    f1s_shuff.append(f1shuff)\n",
    "    accuracies_shuff.append(accshuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'AlleyXTexture')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "\n",
    "ax[0,0].hist(accuracies, color='b', alpha=0.7)\n",
    "ax[0,0].hist(accuracies_shuff, color='k', alpha=0.7)\n",
    "ax[0,0].vlines(np.mean(accuracies), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "ax[0,0].vlines(np.percentile(accuracies_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[0,0].set_title(\"Accuracy\")\n",
    "\n",
    "ax[0,1].hist(precisions, color='b', alpha=0.7)\n",
    "ax[0,1].hist(precisions_shuff, color='k', alpha=0.7)\n",
    "ax[0,1].vlines(np.mean(precisions), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "ax[0,1].vlines(np.percentile(precisions_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[0,1].set_title(\"Precision\")\n",
    "\n",
    "ax[1,0].hist(recalls, color='b', alpha=0.7)\n",
    "ax[1,0].hist(recalls_shuff, color='k', alpha=0.7)\n",
    "ax[1,0].vlines(np.mean(recalls), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "ax[1,0].vlines(np.percentile(recalls_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[1,0].set_title(\"Recall\")\n",
    "\n",
    "ax[1,1].hist(f1s, color='b', alpha=0.7)\n",
    "ax[1,1].hist(f1s_shuff, color='k', alpha=0.7)\n",
    "ax[1,1].vlines(np.mean(f1s), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "ax[1,1].vlines(np.percentile(f1s_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[1,1].set_title(\"F1 Score\")\n",
    "\n",
    "plt.suptitle(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find optimal C/gamma values\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, shuffle=True, random_state=0)\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': [1e-3, 1e-4, 1e-2, 1e-1, 1e-0],\n",
    "                     'C': [1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9]},]\n",
    "\n",
    "clf = GSCV(SVC(), tuned_parameters, cv=5)\n",
    "clf.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = ytest, clf.predict(Xtest)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "\n",
    "y=Y\n",
    "\n",
    "y = label_binarize(y, classes=targetclasses)\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='rbf',C=1e7,gamma=0.01, probability=True,\n",
    "                                 random_state=0))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x265762cecc0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = np.random.choice(list(plt.cm.colors.CSS4_COLORS.keys()),n_classes,replace=False)\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'{target} Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alley and Texture - 27 label decoding\n",
    "\n",
    "ratemaps = {alley: np.empty((0, Def.singleAlleyBins[0]-1)) for alley in [16,17,3,1,5,7,8,10,11]}\n",
    "labels = []\n",
    "popidx = []\n",
    "idx = 0\n",
    "\n",
    "target = 'Alley/Texture'\n",
    "# accs, shuffs, oobs = [], [], []\n",
    "for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "    for clustName, unit in population.items():\n",
    "        popidx.append(idx)\n",
    "        for stim in ['A', 'B', 'C']:\n",
    "            rm = unit.linRMS[alley][stim]\n",
    "            \n",
    "            if type(rm) == np.ndarray and np.nanmax(rm)>frThresh:\n",
    "                ratemaps[alley] = np.vstack((ratemaps[alley], rm))\n",
    "                #labels.append(f\"{alley}{np.random.choice(['A','B','C'])}\")\n",
    "                labels.append(f\"{alley}{np.random.choice(['A','B','C'])}\")\n",
    "                idx += 1\n",
    "    for alley in [16,17,3,1,5,7,8,10,11]:\n",
    "        ratemaps[alley][np.where(np.isnan(ratemaps[alley]))] = 0\n",
    "        \n",
    "pop = np.vstack(([ratemaps[i] for i in [16,17,3,1,5,7,8,10,11]]))\n",
    "X = preprocessing.StandardScaler().fit_transform(pop)\n",
    "Y = np.asarray(labels)\n",
    "targetclasses = list(set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics: Confusion Matrices and Precision/Recall/F1/Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Average precision: 0.08930699270656536\n",
      "Average recalls: 0.0956384500273389\n",
      "Average F1 score: 0.08249653720490693\n",
      "Average accuracy: 0.09074380165289257\n"
     ]
    }
   ],
   "source": [
    "# this is for when youre creating test/train by randomizing obsv\n",
    "\n",
    "precisions, recalls, f1s, accuracies = [], [], [], []\n",
    "avgType = 'macro'\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, shuffle=True) #default split size is 1/4\n",
    "    svc = SVC(C=1e7, gamma=0.01,kernel='rbf')\n",
    "    svc.fit(Xtrain,ytrain)\n",
    "    yfit = svc.predict(Xtest)\n",
    "    p = precision_score(ytest, yfit, average=avgType)\n",
    "    r = recall_score(ytest, yfit, average=avgType)\n",
    "    f1 = f1_score(ytest, yfit, average=avgType)\n",
    "    acc = accuracy_score(ytest,yfit)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f1)\n",
    "    accuracies.append(acc)\n",
    "print(f\"Average precision: {np.mean(precisions)}\")\n",
    "print(f\"Average recalls: {np.mean(recalls)}\")\n",
    "print(f\"Average F1 score: {np.mean(f1s)}\")\n",
    "print(f\"Average accuracy: {np.mean(accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Alley/Texture')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "\n",
    "ax[0,0].hist(accuracies, color='b', alpha=0.7)\n",
    "#ax[0,0].hist(accuracies_shuff, color='k', alpha=0.7)\n",
    "ax[0,0].vlines(np.mean(accuracies), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "#ax[0,0].vlines(np.percentile(accuracies_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[0,0].set_title(\"Accuracy\")\n",
    "\n",
    "ax[0,1].hist(precisions, color='b', alpha=0.7)\n",
    "#ax[0,1].hist(precisions_shuff, color='k', alpha=0.7)\n",
    "ax[0,1].vlines(np.mean(precisions), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "#ax[0,1].vlines(np.percentile(precisions_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[0,1].set_title(\"Precision\")\n",
    "\n",
    "ax[1,0].hist(recalls, color='b', alpha=0.7)\n",
    "#ax[1,0].hist(recalls_shuff, color='k', alpha=0.7)\n",
    "ax[1,0].vlines(np.mean(recalls), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "#ax[1,0].vlines(np.percentile(recalls_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[1,0].set_title(\"Recall\")\n",
    "\n",
    "ax[1,1].hist(f1s, color='b', alpha=0.7)\n",
    "#ax[1,1].hist(f1s_shuff, color='k', alpha=0.7)\n",
    "ax[1,1].vlines(np.mean(f1s), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1],color='b')\n",
    "#ax[1,1].vlines(np.percentile(f1s_shuff,95), ax[0,0].get_ylim()[0], ax[0,0].get_ylim()[1])\n",
    "ax[1,1].set_title(\"F1 Score\")\n",
    "\n",
    "plt.suptitle(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1805a6feba8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x265096d2780>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = accuracies\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].hist(accs)\n",
    "ax[0].set_xlabel(\"1/4 Cross-Val Accuracy\")\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].plot(accs)\n",
    "ax[1].plot([0, nruns], [np.mean(accs), np.mean(accs)], 'k--',alpha=0.5)\n",
    "ax[1].set_xlabel(\"Iteration of Repeated Cross-Validation\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "plt.suptitle(f\"SVM Performance, {target}, C=1e7, gamma=0.01, RBF kernel\", fontsize=16)\n",
    "ax[1].hlines(1/len(targetclasses),0,nruns,'k')\n",
    "ax[0].vlines(1/len(targetclasses),0,ax[0].get_ylim()[1],'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(X, Y, numRuns, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    Taken from the sklearn docs. Modified by WH\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = f'Normalized confusion matrix, {numRuns} runs'\n",
    "        else:\n",
    "            title = f'Confusion matrix, without normalization, {numRuns} runs'\n",
    "\n",
    "    # Compute multiple confusion matrces and sum\n",
    "    allcms = []\n",
    "    for run in range(numRuns):\n",
    "        Xtrain, Xtest, ytrain, y_true = train_test_split(X, Y, shuffle=True, train_size=0.75)\n",
    "        svc = SVC(C=1e7, gamma=0.01,kernel='rbf')\n",
    "        svc.fit(Xtrain,ytrain)\n",
    "        y_pred = svc.predict(Xtest)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        allcms.append(cm)\n",
    "    \n",
    "    cm = np.sum(np.asarray(allcms), axis=0)\n",
    "        \n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    \n",
    "    ax.plot(range(classes.shape[0]), range(classes.shape[0]))\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (27,27) (26,26) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a47482bd7f88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plot_confusion_matrix(X,Y,100, classes=np.unique(Y), normalize=False,\n\u001b[1;32m----> 2\u001b[1;33m                       title=f'{target} Confusion matrix, No R, {frThresh}Hz Fr Thresh')\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-9469e82e8e39>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(X, Y, numRuns, classes, normalize, title, cmap)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mallcms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallcms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Only use the labels that appear in the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   1832\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m     return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 1834\u001b[1;33m                          out=out, **kwargs)\n\u001b[0m\u001b[0;32m   1835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (27,27) (26,26) "
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(X,Y,100, classes=np.unique(Y), normalize=False,\n",
    "                      title=f'{target} Confusion matrix, No R, {frThresh}Hz Fr Thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
