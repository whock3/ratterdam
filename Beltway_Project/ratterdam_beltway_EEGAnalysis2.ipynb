{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beltway Rate remapping Project\n",
    "# EEG/Oscillation Analysis 2\n",
    "## Examining how theta (cycles, precession, etc) and possibly gamma interact w rate remapping effect\n",
    "## Late Feb 2021 WH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, scipy.signal as ss, scipy.fftpack as sf\n",
    "from scipy.signal import hilbert, butter, lfilter\n",
    "import scipy.fftpack\n",
    "from collections import OrderedDict\n",
    "\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_Defaults as Def\n",
    "import ratterdam_visBasic as Vis\n",
    "import utility_fx as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function and Structure Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_data(data, low,high, sf=32000, order=2):\n",
    "    # Determine Nyquist frequency\n",
    "    nyq = sf/2\n",
    "    # Set bands\n",
    "    low = low/nyq\n",
    "    high = high/nyq\n",
    "    # Calculate coefficients\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    # Filter signal\n",
    "    filtered_data = lfilter(b, a, data)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hilbert3 = lambda x: hilbert(x, scipy.fftpack.next_fast_len(len(x)))[:len(x)] # this truncates bc for certain array sizes (primes) underlying FFT is insanely slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncsType = np.dtype([\n",
    "    ('ts', '<u8'),\n",
    "    ('dwChannelNumber', '<u4'),\n",
    "    ('fs', '<u4'),\n",
    "    ('NumValidSamples', '<u4'),\n",
    "    ('data', '<i2', (512, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alleylongcoord = {16:'x',17:'y',3:'y',4:'x',5:'x',7:'x',8:'y',10:'y',11:'x'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\Beltway_Project\\ratterdam_CoreDataStructures.py:178: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\Beltway_Project\\ratterdam_CoreDataStructures.py:178: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\Beltway_Project\\ratterdam_CoreDataStructures.py:184: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\Beltway_Project\\ratterdam_CoreDataStructures.py:184: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "E:\\UserData\\Documents\\GitHub\\ratterdam\\utility_fx.py:330: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n"
     ]
    }
   ],
   "source": [
    "rat = 'R781'\n",
    "expCode = 'BRD3'\n",
    "datafile = f'E:\\\\Ratterdam\\\\{rat}\\\\{rat}{expCode}\\\\'\n",
    "clustname = \"TT5\\\\cl-maze1.1\"\n",
    "qualThresh = 3\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "clustlist, clustQuals = util.getClustList(datafile) # clustList and clustQuals share same order. ith entry in each is the name and qual of same cell. \n",
    "population = OrderedDict()\n",
    "\n",
    "unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "unit.loadData_raw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in tetrode csc data into data and ts structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = 5\n",
    "fname = datafile + f\"CSC{tt}.ncs\"\n",
    "\n",
    "curFile = open(fname)\n",
    "curFile.seek(16*1024)\n",
    "curFile = np.fromfile(curFile, dtype=ncsType)\n",
    "\n",
    "dt = (1/32000)*1e6 # this is the timestep between each sample in packet. Only first sample is explicitly timestamped\n",
    "                     # by neuralynx at time of collection so increment this dt value repeatedly to get ts of all other samples in packet\n",
    "cscdata = curFile['data'].flatten()\n",
    "cscts = []\n",
    "for packet in curFile:\n",
    "    init_ts = packet['ts']\n",
    "    cscts.append(init_ts)\n",
    "    interp_ts = init_ts + dt # initialize the, basically, counter. this init is for the second point if that makes sense\n",
    "    for datapoint in packet['data'][1:]: # start with second bc first one is (the only one) timestamped\n",
    "        cscts.append(interp_ts)\n",
    "        interp_ts += dt # increment for next ts\n",
    "        \n",
    "csc = np.column_stack((cscts, cscdata))\n",
    "del cscts, cscdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#whole session tt theta will be kept \n",
    "theta = np.column_stack((csc[:,0],filter_data(csc[:,1],8,12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractCSCSegment(csc, tsBeg, tsEnd):\n",
    "    \"\"\"\n",
    "    Input - * csc is (n,2) array with whole session csc data\n",
    "            for one tt (sampled 1/32000 s). ts, sample value\n",
    "            * tsBeg, tsEnd - neuralynx ts for segment\n",
    "            start and end\n",
    "    Return: \n",
    "    \"\"\"\n",
    "    mask = (csc[:,0]>tsBeg)&(csc[:,0]<tsEnd)\n",
    "    segment = csc[mask,:]\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcPrecessionTrial(spikes, thetaSegment, coordDict):\n",
    "    \n",
    "    #poormans point projection is just take coordinate of long dimension of alley\n",
    "    if coordDict[alley] == 'y':\n",
    "        spos = spikes[:,2]\n",
    "    elif coordDict[alley] == 'x':\n",
    "        spos = spikes[:,1]\n",
    "    \n",
    "    phaseSegment = np.column_stack((thetaSegment[:,0], np.angle(hilbert3(thetaSegment[:,1]), deg=True)))\n",
    "    precess = np.column_stack((phaseSegment[np.searchsorted(phaseSegment[:,0], spikes[:,0])-1,1],spos))\n",
    "    \n",
    "    return precess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit TT5cl-maze1.1, alley 8\n"
     ]
    }
   ],
   "source": [
    "alley=8\n",
    "precession = {'A': np.empty((0,2)), \n",
    "              'B': np.empty((0,2)), \n",
    "              'C': np.empty((0,2))}\n",
    "\n",
    "print(f\"Unit {unit.name}, alley {alley}\")\n",
    "\n",
    "for visit in unit.alleys[alley]:\n",
    "    spk = visit['spikes']\n",
    "    txt = visit['metadata']['stimulus']\n",
    "    tsBeg, tsEnd = visit['occs'][0,0], visit['occs'][-1,0]\n",
    "    thetaSegment = theta[(theta[:,0]>tsBeg)&(theta[:,0]<tsEnd)]\n",
    "    precession[txt] = np.vstack((precession[txt], calcPrecessionTrial(spk, thetaSegment, alleylongcoord)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for txt in ['A', 'B', 'C']:\n",
    "    plt.figure()\n",
    "    plt.title(f\"{rat} {expCode} {clustname} {alley} {txt}\")\n",
    "    plt.scatter(precession[f'{txt}'][:,1], precession[f'{txt}'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
