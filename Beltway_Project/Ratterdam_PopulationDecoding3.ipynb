{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "\n",
    "import numpy as np, random, json, pickle, datetime, copy, socket, os, sys, scipy\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from importlib import reload\n",
    "\n",
    "if socket.gethostname() == 'Tolman':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whockei1\\\\Google Drive'\n",
    "elif socket.gethostname() == 'DESKTOP-BECTOJ9':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whock\\\\Google Drive'\n",
    "    \n",
    "sys.path.insert(0, codeDirBase + '\\\\KnierimLab\\\\Ratterdam\\\\Code')\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_PermutationTests as Perm\n",
    "import ratterdam_Defaults as Def\n",
    "import ratterdam_DataFiltering as Filt\n",
    "\n",
    "\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:170: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:170: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:176: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:176: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:325: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:498: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:498: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT1\\cl-maze1.1\n",
      "TT1\\cl-maze1.2\n",
      "TT12\\cl-maze1.1\n",
      "TT14\\cl-maze1.2\n",
      "TT14\\cl-maze1.3\n",
      "TT15\\cl-maze1.1\n",
      "TT15\\cl-maze1.5\n",
      "TT15\\cl-maze1.6\n",
      "TT6_0001\\cl-maze1.1\n",
      "TT6_0001\\cl-maze1.2\n",
      "TT6_0001\\cl-maze1.3\n",
      "TT9\\cl-maze1.1\n"
     ]
    }
   ],
   "source": [
    "datafile = \"E:\\\\Ratterdam\\\\R808\\\\R808_Beltway_D7\\\\\"\n",
    "expCode = \"BRD7\"\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw()\n",
    "            rm = util.makeRM(unit.spikes, unit.position)            \n",
    "            if np.nanpercentile(rm,Def.wholetrack_imshow_pct_cutoff) >= 1.:\n",
    "                print(clustname)\n",
    "                population[unit.name+\"___\"] = unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions and Structures for Decoding (not general enough to warrant inclusion in utility_fx.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_epoch(val,size):\n",
    "    \"\"\"hardcode that session is divided\n",
    "    into thirds. find in which third the trial is in\"\"\"\n",
    "    propthrusess = val/size\n",
    "    if propthrusess < 0.25:\n",
    "        epoch = '0'\n",
    "    elif propthrusess <= 0.5:\n",
    "        epoch = '1'\n",
    "    elif propthrusess <= 0.75:\n",
    "        epoch = '2'\n",
    "    elif propthrusess < 1.:\n",
    "        epoch = '3'\n",
    "    return epoch\n",
    "\n",
    "def checkRM(ratemap):\n",
    "    \"\"\"Utility function to take a 1-d linear ratemap\n",
    "    and see if it is valid.\n",
    "    May 2019: it's not empty ie. there's data\n",
    "    and the nanmax of that data exceeds firing rate\n",
    "    thresh defined locally\"\"\"\n",
    "    if type(ratemap) == np.ndarray and np.nanmax(ratemap) >= frThresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def generateLabel(target, alley, stimulus, epoch):\n",
    "    if target == 'Alley':\n",
    "        label = str(alley)\n",
    "    elif target == 'Stimulus':\n",
    "        label = stimulus\n",
    "    elif target == 'Epoch':\n",
    "        label = epoch\n",
    "    elif target == 'AlleyXStimulus':\n",
    "        label = f\"{alley}{stimulus}\"\n",
    "    elif target == 'AlleyXEpoch':\n",
    "        label  = f\"{alley}{epoch}\"\n",
    "    elif target == 'StimulusXEpoch':\n",
    "        label = f\"{stimulus}{epoch}\"\n",
    "    elif target == 'AlleyXStimulusXEpoch':\n",
    "        label = f\"{alley}{stimulus}{epoch}\"\n",
    "    \n",
    "    return label\n",
    "\n",
    "def shuffle(Y, target):\n",
    "    \"\"\"Shuffles list of labels in place according to target value\"\"\"\n",
    "    if target == 'AlleyXStimulus':\n",
    "        txt = [i[-1] for i in Y]\n",
    "        np.random.shuffle(txt)\n",
    "        a = [i[:-1] for i in Y]\n",
    "        Y = [f\"{x}{y}\" for x,y in zip(a,txt)]\n",
    "    elif target == 'Stimulus':\n",
    "        np.random.shuffle(Y)\n",
    "    elif target == 'Alley':\n",
    "        np.random.shuffle(Y)\n",
    "    return None\n",
    "\n",
    "target_classes = {'Alley':[str(i) for i in [16,17,3,1,5,7,8,10,11]],\n",
    "                  'Stimulus': ['A','B','C'],\n",
    "                  'AlleyXStimulus': ['10A', '10B', '10C', '11A', '11B', '11C', '16A', '16B', '16C',\n",
    "                                    '17A', '17B', '17C', '1A', '1B', '1C', '3A', '3B', '3C', '5A', '5B',\n",
    "                                   '5C', '7A', '7B', '7C', '8A', '8B', '8C']\n",
    "                 }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frThresh = 0 #measured in Hz. Pick something close to 0, or 0 itself. \n",
    "target = 'Alley' #choices are Alley, Texture, Epoch, or some 2- or 3-member combination of these\n",
    "beltwayAlleys = [16, 17, 3, 1, 5, 7, 8, 10, 11] # beltway alley IDs in terms of their full track, 17-alley ID\n",
    "nbins = Def.singleAlleyBins[0]-1\n",
    "avgType = 'macro' # for signal detection / performance metrics which are not inherently multiclass (e.g. all but accuracy), pick how to aggregate individual class results\n",
    "nRuns = 250# number of repeats for multiple subsampling\n",
    "shuffle = False\n",
    "split_size = 0.75 # defined in terms of train size, proportion 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data matrix X and label list Y\n",
    "### where each row is a single unit's response to a visit under a certain alley/txt combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.empty((0, nbins+1))\n",
    "Y = []\n",
    "\n",
    "for alley in beltwayAlleys:\n",
    "    visitSize = len(population[list(population.keys())[0]].alleys[alley]) # all units have same behavioral data obviously so use first unit by default to get num viists to alley.\n",
    "    for visitNum in range(60): \n",
    "        #dataRow = np.empty((0))\n",
    "        #epoch = compute_epoch(visitNum, visitSize)\n",
    "        \n",
    "        invalidRow = 0 # initialize to valid, set to invalid upon finding an invalid rm\n",
    "        \n",
    "        unitID = 1\n",
    "        for unitname, Unit in population.items():\n",
    "            dataRow = np.empty((0))\n",
    "            try:\n",
    "                stimulus = population[list(population.keys())[0]].alleys[alley][visitNum]['metadata']['stimulus'] #again, stims are same for all units so use first unit to grab it\n",
    "                label =  generateLabel(target, alley, stimulus, '')\n",
    "                rm = Unit.alleys[alley][visitNum]['ratemap1d']\n",
    "                if checkRM(rm)== True:\n",
    "                    rm = np.hstack((unitID, rm))\n",
    "                    dataRow = np.concatenate((dataRow, rm))\n",
    "                    Y.append(label)\n",
    "                    X = np.vstack((X, dataRow))\n",
    "\n",
    "                else:\n",
    "                    dataRow = np.concatenate((dataRow, np.zeros((nbins+1)) ))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            unitID += 10\n",
    "                \n",
    "        # Y.append(label)\n",
    "        # X = np.vstack((X, dataRow))\n",
    "\n",
    "X[np.where(~np.isfinite(X))] = 0\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "\n",
    "if shuffle is True:\n",
    "    if target == 'AlleyXStimulus':\n",
    "        txt = [i[-1] for i in Y]\n",
    "        np.random.shuffle(txt)\n",
    "        a = [i[:-1] for i in Y]\n",
    "        Y = [f\"{x}{y}\" for x,y in zip(a,txt)]\n",
    "    elif target == 'Stimulus':\n",
    "        np.random.shuffle(Y)\n",
    "    elif target == 'Alley':\n",
    "        np.random.shuffle(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and Y\n",
    "#### where each row is whole population's response to a visit under a given alley/txt combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.empty((0, nbins*len(population.keys())))\n",
    "Y = []\n",
    "\n",
    "for alley in beltwayAlleys:\n",
    "    visitSize = len(population[list(population.keys())[0]].alleys[alley]) # all units have same behavioral data obviously so use first unit by default to get num viists to alley.\n",
    "    for visitNum in range(60): \n",
    "        \n",
    "        invalidRow = 0 # initialize to valid, set to invalid upon finding an invalid rm\n",
    "        unitID = 0\n",
    "        \n",
    "        dataRow = np.empty((0))\n",
    "        for unitname, Unit in population.items():\n",
    "            try:\n",
    "                stimulus = population[list(population.keys())[0]].alleys[alley][visitNum]['metadata']['stimulus'] #again, stims are same for all units so use first unit to grab it\n",
    "                label =  generateLabel(target, alley, stimulus, '')\n",
    "                rm = Unit.alleys[alley][visitNum]['ratemap1d']\n",
    "                if checkRM(rm)== True:\n",
    "                    #rm = np.hstack((unitID, rm))\n",
    "                    dataRow = np.hstack((dataRow, rm))\n",
    "                else:\n",
    "\n",
    "                    dataRow = np.hstack((dataRow, np.zeros((nbins)) ))\n",
    "            except:\n",
    "                dataRow = np.hstack((dataRow, np.zeros((nbins)) ))\n",
    "            \n",
    "            unitID += 1\n",
    "            \n",
    "        Y.append(label)\n",
    "        X = np.vstack((X, dataRow))\n",
    "                \n",
    "\n",
    "X[np.where(~np.isfinite(X))] = 0\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "\n",
    "if shuffle is True:\n",
    "    if target == 'AlleyXStimulus':\n",
    "        txt = [i[-1] for i in Y]\n",
    "        np.random.shuffle(txt)\n",
    "        a = [i[:-1] for i in Y]\n",
    "        Y = [f\"{x}{y}\" for x,y in zip(a,txt)]\n",
    "    elif target == 'Stimulus':\n",
    "        np.random.shuffle(Y)\n",
    "    elif target == 'Alley':\n",
    "        np.random.shuffle(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-394-0f0f61af8cf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0moobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0myfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 316\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[1;32m--> 127\u001b[1;33m                                     for p in self.estimator_params))\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[1;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;31m# catch deprecated param values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# to represent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   3031\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3033\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2781\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2782\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[1;32m-> 2783\u001b[1;33m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[0;32m   2784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2785\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2256\u001b[0m         \u001b[1;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m         \u001b[1;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2258\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func)\u001b[0m\n\u001b[0;32m   2134\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m   2135\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2136\u001b[1;33m                                     default=defaults[offset]))\n\u001b[0m\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m     \u001b[1;31m# *args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[0;32m   2466\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{!r} is not a valid parameter name'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oobs, precisions, recalls, f1s, accuracies = [], [], [], [],[]\n",
    "\n",
    "for i in range(500):\n",
    "    print(i)\n",
    "    clf = RandomForestClassifier(n_estimators=1500, oob_score=True)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,shuffle=True,random_state=0)\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "    oobs.append(clf.oob_score_)\n",
    "    yfit = clf.predict(Xtest)\n",
    "    p = precision_score(ytest, yfit, average=avgType)\n",
    "    r = recall_score(ytest, yfit, average=avgType)\n",
    "    f1 = f1_score(ytest, yfit, average=avgType)\n",
    "    acc = accuracy_score(ytest,yfit)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f1)\n",
    "    accuracies.append(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Histograms of Signal Detection Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'RF Decoding Performance Metrics on Alley, Real')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(precisions, color='b', alpha=0.5)\n",
    "plt.hist(recalls, color='r', alpha=0.5)\n",
    "plt.hist(f1s, color='g', alpha=0.5)\n",
    "plt.hist(accuracies, color='k', alpha=0.5)\n",
    "plt.hist(oobs,color='purple',alpha=0.5)\n",
    "plt.legend([\"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\", \"OOB\"])\n",
    "#plt.vlines(weightedChance(.56,.3),0,plt.ylim()[1])\n",
    "plt.ylabel(\"Frquency\")\n",
    "plt.xlabel(\"Performance\")\n",
    "plt.title(f\"RF Decoding Performance Metrics on {target}, {(lambda x: 'Real' if x == False else 'Shuffle')(shuffle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multiday Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Alley-by-Stimulus Decoding')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots(3,1)\n",
    "fig2, ax2 = plt.subplots(3,1)\n",
    "fig3, ax3 = plt.subplots(3,1)\n",
    "fig1.suptitle(\"Alley Decoding\",fontsize=24)\n",
    "fig2.suptitle(\"Stimulus Decoding\",fontsize=24)\n",
    "fig3.suptitle(\"Alley-by-Stimulus Decoding\",fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figures = {1:fig1, 2:fig2, 3:fig3}\n",
    "for i in [1,2,3]:\n",
    "    figures[i].axes[0].set_ylabel(\"Out-of-Bag Score\", fontsize=24)\n",
    "    figures[i].axes[1].set_ylabel(\"Precision\", fontsize=24)\n",
    "    figures[i].axes[2].set_ylabel(\"Recall\", fontsize=24)\n",
    "    figures[i].axes[2].set_xlabel(\"Recording Days (Real paired with shuffle)\", fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alley\n",
    "# real_files = [\"RFdecoding_Alley_R781BRD3_20191009_2157\",\n",
    "#         \"RFdecoding_Alley_R781BRD4_20191010_1514\",\n",
    "#         \"RFdecoding_Alley_R808BRD4_20191010_1853\",\n",
    "#         \"RFdecoding_Alley_R808BRD5_20191010_2027\",\n",
    "#         \"RFdecoding_R808BRD6_20191009_1900\",\n",
    "#         \"RFdecoding_Alley_R808BRD7_20191010_1201\"]\n",
    "\n",
    "# shuffle_files = [\"RFdecoding_Alley_R781BRD3_20191009_2304\",\n",
    "#             \"RFdecoding_Alley_R781BRD4_20191010_1628\",\n",
    "#             \"RFdecoding_Alley_R808BRD4_20191010_1931\",\n",
    "#             \"RFdecoding_Alley_R808BRD5_20191010_2134\",\n",
    "#             \"RFdecoding_R808BRD6_20191009_1950\",\n",
    "#             \"RFdecoding_Alley_R808BRD7_20191010_1332\"    \n",
    "#             ]\n",
    "\n",
    "#stimulus\n",
    "\n",
    "# real_files = [\"RFdecoding_Stimulus_R781BRD3_20191009_2216\",\n",
    "#              \"RFdecoding_Stimulus_R781BRD4_20191010_1535\",\n",
    "#              \"RFdecoding_Stimulus_R808BRD4_20191010_1905\",\n",
    "#              \"RFdecoding_Stimulus_R808BRD5_20191010_2048\",\n",
    "#              \"RFdecoding_R808BRD6_20191009_1915\",\n",
    "#              \"RFdecoding_Stimulus_R808BRD7_20191010_1231\"]\n",
    "\n",
    "# shuffle_files = [\"RFdecoding_Stimulus_R781BRD3_20191009_2323\",\n",
    "#                 \"RFdecoding_Stimulus_R781BRD4_20191010_1653\",\n",
    "#                 \"RFdecoding_Stimulus_R808BRD4_20191010_1943\",\n",
    "#                 \"RFdecoding_Stimulus_R808BRD5_20191010_2154\",\n",
    "#                 \"RFdecoding_R808BRD6_20191009_2006\",\n",
    "#                 \"RFdecoding_Stimulus_R808BRD7_20191010_1401\"]\n",
    "\n",
    "# alley-by-stimulus\n",
    "\n",
    "real_files = [\"RFdecoding_AlleyXStimulus_R781BRD3_20191009_2242\",\n",
    "             \"RFdecoding_AlleyXStimulus_R781BRD4_20191010_1600\",\n",
    "             \"RFdecoding_AlleyXStimulus_R808BRD4_20191010_1919\",\n",
    "             \"RFdecoding_AlleyXStimulus_R808BRD5_20191010_2110\",\n",
    "             \"RFdecoding_R808BRD6_20191009_1932\",\n",
    "             \"RFdecoding_AlleyXStimulus_R808BRD7_20191010_1300\"]\n",
    "\n",
    "shuffle_files = [\"RFdecoding_AlleyXStimulus_R781BRD3_20191009_2349\",\n",
    "                 \"RFdecoding_AlleyXStimulus_R781BRD4_20191010_1719\",\n",
    "                 \"RFdecoding_AlleyXStimulus_R808BRD4_20191010_1957\",\n",
    "                 \"RFdecoding_AlleyXStimulus_R808BRD5_20191010_2217\",\n",
    "                 \"RFdecoding_R808BRD6_20191009_2023\",\n",
    "                 \"RFdecoding_AlleyXStimulus_R808BRD7_20191010_1430\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = fig3\n",
    "p=0\n",
    "for i in range(6):\n",
    "    s = shuffle_files[i]\n",
    "    r = real_files[i]\n",
    "    with open('E:\\\\Ratterdam\\\\multidayFigures\\\\randomForest\\\\'+s+\".json\",\"r\") as file:\n",
    "        shuffle = json.load(file)\n",
    "    with open('E:\\\\Ratterdam\\\\multidayFigures\\\\randomForest\\\\'+r+\".json\",\"r\") as file:\n",
    "        real = json.load(file)\n",
    "        \n",
    "    for data  in [shuffle,real]:\n",
    "        for metric,a,c in zip(['oobs', 'precisions', 'recalls'],[0,1,2],['green','blue','red']):\n",
    "            vp = f.axes[a].violinplot(data[metric],[p],showmeans=True,widths=1.5)\n",
    "            for vp_element in ['cmeans','cmins','cmaxes','cbars']:\n",
    "                vp[vp_element].set_facecolor(c)\n",
    "                vp[vp_element].set_edgecolor(c)\n",
    "            for part in vp['bodies']:\n",
    "                part.set_facecolor(c)\n",
    "                part.set_edgecolor(c)\n",
    "\n",
    "        p += 2\n",
    "for a in [0,1,2]:\n",
    "    f.axes[a].set_xticks([])\n",
    "    f.axes[a].tick_params(axis='y',labelsize=20)\n",
    "    f.axes[a].spines['right'].set_visible(False)\n",
    "    f.axes[a].spines['top'].set_visible(False)\n",
    "f.axes[2].set_xticks([0,2])\n",
    "f.axes[2].set_xticklabels([\"Shuffle\", \"Real\"])\n",
    "for tick in f.axes[2].xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Non spatial decoding - representing responses in different ways besides the firing rate\n",
    "#### first thing mid dec 2019 - test stat diffs, deviation of a single visit rm from [window median, window mean, etc], summary parm vec [max, mean, etc of a visit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkRM(ratemap):\n",
    "    \"\"\"Utility function to take a 1-d linear ratemap\n",
    "    and see if it is valid.\n",
    "    May 2019: it's not empty ie. there's data\n",
    "    and the nanmax of that data exceeds firing rate\n",
    "    thresh defined locally\"\"\"\n",
    "    if type(ratemap) == np.ndarray and np.nanmax(ratemap) >= frThresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:170: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:170: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:176: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:176: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:325: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:498: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:498: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT10\\cl-maze1.1\n",
      "TT10\\cl-maze1.2\n",
      "TT10\\cl-maze1.3\n",
      "TT10\\cl-maze1.4\n",
      "TT10\\cl-maze1.6\n",
      "TT10\\cl-maze1.7\n",
      "TT11\\cl-maze1.1\n",
      "TT13\\cl-maze1.1\n",
      "TT13\\cl-maze1.2\n",
      "TT13\\cl-maze1.4\n",
      "TT13\\cl-maze1.5\n",
      "TT13\\cl-maze1.7\n",
      "TT14\\cl-maze1.1\n",
      "TT14\\cl-maze1.3\n",
      "TT3_0001\\cl-maze1.1\n",
      "TT3_0001\\cl-maze1.3\n",
      "TT3_0001\\cl-maze1.4\n",
      "TT3_0001\\cl-maze1.5\n",
      "TT3_0001\\cl-maze1.6\n",
      "TT3_0001\\cl-maze1.7\n",
      "TT4_0001\\cl-maze1.1\n",
      "TT4_0001\\cl-maze1.2\n",
      "TT4_0001\\cl-maze1.3\n",
      "TT4_0001\\cl-maze1.4\n",
      "TT4_0001\\cl-maze1.5\n",
      "TT5_0001\\cl-maze1.2\n",
      "TT5_0001\\cl-maze1.3\n",
      "TT6_0001\\cl-maze1.1\n",
      "TT6_0001\\cl-maze1.2\n",
      "TT6_0001\\cl-maze1.3\n",
      "TT6_0001\\cl-maze1.4\n",
      "TT6_0001\\cl-maze1.5\n",
      "TT6_0001\\cl-maze1.6\n",
      "TT6_0001\\cl-maze1.7\n",
      "TT6_0001\\cl-maze1.8\n",
      "TT7\\cl-maze1.2\n",
      "TT7\\cl-maze1.3\n",
      "TT7\\cl-maze1.4\n",
      "TT8\\cl-maze1.1\n",
      "TT8\\cl-maze1.2\n",
      "TT8\\cl-maze1.3\n",
      "TT8\\cl-maze1.4\n",
      "TT8\\cl-maze1.5\n",
      "TT8\\cl-maze1.6\n",
      "TT9\\cl-maze1.10\n",
      "TT9\\cl-maze1.2\n",
      "TT9\\cl-maze1.3\n",
      "TT9\\cl-maze1.4\n",
      "TT9\\cl-maze1.5\n",
      "TT9\\cl-maze1.6\n",
      "TT9\\cl-maze1.7\n",
      "TT9\\cl-maze1.8\n",
      "TT9\\cl-maze1.9\n"
     ]
    }
   ],
   "source": [
    "datafile = \"Z:\\\\CheetahData\\\\R859BRD3\\\\\"\n",
    "expCode = \"BRD3\"\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw()\n",
    "            rm = util.makeRM(unit.spikes, unit.position)            \n",
    "            if np.nanpercentile(rm,Def.wholetrack_imshow_pct_cutoff) >= 1.:\n",
    "                print(clustname)\n",
    "                population[unit.name+\"___\"] = unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frThresh = 0 #measured in Hz. Pick something close to 0, or 0 itself. \n",
    "target = 'Alley' #choices are Alley, Texture, Epoch, or some 2- or 3-member combination of these\n",
    "beltwayAlleys = [16, 17, 3, 1, 5, 7, 8, 10, 11] # beltway alley IDs in terms of their full track, 17-alley ID\n",
    "nbins = Def.singleAlleyBins[0]-1\n",
    "avgType = 'macro' # for signal detection / performance metrics which are not inherently multiclass (e.g. all but accuracy), pick how to aggregate individual class results\n",
    "nRuns = 250# number of repeats for multiple subsampling\n",
    "shuffle = False\n",
    "split_size = 0.75 # defined in terms of train size, proportion 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcStatPair(unit, alley, pair):\n",
    "    x,y = pair #unpack the pair of stimuli eg AB\n",
    "    rma, rmb = unit.linRMS[alley][x], unit.linRMS[alley][y]\n",
    "    stat = np.abs(rma-rmb)\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateLabel2(target, alley, stimulus):\n",
    "    if target == 'Alley':\n",
    "        label = str(alley)\n",
    "    elif target == 'Stimulus':\n",
    "        if len(stimulus) == 1:\n",
    "            label = stimulus\n",
    "        elif len(stimulus) == 2:\n",
    "            label = stimulus[0] # if label is a pair of stims for a test stat label\n",
    "    elif target == 'AlleyXStimulus':\n",
    "        if len(stimulus) == 1:\n",
    "            label = f\"{alley}{stimulus}\"\n",
    "        elif len(stimulus) == 2:\n",
    "            label = f\"{alley}{stimulus[0]}\"\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcRMdeviation(unit, alley, visit, window=5, deviation='diff'):\n",
    "    \"\"\"\n",
    "    Compute the deviation of a visit's ratemap\n",
    "    for a cell from the average within a window\n",
    "    of all visits' rms. Window var is one-sided\n",
    "    so whole window size is 2*window. \n",
    "    \n",
    "    Deviation is \n",
    "    - 'diff' for binwise difference\n",
    "    \"\"\"\n",
    "                    \n",
    "    rmvisit = unit.alleys[alley][visit]['ratemap1d']\n",
    "    rms_in_window = np.empty((0, nbins))\n",
    "    \n",
    "    if visit < window:\n",
    "        for i in range(0, (window-visit)+1):\n",
    "            rm = unit.alleys[alley][i]['ratemap1d']\n",
    "            rms_in_window = np.vstack((rms_in_window, rm))\n",
    "            \n",
    "    elif (visit+window) >= len(unit.alleys[alley]):\n",
    "        for i in range(visit-window, visit+(len(unit.alleys[alley])-visit)):\n",
    "            rm = unit.alleys[alley][i]['ratemap1d']\n",
    "            rms_in_window = np.vstack((rms_in_window, rm))     \n",
    "            \n",
    "    else:\n",
    "        for i in range(visit-window, visit+window+1):\n",
    "            rm = unit.alleys[alley][i]['ratemap1d']\n",
    "            rms_in_window = np.vstack((rms_in_window, rm))\n",
    "            \n",
    "    mask = np.ma.masked_invalid(rms_in_window)\n",
    "    avg = np.median(mask.data,axis=0) # ignores inf and nan\n",
    "    if deviation == 'diff':\n",
    "        stat = np.abs(rmvisit-avg)\n",
    "    if deviation == 'grad': \n",
    "        stat = np.gradient(rmvisit)\n",
    "    elif deviation.lower() == 'none':\n",
    "        stat = rmvisit # this passthrough is so you dont have to change anything but a toggle in setup fx\n",
    "\n",
    "    else:\n",
    "        return \"Incorrect deviation argument\"\n",
    "    \n",
    "    return stat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcRMSummary(unit, alley, visit):\n",
    "    \"\"\"\n",
    "    For a given pass for a given unit\n",
    "    summarize the 1d ratemap into a simpler,\n",
    "    explicit vector of attributes\n",
    "    - period within session (half, third?,)\n",
    "    - max\n",
    "    - min\n",
    "    - mean\n",
    "    - loc max\n",
    "    - loc min\n",
    "    \"\"\"\n",
    "    rm = unit.alleys[alley][visit]['ratemap1d']\n",
    "    epoch = np.digitize(visit,[0,30,60])\n",
    "    maximum, minimum, mean = np.nanpercentile(rm, 95), np.nanmin(rm), np.nanmean(rm)\n",
    "    locmax, locmin = np.nanargmax(rm), np.nanargmin(rm)\n",
    "    auc = simps(rm)\n",
    "    avgdrds = np.mean(np.abs(np.diff(rm))) # avg dr/ds change in rate / change in pos. \n",
    "    maxdrds = np.percentile(np.abs(np.diff(rm)), 95)\n",
    "    com = center_of_mass(rm)\n",
    "    rm = np.nan_to_num(rm)\n",
    "    distA = cosine(rm, unit.linRMS[alley]['A'])\n",
    "    distB = cosine(rm, unit.linRMS[alley]['B'])\n",
    "    distC = cosine(rm, unit.linRMS[alley]['C'])\n",
    "    #x = preprocessing.StandardScaler().fit_transform(rm)\n",
    "    #pca = PCA(n_components=3)\n",
    "    #principalComponents = pca.fit_transform(x)\n",
    "    return np.asarray((maximum, minimum, locmax, locmin, com[0], auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupRFdata(target, representationFx):\n",
    "\n",
    "    \"\"\"\n",
    "    This block collects data into data matrix X and label matrix Y.\n",
    "    Each entry is an averaged linear ratemap for a cell under a given condition (alley/txt).\n",
    "    Entry is the test statistic comparing AvB (labeled A), B vs C (labeled B) and CvA (labeled C)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.empty((0, (6)*len(population)))\n",
    "    Y = []\n",
    "\n",
    "\n",
    "    for alley in beltwayAlleys:\n",
    "\n",
    "        for visit in range(len(population[list(population.keys())[0]].alleys[alley])):\n",
    "\n",
    "            stim = population[list(population.keys())[0]].alleys[alley][visit]['metadata']['stimulus']\n",
    "            label = generateLabel2(target, alley, stim)\n",
    "            dataRow = np.empty((0))\n",
    "            \n",
    "            for unitname, Unit in population.items():\n",
    "                rm = representationFx(Unit, alley, visit)\n",
    "                dataRow = np.hstack((dataRow, rm))\n",
    "        \n",
    "            Y.append(label)\n",
    "            X = np.vstack((X, dataRow))\n",
    "\n",
    "    X[np.where(~np.isfinite(X))] = 0\n",
    "    #X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "    if shuffle is True:\n",
    "        if target == 'AlleyXStimulus':\n",
    "            txt = [i[-1] for i in Y]\n",
    "            np.random.shuffle(txt)\n",
    "            a = [i[:-1] for i in Y]\n",
    "            Y = [f\"{x}{y}\" for x,y in zip(a,txt)]\n",
    "        elif target == 'Stimulus':\n",
    "            np.random.shuffle(Y)\n",
    "        elif target == 'Alley':\n",
    "            np.random.shuffle(Y)\n",
    "\n",
    "    return X, np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRandomForest(X, Y, runs=300, trees=700):\n",
    "    oobs, precisions, recalls, f1s, accuracies = [], [], [], [],[]\n",
    "    avgType = 'macro'\n",
    "    for i in range(runs):\n",
    "        clf = RandomForestClassifier(n_estimators=trees, \n",
    "                                     oob_score=True,\n",
    "                                     max_features = None,\n",
    "                                     max_depth = 4\n",
    "                                    )\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,shuffle=True,random_state=0)\n",
    "        clf.fit(Xtrain,ytrain)\n",
    "        oobs.append(clf.oob_score_)\n",
    "        yfit = clf.predict(Xtest)\n",
    "        p = precision_score(ytest, yfit, average=avgType)\n",
    "        r = recall_score(ytest, yfit, average=avgType)\n",
    "        f1 = f1_score(ytest, yfit, average=avgType)\n",
    "        acc = accuracy_score(ytest,yfit)\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        f1s.append(f1)\n",
    "        accuracies.append(acc)\n",
    "    return [oobs, precisions, recalls, f1s, accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest_wrapper(target):\n",
    "    \"\"\"\n",
    "    Wrapper function that takes a target variable\n",
    "    to decode. Creates data and label matrices X,Y\n",
    "    and runs a random forest classifier with a set\n",
    "    number of trees and runs. Returns readouts:\n",
    "    oob score, precision, recall, F1, accuracy for each run\n",
    "    Plots the histograms of each on a single new figure\n",
    "    \"\"\"\n",
    "    X,Y = setupRFdata(target)\n",
    "    oobs, precisions, recalls, f1s, accuracies = runRandomForest(X,Y, runs=100)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(precisions, color='b', alpha=0.5)\n",
    "    ax.hist(recalls, color='r', alpha=0.5)\n",
    "    ax.hist(f1s, color='g', alpha=0.5)\n",
    "    ax.hist(accuracies, color='k', alpha=0.5)\n",
    "    ax.hist(oobs,color='purple',alpha=0.5)\n",
    "    ax.legend([\"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\", \"OOB\"])\n",
    "    ax.set_ylabel(\"Frquency\")\n",
    "    ax.set_xlabel(\"Performance\")\n",
    "    ax.set_title(f\"RF Decoding Performance Metrics on {target}, {(lambda x: 'Real' if x == False else 'Shuffle')(shuffle)}\")\n",
    "    plt.show()\n",
    "    print(target)\n",
    "    return oobs, precisions, recalls, f1s, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "rc = Client()\n",
    "dv = rc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing RandomForestClassifier from sklearn.ensemble on engine(s)\n",
      "importing classification_report,precision_score,recall_score,f1_score,accuracy_score from sklearn.metrics on engine(s)\n",
      "importing train_test_split from sklearn.model_selection on engine(s)\n"
     ]
    }
   ],
   "source": [
    "with dv.sync_imports():\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "    from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\measurements.py:1301: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  for dir in range(input.ndim)]\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4274: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Creating Data Matrices\n",
      "Finished Decoding, took 13.73min\n"
     ]
    }
   ],
   "source": [
    "Xs, Ys = [], []\n",
    "\n",
    "# choose here which representation function to use\n",
    "repFx = calcRMSummary\n",
    "for target in ['Alley', 'Stimulus', 'AlleyXStimulus']:\n",
    "    X, Y  = setupRFdata(target, repFx)\n",
    "    Xs.append(X)\n",
    "    Ys.append(Y)\n",
    "\n",
    "print(\"Finished Creating Data Matrices\")\n",
    "\n",
    "beginT = datetime.datetime.now()\n",
    "results = dv.map_sync(runRandomForest, Xs, Ys)\n",
    "endT = datetime.datetime.now()\n",
    "print(f\"Finished Decoding, took {round((endT-beginT).total_seconds()/60,2)}min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   2.,  18.,  53.,  41.,  93.,  63.,  18.,   9.,   1.]),\n",
       " array([ 0.195,  0.204,  0.213,  0.222,  0.231,  0.24 ,  0.249,  0.258,\n",
       "         0.267,  0.276,  0.285]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(results[0][0],color='b')\n",
    "plt.hist(results[1][0],color='g')\n",
    "plt.hist(results[2][0],color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
