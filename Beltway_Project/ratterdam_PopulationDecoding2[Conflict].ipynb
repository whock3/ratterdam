{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whock\\Anaconda3\\Lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\whock\\Anaconda3\\Lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "import numpy as np, random, json, pickle, datetime, copy, socket, os, sys, scipy\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from importlib import reload\n",
    "\n",
    "if socket.gethostname() == 'Tolman':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whockei1\\\\Google Drive'\n",
    "elif socket.gethostname() == 'DESKTOP-BECTOJ9':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whock\\\\Google Drive'\n",
    "    \n",
    "sys.path.insert(0, codeDirBase + '\\\\KnierimLab\\\\Ratterdam\\\\Code')\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as Parse\n",
    "import ratterdam_CoreDataStructures as Core\n",
    "import ratterdam_PermutationTests as Perm\n",
    "import ratterdam_Defaults as Def\n",
    "\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Population data into dict unitname:UnitData() object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT11\\cl-maze1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whock\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:157: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whock\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:157: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*30\n",
      "C:\\Users\\whock\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:163: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whock\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:163: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 30\n",
      "C:\\Users\\whock\\Google Drive\\KnierimLab\\Ratterdam\\Code\\utility_fx.py:321: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT11\\cl-maze1.2\n",
      "TT3\\cl-maze1.1\n",
      "TT3\\cl-maze1.2\n",
      "TT3\\cl-maze1.3\n",
      "TT3\\cl-maze1.4\n",
      "TT3\\cl-maze1.5\n",
      "TT3\\cl-maze1.6\n",
      "TT3\\cl-maze1.7\n",
      "TT5\\cl-maze1.1\n",
      "TT5\\cl-maze1.2\n",
      "TT5\\cl-maze1.3\n",
      "TT5\\cl-maze1.4\n",
      "TT6\\cl-maze1.1\n",
      "TT6\\cl-maze1.2\n",
      "TT6\\cl-maze1.3\n",
      "TT6\\cl-maze1.4\n",
      "TT6\\cl-maze1.5\n",
      "TT6\\cl-maze1.6\n",
      "TT6\\cl-maze1.7\n",
      "TT6\\cl-maze1.8\n",
      "TT6\\cl-maze1.9\n",
      "TT9\\cl-maze1.1\n",
      "TT9\\cl-maze1.2\n",
      "TT9\\cl-maze1.3\n",
      "TT9\\cl-maze1.4\n",
      "TT9\\cl-maze1.5\n",
      "TT9\\cl-maze1.6\n",
      "TT9\\cl-maze1.7\n"
     ]
    }
   ],
   "source": [
    "#datafile = \"E:\\\\Ratterdam\\\\R781\\\\Beltway_D3_190307\\\\\"\n",
    "datafile = \"C:\\\\Users\\\\whock\\\\Google Drive\\\\KnierimLab\\\\Ratterdam\\\\Data\\\\R781\\\\Beltway_D3\\\\\"\n",
    "expCode = \"BRD3\"\n",
    "alleyTracking, alleyVisits,  txtVisits, p_sess, ts_sess = Parse.getDaysBehavioralData(datafile, expCode)\n",
    "population = {}\n",
    "for subdir, dirs, fs in os.walk(datafile):\n",
    "    for f in fs:\n",
    "        if 'cl-maze1' in f and 'OLD' not in f and 'Undefined' not in f:\n",
    "            clustname = subdir[subdir.index(\"TT\"):] + \"\\\\\" + f\n",
    "            print(clustname)\n",
    "            unit = Core.UnitData(clustname, datafile, expCode, Def.alleyBounds, alleyVisits, txtVisits, p_sess, ts_sess)\n",
    "            unit.loadData_raw(includeRewards=False)\n",
    "            population[unit.name] = unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions for Decoding (not general enough to warrant inclusion in utility_fx.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_epoch(val,size):\n",
    "    \"\"\"hardcode that session is divided\n",
    "    into thirds. find in which third the trial is in\"\"\"\n",
    "    propthrusess = val/size\n",
    "    if propthrusess < 0.25:\n",
    "        epoch = '0'\n",
    "    elif propthrusess <= 0.5:\n",
    "        epoch = '1'\n",
    "    elif propthrusess <= 0.75:\n",
    "        epoch = '2'\n",
    "    elif propthrusess < 1.:\n",
    "        epoch = '3'\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkRM(ratemap):\n",
    "    \"\"\"Utility function to take a 1-d linear ratemap\n",
    "    and see if it is valid.\n",
    "    May 2019: it's not empty ie. there's data\n",
    "    and the nanmax of that data exceeds firing rate\n",
    "    thresh defined locally\"\"\"\n",
    "    if type(ratemap) == np.ndarray and np.nanmax(ratemap) > frThresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateLabel(target, alley, stimulus, epoch):\n",
    "    if target == 'Alley':\n",
    "        label = str(alley)\n",
    "    elif target == 'Stimulus':\n",
    "        label = stimulus\n",
    "    elif target == 'Epoch':\n",
    "        label = epoch\n",
    "    elif target == 'AlleyXStimulus':\n",
    "        label = f\"{alley}{stimulus}\"\n",
    "    elif target == 'AlleyXEpoch':\n",
    "        label  = f\"{alley}{epoch}\"\n",
    "    elif target == 'StimulusXEpoch':\n",
    "        label = f\"{stimulus}{epoch}\"\n",
    "    elif target == 'AlleyXStimulusXEpoch':\n",
    "        label = f\"{alley}{stimulus}{epoch}\"\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateLabel_rand(target, alley, stimulus, epoch):\n",
    "    if target == 'Alley':\n",
    "        label = str(alley)\n",
    "    elif target == 'Stimulus':\n",
    "        label = stimulus\n",
    "    elif target == 'Epoch':\n",
    "        label = epoch\n",
    "    elif target == 'AlleyXStimulus':\n",
    "        label = f\"{alley}{np.random.choice(['A','B','C'])}\"\n",
    "    elif target == 'AlleyXEpoch':\n",
    "        label  = f\"{alley}{epoch}\"\n",
    "    elif target == 'StimulusXEpoch':\n",
    "        label = f\"{stimulus}{epoch}\"\n",
    "    elif target == 'AlleyXStimulusXEpoch':\n",
    "        label = f\"{alley}{stimulus}{epoch}\"\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frThresh = 0.0 #measured in Hz. Pick something close to 0, or 0 itself. \n",
    "target = 'AlleyXStimulus' #choices are Alley, Texture, Epoch, or some 2- or 3-member combination of these\n",
    "beltwayAlleys = [16, 17, 3, 1, 5, 7, 8, 10, 11] # beltway alley IDs in terms of their full track, 17-alley ID\n",
    "nbins = Def.singleAlleyBins[0]-1\n",
    "avgType = 'macro' # for signal detection / performance metrics which are not inherently multiclass (e.g. all but accuracy), pick how to aggregate individual class results\n",
    "nRuns = 200# number of repeats for multiple subsampling\n",
    "\n",
    "# SVC params\n",
    "C = 1e7 # found via gridsearch\n",
    "gamma = 0.01 # found via gridsearch\n",
    "kernel = 'rbf'\n",
    "split_size = 0.75 # defined in terms of train size, proportion 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Matrix X and label vector Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.empty((0, nbins*len(population.keys())))\n",
    "X = np.empty((0, nbins))\n",
    "Y = []\n",
    "\n",
    "for alley in beltwayAlleys:\n",
    "    visitSize = len(population[list(population.keys())[0]].alleys[alley]) # all units have same behavioral data obviously so use first unit by default to get num viists to alley.\n",
    "    for visitNum in range(visitSize): \n",
    "        dataRow = np.empty((0))\n",
    "        epoch = compute_epoch(visitNum, visitSize)\n",
    "        stimulus = population[list(population.keys())[0]].alleys[alley][visitNum]['metadata']['stimulus'] #again, stims are same for all units so use first unit to grab it\n",
    "        label = generateLabel(target, alley, stimulus, epoch)\n",
    "        \n",
    "        invalidRow = 0 # initialize to valid, set to invalid upon finding an invalid rm\n",
    "        for unitname, Unit in population.items():\n",
    "            rm = Unit.alleys[alley][visitNum]['ratemap1d']\n",
    "            if checkRM(rm) == True:\n",
    "                dataRow = np.concatenate((dataRow, rm))\n",
    "                X = np.vstack((X, rm))\n",
    "                Y.append(label)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "                #dataRow = np.concatenate((dataRow, np.zeros((nbins)) ))\n",
    "                \n",
    "        #Y.append(label)\n",
    "        #X = np.vstack((X, dataRow))\n",
    "\n",
    "X[np.where(~np.isfinite(X))] = 0\n",
    "X = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whock\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-3d14bc18b3f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#default split size is 1/4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0myfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mavgType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "precisions, recalls, f1s, accuracies = [], [], [], []\n",
    "\n",
    "for i in range(nRuns):\n",
    "    print(i)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, shuffle=True, train_size=split_size) #default split size is 1/4\n",
    "    svc = SVC(C=C, gamma=gamma,kernel=kernel)\n",
    "    svc.fit(Xtrain,ytrain)\n",
    "    yfit = svc.predict(Xtest)\n",
    "    p = precision_score(ytest, yfit, average=avgType)\n",
    "    r = recall_score(ytest, yfit, average=avgType)\n",
    "    f1 = f1_score(ytest, yfit, average=avgType)\n",
    "    acc = accuracy_score(ytest,yfit)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f1)\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Visualization of Signal Detection / Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'SVM Decoding Performance Metrics on AlleyXStimulus')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(precisions, color='b', alpha=0.5)\n",
    "plt.hist(recalls, color='r', alpha=0.5)\n",
    "plt.hist(f1s, color='g', alpha=0.5)\n",
    "plt.hist(accuracies, color='k', alpha=0.5)\n",
    "plt.legend([\"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"])\n",
    "#plt.vlines(0.093,0,plt.ylim()[1])\n",
    "plt.ylabel(\"Frquency\")\n",
    "plt.xlabel(\"Performance\")\n",
    "plt.title(f\"SVM Decoding Performance Metrics on {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whock\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function prints and plots the confusion matrix.\n",
    "Normalization can be applied by setting `normalize=True`.\n",
    "\n",
    "Taken from the sklearn docs. Modified by WH\n",
    "\"\"\"\n",
    "normalize=False\n",
    "classes = np.unique(Y)\n",
    "# Compute multiple confusion matrces and sum\n",
    "allcms = []\n",
    "for run in range(1):\n",
    "    Xtrain, Xtest, ytrain, y_true = train_test_split(X, Y, shuffle=True, train_size=split_size)\n",
    "    svc = SVC(C=C, gamma=gamma,kernel=kernel)\n",
    "    svc.fit(Xtrain,ytrain)\n",
    "    y_pred = svc.predict(Xtest)\n",
    "    c = confusion_matrix(y_true, y_pred)\n",
    "    allcms.append(c)\n",
    "\n",
    "cm = np.sum(np.asarray(allcms), axis=0)\n",
    "\n",
    "# Only use the labels that appear in the data\n",
    "if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "# We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       # ... and label them with the respective list entries\n",
    "       xticklabels=classes, yticklabels=classes,\n",
    "       title=[],\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "\n",
    "ax.plot(range(classes.shape[0]), range(classes.shape[0]))\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "fmt = '.2f' if normalize else 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
