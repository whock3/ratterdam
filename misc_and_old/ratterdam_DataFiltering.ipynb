{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratterdam Data Filtering\n",
    "### Notebook to test code related to velocity filtering, EEG filtering, normalization,\n",
    "### and other tertiary pre-processing steps that affect what data enters \n",
    "### the core data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, random, json, pickle, datetime, copy, socket, os\n",
    "from numpy.linalg import norm as npNorm\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as colors\n",
    "from scipy.ndimage import gaussian_filter as gauss # for smoothing ratemaps\n",
    "import sys\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as GS\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from importlib import reload\n",
    "\n",
    "if socket.gethostname() == 'Tolman':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whockei1\\\\Google Drive'\n",
    "    dataDrive = \"E:\\Ratterdam\"\n",
    "elif socket.gethostname() == 'DESKTOP-BECTOJ9':\n",
    "    codeDirBase = 'C:\\\\Users\\\\whock\\\\Google Drive'\n",
    "    dataDrive = \"D:\\Knierim_Lab\\\\Ratterdam\"\n",
    "    \n",
    "sys.path.insert(0, codeDirBase + '\\\\KnierimLab\\\\Ratterdam\\\\Code')\n",
    "sys.path.insert(0, codeDirBase + '\\\\Python_Code\\\\KLab\\\\mts_analysis')\n",
    "import utility_fx as util\n",
    "import ratterdam_ParseBehavior as pBehav\n",
    "import ratterdam_CoreDataStructures as core\n",
    "from ratterdam_Defaults import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --style native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:139: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:139: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*33\n",
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:309: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:305: RuntimeWarning: invalid value encountered in multiply\n",
      "  W=0*U.copy()+1\n"
     ]
    }
   ],
   "source": [
    "rat = \"R765\"\n",
    "exp = \"RFD7\"\n",
    "datafile = f\"{dataDrive}\\\\{rat}\\\\{rat}{exp}\\\\\"\n",
    "clustname = 'TT4\\\\cl-maze1.9'\n",
    "clustList = util.getClustList(datafile)\n",
    "behav = core.BehavioralData(datafile, exp, 0)\n",
    "ts, position, alleyTracking, alleyVisits,  txtVisits = behav.loadData()\n",
    "unit = core.UnitData(clustname, datafile, exp, alleyBounds, alleyVisits, txtVisits, position, ts)\n",
    "unit.loadData_raw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Velocity Filtering and Trying to find a good V threshold for ratterdam\n",
    "winsz = 50\n",
    "vthresh = 3\n",
    "ptsCm = 4.85\n",
    "\n",
    "gradts, gradx, grady = np.gradient(position[:,0]), np.gradient(position[:,1]), np.gradient(position[:,2])\n",
    "gradx = [np.mean(gradx[0+i:winsz+i]) for i in range(len(gradx))]\n",
    "grady = [np.mean(grady[0+i:winsz+i]) for i in range(len(grady))]\n",
    "gradx = np.asarray([i/ptsCm for i in gradx])\n",
    "grady = np.asarray([i/ptsCm for i in grady])\n",
    "\n",
    "vx = np.asarray([1e6*a/b for a,b in zip(gradx,gradts)])\n",
    "vy = np.asarray([1e6*a/b for a,b in zip(grady,gradts)])\n",
    "v =  np.sqrt((vx**2)+(vy**2))  \n",
    "\n",
    "sv = [np.mean(v[0+i:winsz+i]) for i in range(len(v))]\n",
    "sv = np.asarray(sv)\n",
    "\n",
    "vf_pos = position[sv > vthresh]\n",
    "belowthresh_pos = position[sv <= vthresh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Directionality\n",
    "logic is get midpoints of alley line bounds, check distance, which is closer?\n",
    "Then see if that end is the, by convention, NE or SW, and add it to that group.\n",
    "To get determine which side is NE/SW you just see if either x,y is smaller\n",
    "than the other alley end size, depending on which orienation the alley is.\n",
    "which in turn can be checked by seeing if x alley bound range > y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractCorners(givenAlleyBounds):\n",
    "    \"\"\"Alley bounds gives [[x1, x2], [y1, y2]]. Convert that\n",
    "    to UL, LL, UR, LL (xn, ym) points n,m <- [1,2]\n",
    "    ul - x1, y2\n",
    "    ll - x1, y1\n",
    "    ur = x2, y2\n",
    "    lr = x2, y1\n",
    "    \n",
    "    Returns ul, ll, ur, lr\n",
    "    \"\"\"\n",
    "    b = givenAlleyBounds # for ease of typing\n",
    "    ul, ll, ur, lr = [b[0][0], b[1][1]], [b[0][0], b[1][0]], [b[0][1], b[1][1]], [b[0][1], b[1][0]]\n",
    "    return ul, ll, ur, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCloserPoint(p1, p2, pt):\n",
    "    \"\"\"\n",
    "    Given two points p1, p2\n",
    "    where each is [x,y]\n",
    "    see which pt is closer to\n",
    "    (also of form [x,y])\n",
    "    \n",
    "    Return string \"first\" or \"second\"\n",
    "    meaning its closer to first point arg\n",
    "    or second point arg. If equal return \"error\"\n",
    "    \"\"\"\n",
    "    d1 = npNorm(p1 - pt)\n",
    "    d2 = npNorm(p2 - pt)\n",
    "    if d1 < d2:\n",
    "        return \"first\"\n",
    "    elif d2 < d1:\n",
    "        return \"second\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkVisitEntrySide(visitOccs, bounds):\n",
    "    \"\"\"\n",
    "    visitOccs is [ts,x,y] arr for 1 visit\n",
    "    bounds is [ul, ll, ur, lr] for alley in question\n",
    "    Return a label \"SW\" or \"NE\"\n",
    "    \"\"\"\n",
    "    begin = visitOccs[0,1:]\n",
    "    ll, ur = bounds[1], bounds[2]\n",
    "    closerPt = checkCloserPoint(ll, ur, begin)\n",
    "    if closerPt is not None:\n",
    "        if closerPt == \"first\":\n",
    "            side = \"SW\"\n",
    "        elif closerPt == \"second\":\n",
    "            side = \"NE\"\n",
    "    else:\n",
    "        side = None\n",
    "    return side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupVisitsByDir(alley):\n",
    "    \"\"\"\n",
    "    Given a 1-idx alley, consider all\n",
    "    visits and group them by whether entry\n",
    "    was from SW or NE side.\n",
    "    \n",
    "    Method checks if 1st occ pt is closer\n",
    "    to LL or UR corner of alley\n",
    "    \n",
    "    Returns dict list of visits from SW, NE\n",
    "    \"\"\"\n",
    "    bounds = extractCorners(alleyBounds[alley-1]) # ul, ll, ur, lr format list\n",
    "    visitDirs = {\"SW\":[], \"NE\":[]}\n",
    "    for i,visit in enumerate(unit.alleys[alley]):\n",
    "        side = checkVisitEntrySide(visit['occs'], bounds)\n",
    "        if side is not None:\n",
    "            visitDirs[side].append(i)\n",
    "    \n",
    "    return visitDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visitsByDir_LinearRM(alley):\n",
    "    \"\"\"\n",
    "    Given an alley, separate visits by\n",
    "    entry on the SW, NE side of it.\n",
    "    Concat all those linear RM into\n",
    "    a nXc matrix\n",
    "    \n",
    "    Assume unit is in local namespace\n",
    "    defaults in local namespace\n",
    "    \"\"\"\n",
    "    c = singleAlleyBins[1]-1 #-1 because the nominal val is +1 for histgr reasons\n",
    "    visitDirs = groupVisitsByDir(alley)\n",
    "    groupedLinRMs = {\"SW\":np.empty((0,c)), \"NE\":np.empty((0,c))}\n",
    "    for side in [\"SW\", \"NE\"]:\n",
    "        if visitDirs[side] is not []:\n",
    "            for visitIdx in visitDirs[side]:\n",
    "                groupedLinRMs[side] = np.vstack((groupedLinRMs[side], unit.alleys[alley][visitIdx]['ratemap1d']))\n",
    "    return groupedLinRMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_VisitsDirLinRM(ax, alley, groupedLinRMs):\n",
    "    \"\"\"\n",
    "    Given a dict of matrices, one for all\n",
    "    visits from each side of alley (SW, NE)\n",
    "    plot them avg +/- sem on same subplot\n",
    "    provided externally by ax arg\n",
    "    \n",
    "    make sure scipy.stats.sem is imp as 'sem'\n",
    "    \n",
    "    dir1 will be blue, dir2 red. Don't confuse w/ longrunning txt color codes\n",
    "    \"\"\"\n",
    "    sides = list(groupedLinRMs.keys()) # initially side closer to SW, NE corner but make arb if changed\n",
    "    dir1, dir2 = groupedLinRMs[sides[0]], groupedLinRMs[sides[1]]\n",
    "    dir1mean, dir2mean, dir1sem, dir2sem = np.nanmean(dir1, axis=0), np.nanmean(dir2, axis=0), sem(dir1,axis=0, nan_policy='omit'), sem(dir2,axis=0, nan_policy='omit')\n",
    "    for mean, err, color in zip([dir1mean, dir2mean], [dir1sem, dir2sem], ['b', 'r']):\n",
    "        ax.plot(mean, color)\n",
    "        ax.fill_between(range(len(mean)), mean-err, mean+err, color=color, alpha=0.5)\n",
    "    ax.set_title(f\"Alley {alley}, {sides[0]} (b): {dir1.shape[0]}, {sides[1]} (r): {dir2.shape[0]}\",fontsize=12)\n",
    "    ax.set_xticks([])\n",
    "    \n",
    "    #make textbox of counts, passes thru dir by txt present\n",
    "    # counts is nested dir txt -> side\n",
    "    counts = tabulateTxtByDir(getTxtVisitsByDir(alley))\n",
    "    annot = \"\\n\".join((\n",
    "        f\"A: SW: {counts['A']['SW']}, NE:{counts['A']['NE']}\",\n",
    "        f\"B: SW: {counts['B']['SW']}, NE:{counts['B']['NE']}\",\n",
    "        f\"C: SW: {counts['C']['SW']}, NE:{counts['C']['NE']}\",\n",
    "    ))\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.05, 0.95, annot, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotRoutine_VisitsDirLin():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(5,4, figsize=(10,10))\n",
    "    for alley in range(1,18):\n",
    "        axis = fig.axes[alley-1]\n",
    "        groupedLinRMs = visitsByDir_LinearRM(alley)\n",
    "        plot_VisitsDirLinRM(axis, alley, groupedLinRMs)\n",
    "    plt.suptitle(f\"{exp} {unit.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTxtVisitsByDir(alley):\n",
    "    \"\"\"\n",
    "    Given an alley, group visits\n",
    "    whether SW/NE entry and crossref\n",
    "    with txts present to get table\n",
    "    of txts by dir count\n",
    "    \"\"\"\n",
    "    txtDirTable = {txt:{\"SW\":[], \"NE\":[]} for txt in [\"A\", \"B\", \"C\"]}\n",
    "    visitDirs = groupVisitsByDir(alley)\n",
    "    for side in [\"SW\", \"NE\"]:\n",
    "        if visitDirs[side] is not []:\n",
    "            for visitIdx in visitDirs[side]:\n",
    "                txt = unit.alleys[alley][visitIdx]['metadata']['stimulus'][0] # 0 bc it has dtype as entry 1\n",
    "                txtDirTable[txt][side].append(visitIdx)\n",
    "    return txtDirTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabulateTxtByDir(txtDirTable):\n",
    "    \"\"\"\n",
    "    Helper fx to count passes along a dir\n",
    "    by txt present\n",
    "    \"\"\"\n",
    "    counts = {txt:{\"SW\":0, \"NE\":0} for txt in [\"A\", \"B\", \"C\"]}\n",
    "    for txt in [\"A\", \"B\", \"C\"]:\n",
    "        for side in [\"SW\", \"NE\"]:\n",
    "            if txtDirTable[txt][side] is not []:\n",
    "                counts[txt][side] = len(txtDirTable[txt][side])\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behav = core.BehavioralData(datafile, exp, 0)\n",
    "ts, position, alleyTracking, alleyVisits,  txtVisits = behav.loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:139: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (hs*np.reciprocal(ho))*33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:139: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (hs*np.reciprocal(ho))*33\n",
      "C:\\Users\\whockei1\\Google Drive\\Python_Code\\KLab\\mts_analysis\\utility_fx.py:314: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Z=VV/WW\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\Google Drive\\KnierimLab\\Ratterdam\\Code\\ratterdam_CoreDataStructures.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = (ls* np.reciprocal(lo)) * 33\n",
      "C:\\Users\\whockei1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "clustname = \"TT4\\\\cl-maze1.1\"\n",
    "unit = core.UnitData(clustname, datafile, exp, alleyBounds, alleyVisits, txtVisits, position, ts)\n",
    "unit.loadData_raw()\n",
    "plotRoutine_VisitsDirLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupTrials(alley, trialList):\n",
    "    \"\"\"\n",
    "    Given a list of visits and alley\n",
    "    gather them and vstack\n",
    "    If empty return None\n",
    "    \"\"\"\n",
    "    if trialList ==[] or trialList == None:\n",
    "        return None\n",
    "    else:\n",
    "        trialMat = np.empty((0, singleAlleyBins[1]-1))\n",
    "        for trial in trialList:\n",
    "            rm = unit.alleys[alley][trial]['ratemap1d']\n",
    "            trialMat = np.vstack((trialMat, rm))\n",
    "    return trialMat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSmartMax(array2d, cutoff=0.98, scale=2.5,bins=100):\n",
    "    \"\"\"\n",
    "    Given array where each row is a sample, eg a lin rate map\n",
    "    find a good max visualiz. value for eg. imshow across all samples\n",
    "    by getting percentile cutoff and boosting it by scale factor\n",
    "    \n",
    "    Bins is tricky, depends on how many rate maps\n",
    "    go into the analysis. 100 bins is good. 0.98 cutoff.\n",
    "    \"\"\"\n",
    "    frs = []\n",
    "    for row in array2d:\n",
    "        frs.extend(row)\n",
    "    frs = np.asarray(frs)\n",
    "    frs = frs[np.isfinite(frs)]\n",
    "    h,b = np.histogram(frs, bins=bins)\n",
    "    frcum = np.cumsum(h)\n",
    "    propExp = np.asarray([i/h.sum() for i in frcum])\n",
    "    try:\n",
    "        thresh = np.where(propExp < cutoff)[0][-1]\n",
    "    except:\n",
    "        thresh = np.where(b == np.median(b))\n",
    "    return b[thresh]*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = util.makeCustomColormap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'C')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alley = 9\n",
    "table = getTxtVisitsByDir(alley)\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize=(7,7))\n",
    "i=0 # crude counter to get current idx for axes\n",
    "\n",
    "allmats = np.empty((0, singleAlleyBins[1]-1)) # gather all so you can get an overall max.\n",
    "\n",
    "for txt in [\"A\", \"B\", \"C\"]:\n",
    "    for side in [\"SW\", \"NE\"]:\n",
    "        mat = groupTrials(alley, table[txt][side])\n",
    "        allmats = np.vstack((allmats, mat))\n",
    "mymax = calcSmartMax(allmats, cutoff=0.90, scale=2.5, bins=100)   \n",
    "\n",
    "for txt in [\"A\", \"B\", \"C\"]:\n",
    "    for side in [\"SW\", \"NE\"]:\n",
    "        axis = fig.axes[i]\n",
    "        mat = groupTrials(alley, table[txt][side])\n",
    "        axis.imshow(mat, interpolation='None', aspect='auto', cmap = cmap, vmax = mymax)\n",
    "        i +=1\n",
    "        \n",
    "# annotate with labels\n",
    "fig.axes[0].set_title(\"SW Entry\")\n",
    "fig.axes[1].set_title(\"NE Entry\")\n",
    "fig.axes[0].set_ylabel(\"A\")\n",
    "fig.axes[2].set_ylabel(\"B\")\n",
    "fig.axes[4].set_ylabel(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
